# Data Structures & Algorithms — Deep Dive

> **Mục tiêu:** Hiểu SÂU cấu trúc dữ liệu & giải thuật từ góc nhìn backend engineer — không chỉ "biết dùng" mà hiểu TẠI SAO nó tồn tại, cái giá phải trả (trade-offs), và khi nào nó THẤT BẠI.
>
> **Phương pháp:** 6 patterns tư duy — 5 Whys, First Principles, Trade-off Analysis, Mental Mapping, Reverse Engineering, Contextual History.
>
> **Ngôn ngữ:** Go (áp dụng được cho mọi ngôn ngữ)

---

## Bản Đồ Tổng Quan — Mental Map

```
╔═══════════════════════════════════════════════════════════════════╗
║   DATA STRUCTURES — BẢN ĐỒ TINH THẦN                            ║
╠═══════════════════════════════════════════════════════════════════╣
║                                                                   ║
║  Câu hỏi gốc: "Dữ liệu nên CHỨA ở đâu và TRUY CẬP thế nào?" ║
║                                                                   ║
║  ┌─────────────────────────────────────────────────────────┐     ║
║  │                    DATA STRUCTURES                       │     ║
║  ├─────────────┬───────────────┬───────────────────────────┤     ║
║  │  LINEAR     │  NON-LINEAR   │  PROBABILISTIC            │     ║
║  │  (Tuyến tính)│ (Phi tuyến)  │  (Xác suất)              │     ║
║  ├─────────────┼───────────────┼───────────────────────────┤     ║
║  │  Array      │  Binary Tree  │  Bloom Filter             │     ║
║  │  Linked List│  BST          │  HyperLogLog              │     ║
║  │  Stack      │  Heap         │  Count-Min Sketch         │     ║
║  │  Queue      │  Trie         │  Skip List                │     ║
║  │  Hash Map   │  Graph        │  Consistent Hashing       │     ║
║  │             │  B-Tree/B+Tree│                           │     ║
║  └─────────────┴───────────────┴───────────────────────────┘     ║
║                                                                   ║
║  CHỌN CẤU TRÚC NÀO? → Trả lời 4 câu hỏi:                     ║
║  ① Cần truy cập NGẪU NHIÊN hay TUẦN TỰ?                       ║
║  ② Cần INSERT/DELETE NHANH hay SEARCH NHANH?                    ║
║  ③ Dữ liệu có THỨ TỰ không?                                    ║
║  ④ Cần bao nhiêu MEMORY?                                        ║
║                                                                   ║
║  ┌─────────────────────────────────────────────────────────┐     ║
║  │  TẦNG ỨNG DỤNG                                         │     ║
║  │  API handler: []User, map[string]Session                │     ║
║  ├─────────────────────────────────────────────────────────┤     ║
║  │  TẦNG TRUNG GIAN                                       │     ║
║  │  Redis: Skip List (sorted set), Hash Table              │     ║
║  │  Kafka: Append-only log (array on disk)                 │     ║
║  ├─────────────────────────────────────────────────────────┤     ║
║  │  TẦNG DATABASE                                          │     ║
║  │  PostgreSQL: B+Tree (index), Heap (table storage)       │     ║
║  │  MongoDB: B-Tree (WiredTiger)                           │     ║
║  ├─────────────────────────────────────────────────────────┤     ║
║  │  TẦNG OS / RUNTIME                                      │     ║
║  │  Go runtime: treap (timer), hash map (map), rb-tree     │     ║
║  │  Linux kernel: red-black tree (scheduler), radix tree   │     ║
║  ├─────────────────────────────────────────────────────────┤     ║
║  │  TẦNG PHẦN CỨNG                                        │     ║
║  │  CPU cache: array-friendly (contiguous memory)          │     ║
║  │  Disk: B+Tree-friendly (minimize seeks)                 │     ║
║  └─────────────────────────────────────────────────────────┘     ║
║                                                                   ║
╚═══════════════════════════════════════════════════════════════════╝
```

---

## §1. Array / Slice — Nền Tảng Của Mọi Thứ

### Tại sao Array là cấu trúc dữ liệu QUAN TRỌNG NHẤT?

Mọi cấu trúc dữ liệu phức tạp — từ Hash Map đến B-Tree — cuối cùng đều được xây dựng trên **array** (vùng nhớ liên tục). Hiểu array = hiểu cách CPU và RAM thực sự hoạt động.

> **Analogy:** Array như một dãy **tủ đồ locker** trong phòng gym:
>
> - Các locker **liền nhau**, đánh số từ 0
> - Biết số locker → mở **ngay lập tức** (random access O(1))
> - Muốn **chèn locker mới** vào giữa? Phải **đẩy** tất cả locker phía sau sang phải! (O(n))
> - Muốn **mở rộng**? Phải **thuê cả dãy mới lớn hơn** và **chuyển đồ** sang! (reallocation)

### First Principles — Array ở cấp phần cứng

```
╔═══════════════════════════════════════════════════════════════╗
║   ARRAY TRONG RAM — TẠI SAO NHANH?                          ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Array: vùng nhớ LIÊN TỤC (contiguous)                      ║
║                                                               ║
║  arr := [5]int{10, 20, 30, 40, 50}                           ║
║                                                               ║
║  RAM (mỗi int = 8 bytes trên 64-bit):                       ║
║  ┌────────┬────────┬────────┬────────┬────────┐             ║
║  │  10    │  20    │  30    │  40    │  50    │             ║
║  ├────────┼────────┼────────┼────────┼────────┤             ║
║  │ 0x1000 │ 0x1008 │ 0x1010 │ 0x1018 │ 0x1020│             ║
║  └────────┴────────┴────────┴────────┴────────┘             ║
║   base     +8       +16      +24      +32                    ║
║                                                               ║
║  TRUY CẬP arr[3]:                                            ║
║  address = base + (index × sizeof(element))                  ║
║         = 0x1000 + (3 × 8)                                   ║
║         = 0x1018 → Đọc giá trị 40                           ║
║  → 1 phép tính → O(1) CONSTANT TIME!                       ║
║                                                               ║
║  ─────────────────────────────────────────────────────────    ║
║                                                               ║
║  TẠI SAO ARRAY THÂN THIỆN VỚI CPU CACHE?                    ║
║                                                               ║
║  CPU cache line = 64 bytes → chứa 8 int liền nhau!         ║
║                                                               ║
║  Khi đọc arr[0]:                                             ║
║  → CPU load NGUYÊN cache line: arr[0]..arr[7]               ║
║  → Đọc arr[1], arr[2]... = đã có trong cache!              ║
║  → Cache HIT rate > 95% → CỰC NHANH                       ║
║                                                               ║
║  So sánh với Linked List:                                    ║
║  → Mỗi node ở vị trí NGẪU NHIÊN trong RAM                 ║
║  → CPU load cache line → chỉ dùng được 1 node!            ║
║  → Đọc node tiếp → CACHE MISS → chờ ~100ns!              ║
║  → Cache HIT rate < 20% → CHẬM 5-10×                      ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### Go Slice — Array động thông minh

Go không khuyến khích dùng array cố định. Thay vào đó, **slice** là abstraction phổ biến nhất — mọi Go developer đều dùng hàng ngày:

```go
// SLICE INTERNAL STRUCTURE
// Go slice = struct 3 fields (24 bytes trên 64-bit)
type slice struct {
    ptr *[...]T  // pointer đến underlying array
    len int      // số phần tử đang dùng
    cap int      // tổng capacity (trước khi cần realloc)
}
```

```
╔═══════════════════════════════════════════════════════════════╗
║   GO SLICE — 3 THÀNH PHẦN                                   ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  s := make([]int, 3, 5)   // len=3, cap=5                   ║
║                                                               ║
║  Slice header (24 bytes, trên stack):                        ║
║  ┌──────────┬──────────┬──────────┐                          ║
║  │ ptr=0x.. │ len=3    │ cap=5    │                          ║
║  └────┬─────┴──────────┴──────────┘                          ║
║       │                                                       ║
║       ▼  Underlying array (trên heap):                       ║
║  ┌────────┬────────┬────────┬────────┬────────┐             ║
║  │   0    │   0    │   0    │  ???   │  ???   │             ║
║  └────────┴────────┴────────┴────────┴────────┘             ║
║    [0]      [1]      [2]     unused   unused                 ║
║  ◄─────── len=3 ──────────►                                  ║
║  ◄──────────────── cap=5 ────────────────────►               ║
║                                                               ║
║  APPEND khi len < cap:                                       ║
║  s = append(s, 99) → len=4, cap=5 (KHÔNG realloc!)         ║
║  ┌────────┬────────┬────────┬────────┬────────┐             ║
║  │   0    │   0    │   0    │  99    │  ???   │             ║
║  └────────┴────────┴────────┴────────┴────────┘             ║
║                                                               ║
║  APPEND khi len == cap:                                      ║
║  s = append(s, 77, 88) → CẦN REALLOC!                      ║
║  ① Allocate mảng mới cap = cap*2 (hoặc +25% nếu >256)    ║
║  ② Copy toàn bộ data sang mảng mới                         ║
║  ③ Append phần tử mới                                       ║
║  ④ Old array → chờ GC thu hồi                              ║
║                                                               ║
║  ┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┐                ║
║  │ 0 │ 0 │ 0 │99 │77 │88 │???│???│???│???│  cap=10       ║
║  └───┴───┴───┴───┴───┴───┴───┴───┴───┴───┘                ║
║  ◄──────── len=6 ────────►                                   ║
║                                                               ║
║  GROWTH STRATEGY (Go 1.21+):                                ║
║  ┌──────────────┬──────────────────────────┐                ║
║  │ Old cap      │ New cap                   │                ║
║  ├──────────────┼──────────────────────────┤                ║
║  │ < 256        │ cap × 2 (gấp đôi)       │                ║
║  │ ≥ 256        │ cap + cap/4 + 192        │                ║
║  │              │ (tăng ~25%, smoother)    │                ║
║  └──────────────┴──────────────────────────┘                ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### Slice Gotchas — Bẫy mà Senior phải biết

```go
// ❌ BẪY 1: Slice share underlying array
func main() {
    original := []int{1, 2, 3, 4, 5}
    sub := original[1:3]  // sub = [2, 3]

    // sub và original CÙNG CHUNG underlying array!
    sub[0] = 99
    fmt.Println(original) // [1, 99, 3, 4, 5] ← BỊ THAY ĐỔI!

    // ✅ FIX: copy ra slice mới
    safe := make([]int, len(sub))
    copy(safe, sub)
    safe[0] = 77
    fmt.Println(original) // [1, 99, 3, 4, 5] ← KHÔNG bị ảnh hưởng
}

// ❌ BẪY 2: Memory leak qua sub-slice
func getFirstTwo(data []int) []int {
    return data[:2]
    // Giữ reference đến TOÀN BỘ underlying array!
    // Nếu data = 1M elements → 1M elements KHÔNG được GC!
}

// ✅ FIX: copy
func getFirstTwoSafe(data []int) []int {
    result := make([]int, 2)
    copy(result, data[:2])
    return result  // Chỉ giữ 2 elements, 1M elements được GC!
}

// ❌ BẪY 3: append có thể tạo array MỚI
func main() {
    a := make([]int, 3, 3) // len=3, cap=3
    b := a                  // b trỏ CÙNG array

    a = append(a, 4)        // cap hết → tạo array MỚI!
    a[0] = 99
    fmt.Println(b[0])       // 0 ← b vẫn trỏ array CŨ!
}

// ❌ BẪY 4: Pre-allocate sai cách
func bad() []int {
    result := []int{}           // cap=0 → sẽ realloc NHIỀU LẦN!
    for i := 0; i < 10000; i++ {
        result = append(result, i)
    }
    return result
    // Log2(10000) ≈ 14 lần realloc + copy!
}

func good() []int {
    result := make([]int, 0, 10000) // Pre-allocate cap=10000
    for i := 0; i < 10000; i++ {
        result = append(result, i)
    }
    return result
    // 0 lần realloc! Nhanh hơn ~3×
}
```

### 5 Whys: Tại sao Array/Slice?

```
╔═══════════════════════════════════════════════════════════════╗
║   5 WHYS: ARRAY / SLICE                                     ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  WHY 1: Tại sao array access O(1)?                          ║
║  → Vì address = base + index × size (1 phép tính!)        ║
║                                                               ║
║  WHY 2: Tại sao phép tính đó nhanh?                        ║
║  → Vì data nằm LIÊN TỤC trong RAM → CPU tính trực tiếp   ║
║                                                               ║
║  WHY 3: Tại sao liên tục lại nhanh?                        ║
║  → Vì CPU cache line = 64B, load 1 lần = 8 int            ║
║  → Spatial locality: data gần nhau → cache hit             ║
║                                                               ║
║  WHY 4: Tại sao insert/delete O(n)?                        ║
║  → Vì phải shift tất cả phần tử → duy trì tính liên tục ║
║  → Đây là CÁI GIÁ của random access O(1)                  ║
║                                                               ║
║  WHY 5: Tại sao Go dùng slice thay array?                   ║
║  → Array cố định → biết trước kích thước = hiếm           ║
║  → Slice = array + len + cap → linh hoạt, amortized O(1)  ║
║  → Growth strategy: double → 25% → giảm memory waste     ║
║                                                               ║
║  GIỚI HẠN VẬT LÝ:                                          ║
║  → Insert ở giữa LUÔN O(n) — không thể tránh vì phải    ║
║    duy trì contiguous memory layout                         ║
║  → Giải pháp: dùng data structure KHÁC (linked list, tree) ║
║    nhưng MẤT cache locality!                                ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### Trade-off Analysis

| Tiêu chí          | Array/Slice             | Khi nào THẤT BẠI?             |
| ----------------- | ----------------------- | ----------------------------- |
| Random access     | O(1) ★★★★★              | —                             |
| Append (cuối)     | Amortized O(1)          | Realloc spike khi cap hết     |
| Insert (giữa)     | O(n) ❌                 | Dữ liệu thay đổi thường xuyên |
| Delete (giữa)     | O(n) ❌                 | Phải shift elements           |
| Search (unsorted) | O(n)                    | Dùng hash map thay thế        |
| Search (sorted)   | O(log n) binary search  | —                             |
| Memory            | Compact, cache-friendly | Waste khi cap >> len          |
| Thread-safe       | ❌ KHÔNG                | Cần sync.Mutex hoặc channel   |

### Contextual History — Lịch sử tiến hóa

```
╔═══════════════════════════════════════════════════════════════╗
║   LỊCH SỬ: TỪ ARRAY ĐẾN SLICE                             ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  1950s: Array trong Fortran                                  ║
║  → Kích thước CỐ ĐỊNH, khai báo lúc compile               ║
║  → DIMENSION A(100) → 100 phần tử, không thêm bớt!       ║
║                                                               ║
║  1970s: C arrays                                             ║
║  → Vẫn cố định, nhưng có malloc() → dynamic array          ║
║  → Vấn đề: buffer overflow, no bounds checking!            ║
║  → int arr[10]; arr[20] = 1; // UNDEFINED BEHAVIOR!        ║
║                                                               ║
║  1990s: C++ std::vector, Java ArrayList                      ║
║  → Auto-resize, bounds checking                              ║
║  → Nhưng vẫn trên heap, boxing/unboxing overhead (Java)    ║
║                                                               ║
║  2009: Go Slice                                              ║
║  → 3-word header: ptr + len + cap                           ║
║  → Bounds checking (runtime panic thay vì UB)              ║
║  → Value semantics cho header, shared backing array         ║
║  → Growth strategy tối ưu cho real-world workloads         ║
║                                                               ║
║  Bài học: Mỗi thế hệ giải quyết VẤN ĐỀ của thế hệ trước║
║  C: "array quá cứng" → malloc                              ║
║  C++/Java: "malloc quá nguy hiểm" → auto-resize           ║
║  Go: "OOP overhead quá lớn" → slice = simple struct        ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### Reverse Engineering — Tự implement Dynamic Array

```go
// Tự xây dựng Dynamic Array để hiểu slice hoạt động thế nào
package main

import "fmt"

type DynArray struct {
    data []int // underlying storage
    size int   // số phần tử thực tế (= len)
}

func NewDynArray() *DynArray {
    return &DynArray{
        data: make([]int, 1), // bắt đầu capacity = 1
        size: 0,
    }
}

func (d *DynArray) Append(val int) {
    // Nếu đầy → double capacity
    if d.size == len(d.data) {
        newData := make([]int, len(d.data)*2)
        copy(newData, d.data) // O(n) copy!
        d.data = newData
        fmt.Printf("  [REALLOC] cap: %d → %d\n", d.size, len(d.data))
    }
    d.data[d.size] = val
    d.size++
}

func (d *DynArray) Get(index int) int {
    if index < 0 || index >= d.size {
        panic("index out of bounds")
    }
    return d.data[index] // O(1)!
}

func (d *DynArray) InsertAt(index, val int) {
    // Phải shift tất cả phần tử từ index trở đi → O(n)
    d.Append(0) // ensure capacity
    for i := d.size - 1; i > index; i-- {
        d.data[i] = d.data[i-1]
    }
    d.data[index] = val
}

func main() {
    arr := NewDynArray()
    for i := 0; i < 20; i++ {
        arr.Append(i)
    }
    // Output: 5 lần realloc (1→2→4→8→16→32)
    // Amortized cost: n inserts → ~2n copy operations → O(1) per insert
    fmt.Printf("Size: %d, Capacity: %d\n", arr.size, len(arr.data))
}
```

### Backend Relevance — Dùng ở đâu trong production?

```
╔═══════════════════════════════════════════════════════════════╗
║   ARRAY/SLICE TRONG BACKEND THỰC TẾ                         ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ① API Response: JSON array of objects                      ║
║  → users := make([]User, 0, 100) // pre-allocate!           ║
║  → Pagination: LIMIT 100 → cap=100 → 0 realloc            ║
║                                                               ║
║  ② Batch Processing: xử lý hàng loạt                       ║
║  → orders := make([]Order, 0, batchSize)                    ║
║  → Process 1000 orders/batch → pre-allocate cap=1000       ║
║                                                               ║
║  ③ Ring Buffer: circular queue cho metrics                  ║
║  → buf := make([]Metric, 1000) // fixed size               ║
║  → Write: buf[writeIdx % 1000] = metric                    ║
║  → Không bao giờ realloc! O(1) write, O(1) read           ║
║                                                               ║
║  ④ Kafka: Log segments = append-only array on disk         ║
║  → Chỉ append cuối → O(1)                                  ║
║  → Không bao giờ insert/delete ở giữa!                     ║
║  → Sequential I/O → disk-friendly                           ║
║                                                               ║
║  ⑤ Database: Table = array of pages (8KB mỗi page)        ║
║  → Sequential scan = đọc array từ đầu đến cuối           ║
║  → Index scan = binary search + random access              ║
║                                                               ║
║  PERFORMANCE TIP:                                             ║
║  → LUÔN pre-allocate khi biết trước kích thước!            ║
║  → make([]T, 0, n) thay vì []T{}                           ║
║  → Giảm 3-5× allocations, giảm GC pressure                ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §2. Hash Map — Vua Tìm Kiếm O(1)

### Bài toán gốc: Tìm kiếm NHANH

Array cho random access O(1) bằng **index**, nhưng nếu key là string (ví dụ username, session ID)? Duyệt lần lượt O(n) → quá chậm cho backend xử lý millions requests.

**Hash Map** giải quyết: biến **key bất kỳ** thành **index** qua hàm hash → O(1) lookup!

> **Analogy:** Hash Map như **hộp thư trong chung cư**:
>
> - Mỗi cư dân có tên (key) → quy tắc gán số hộp thư (hash function)
> - "Nguyễn Văn A" → hash("Nguyễn Văn A") % 100 = hộp thư số 42
> - Lấy thư? Đi thẳng đến hộp 42 → **O(1)**!
> - Hai người cùng số hộp thư? → **Collision** → cần giải quyết!

### First Principles — Hash Function & Collision

```
╔═══════════════════════════════════════════════════════════════╗
║   HASH MAP — CƠ CHẾ HOẠT ĐỘNG                               ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  BƯỚC 1: Hash Function                                      ║
║  key = "user:123"                                            ║
║  hash("user:123") = 0x7A3F...  (số rất lớn)                ║
║  index = hash % len(buckets) = 0x7A3F % 8 = 7              ║
║                                                               ║
║  BƯỚC 2: Lưu vào bucket[7]                                  ║
║  ┌────────┬────────┬────────┬────────┐                      ║
║  │ bucket │ bucket │  ...   │ bucket │                      ║
║  │   0    │   1    │        │   7    │ ← insert here        ║
║  └────────┴────────┴────────┴────┬───┘                      ║
║                                   │                          ║
║                    ┌──────────────▼───────────────┐          ║
║                    │ key="user:123" val=UserData  │          ║
║                    └─────────────────────────────┘          ║
║                                                               ║
║  ─────────────────────────────────────────────────────────    ║
║                                                               ║
║  COLLISION: Hai keys cùng bucket!                            ║
║  hash("user:123") % 8 = 7                                   ║
║  hash("order:456") % 8 = 7  ← CÙNG bucket!                ║
║                                                               ║
║  Giải pháp 1: CHAINING (Go dùng cách này)                  ║
║  bucket[7] → [user:123|data] → [order:456|data] → nil     ║
║  → Linked list trong mỗi bucket                             ║
║  → Worst case: tất cả keys vào 1 bucket → O(n)!           ║
║                                                               ║
║  Giải pháp 2: OPEN ADDRESSING (Python dict)                 ║
║  bucket[7] đã có → thử bucket[8] → bucket[9] → ...        ║
║  → Linear probing / Quadratic probing / Double hashing      ║
║  → Không cần linked list, cache-friendly hơn               ║
║                                                               ║
║  Giải pháp 3: ROBIN HOOD HASHING (Rust HashMap)            ║
║  → Open addressing + đảm bảo "khoảng cách đều"            ║
║  → Giảm variance → worst case tốt hơn                     ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### Go Map Internals — Runtime chi tiết

```
╔═══════════════════════════════════════════════════════════════╗
║   GO MAP — SWISS TABLE (Go 1.24+)                            ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Go 1.0-1.23: custom hash table (chaining)                   ║
║  Go 1.24+: Swiss Table (inspired by Abseil/C++)              ║
║                                                               ║
║  KIẾN TRÚC TRƯỚC Go 1.24 (vẫn cần biết):                   ║
║                                                               ║
║  type hmap struct {                                          ║
║      count     int    // số key-value pairs                  ║
║      B         uint8  // log2(số buckets), 2^B buckets      ║
║      buckets   unsafe.Pointer  // array of bmap             ║
║      oldbuckets unsafe.Pointer // dùng khi đang grow        ║
║  }                                                           ║
║                                                               ║
║  type bmap struct { // mỗi bucket chứa 8 key-value pairs    ║
║      tophash [8]uint8    // top 8 bits của hash mỗi key     ║
║      // keys và values lưu liên tiếp (không xen kẽ!)       ║
║      // keys:   [k0][k1][k2]...[k7]                         ║
║      // values: [v0][v1][v2]...[v7]                         ║
║      // overflow *bmap  // pointer đến bucket tràn          ║
║  }                                                           ║
║                                                               ║
║  ┌──────────────────────────────────────────────┐            ║
║  │ hmap: count=5, B=1 (2 buckets)               │            ║
║  └────────┬─────────────────────────────────────┘            ║
║           │                                                   ║
║  ┌────────▼────────┬───────────────────┐                     ║
║  │   bucket 0       │   bucket 1        │                     ║
║  │ ┌──────────────┐│ ┌──────────────┐  │                     ║
║  │ │tophash: [3 vals]│ │tophash: [2 vals]│                    ║
║  │ │keys: [k0,k1,k2]│ │keys: [k3,k4]   │                    ║
║  │ │vals: [v0,v1,v2]│ │vals: [v3,v4]   │                    ║
║  │ └──────────────┘│ └──────────────┘  │                     ║
║  └─────────────────┴───────────────────┘                     ║
║                                                               ║
║  TẠI SAO keys và values TÁCH RIÊNG?                         ║
║  → Tránh padding! map[int8]int64:                           ║
║  → Xen kẽ: [k0(1B)][pad(7B)][v0(8B)] = 16B/pair          ║
║  → Tách riêng: [k0,k1,...k7](8B) + [v0,...v7](64B) = 9B/p  ║
║                                                               ║
║  GROW (mở rộng):                                             ║
║  → Khi load factor > 6.5 (trung bình 6.5 keys/bucket)      ║
║  → Hoặc quá nhiều overflow buckets                          ║
║  → Incremental rehash: KHÔNG copy tất cả cùng lúc!        ║
║  → Mỗi lần access → move vài buckets sang bảng mới       ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

```go
// Go Map — Những điều PHẢI BIẾT

// ❌ Map KHÔNG thread-safe!
// Concurrent read+write → runtime panic (không phải race condition!)
func bad() {
    m := make(map[string]int)
    go func() { m["a"] = 1 }()  // write
    go func() { _ = m["a"] }()  // read
    // → fatal error: concurrent map read and map write
}

// ✅ FIX 1: sync.Mutex
type SafeMap struct {
    mu sync.RWMutex
    m  map[string]int
}
func (s *SafeMap) Get(key string) int {
    s.mu.RLock()         // read lock (nhiều goroutine đọc đồng thời)
    defer s.mu.RUnlock()
    return s.m[key]
}
func (s *SafeMap) Set(key string, val int) {
    s.mu.Lock()          // write lock (exclusive)
    defer s.mu.Unlock()
    s.m[key] = val
}

// ✅ FIX 2: sync.Map (optimized cho read-heavy workloads)
var cache sync.Map
cache.Store("user:123", userData)           // write
val, ok := cache.Load("user:123")           // read (lock-free!)
cache.Delete("user:123")                    // delete

// Khi nào dùng sync.Map vs sync.RWMutex?
// sync.Map: key ít thay đổi, read >> write (cache, config)
// sync.RWMutex: write thường xuyên, cần iterate

// Map iteration order: RANDOM!
m := map[string]int{"a": 1, "b": 2, "c": 3}
for k, v := range m {
    fmt.Println(k, v) // Thứ tự KHÁC NHAU mỗi lần chạy!
}
// Go cố ý randomize để developer KHÔNG phụ thuộc vào order

// Pre-allocate map
m := make(map[string]int, 1000) // hint: ~1000 entries
// → Runtime allocate đủ buckets từ đầu → ít grow hơn

// Kiểm tra key tồn tại
val, exists := m["key"]
if !exists {
    // key không tồn tại
}
// ❌ ĐỪNG: if m["key"] == 0 → 0 có thể là giá trị hợp lệ!
```

### 5 Whys: Hash Map

```
╔═══════════════════════════════════════════════════════════════╗
║   5 WHYS: HASH MAP                                          ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  WHY 1: Tại sao hash map O(1) lookup?                       ║
║  → Vì hash function biến key → index trong 1 bước         ║
║                                                               ║
║  WHY 2: Tại sao không LUÔN O(1)?                            ║
║  → Vì collision! Nhiều keys cùng bucket → phải scan        ║
║  → Worst case: tất cả n keys vào 1 bucket → O(n)!         ║
║                                                               ║
║  WHY 3: Tại sao vẫn dùng dù worst case O(n)?               ║
║  → Vì hash function tốt → collisions CỰC HIẾM            ║
║  → Average case = O(1), worst case gần như không xảy ra    ║
║  → Load factor < 6.5 → mỗi bucket chỉ ~6 keys            ║
║                                                               ║
║  WHY 4: Tại sao Go map KHÔNG thread-safe?                   ║
║  → Vì lock mỗi access = overhead ~30ns (chậm 3×!)        ║
║  → 95% use cases là single-goroutine → lock = lãng phí    ║
║  → Developer tự chọn: mutex, sync.Map, hoặc channel       ║
║                                                               ║
║  WHY 5: Tại sao Go randomize iteration order?               ║
║  → Vì hash map KHÔNG có thứ tự tự nhiên                   ║
║  → Nếu order ổn định → developer phụ thuộc vào nó        ║
║  → Khi Go thay đổi hash function → code BỊ VỠ!           ║
║  → Randomize = ép developer KHÔNG phụ thuộc order         ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### Trade-off Analysis

| Tiêu chí          | Hash Map                    | Khi nào THẤT BẠI?                     |
| ----------------- | --------------------------- | ------------------------------------- |
| Lookup            | O(1) average ★★★★★          | Hash collision storm → O(n)           |
| Insert            | O(1) average                | Grow/rehash → spike latency           |
| Delete            | O(1) average                | —                                     |
| Ordered iteration | ❌ KHÔNG                    | Dùng TreeMap / sorted slice           |
| Range query       | ❌ KHÔNG                    | "find keys between A-Z" → dùng B-Tree |
| Memory            | ~40-80 bytes overhead/entry | Nhiều hơn array                       |
| Thread-safe       | ❌ (Go)                     | Cần sync.Mutex / sync.Map             |
| Cache-friendly    | Kém (pointer chasing)       | Array tốt hơn cho sequential          |

### Contextual History

```
╔═══════════════════════════════════════════════════════════════╗
║   LỊCH SỬ: HASH TABLE QUA CÁC THỜI KỲ                     ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  1953: Hans Peter Luhn (IBM) — phát minh hash table         ║
║  → Ý tưởng: dùng "phép chia lấy dư" làm index             ║
║                                                               ║
║  1960s: Chaining collision resolution                        ║
║  → Linked list trong mỗi bucket → đơn giản nhưng chậm     ║
║                                                               ║
║  1970s: Open addressing (linear probing)                     ║
║  → Cache-friendly hơn, nhưng clustering problem             ║
║                                                               ║
║  2001: Cuckoo hashing — O(1) worst case lookup!             ║
║  → 2 hash functions, 2 tables                               ║
║  → Nhưng insert khó (có thể cần realloc)                   ║
║                                                               ║
║  2017: Swiss Table (Google Abseil C++)                        ║
║  → SIMD nội suy song song → scan 16 slots cùng lúc        ║
║  → Flat structure → ít pointer → cache-friendly            ║
║  → Go 1.24 (2025) adopt Swiss Table!                        ║
║                                                               ║
║  Bài học: Hash table 70 năm tuổi nhưng VẪN được cải tiến  ║
║  → Mỗi thế hệ tối ưu cho hardware mới (SIMD, cache)      ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### Reverse Engineering — Tự implement Hash Map

```go
package main

import "fmt"

const bucketCount = 16

type entry struct {
    key   string
    value int
    next  *entry // chaining
}

type HashMap struct {
    buckets [bucketCount]*entry
    size    int
}

// Hash function đơn giản (FNV-1a inspired)
func (h *HashMap) hash(key string) int {
    hash := uint32(2166136261)
    for i := 0; i < len(key); i++ {
        hash ^= uint32(key[i])
        hash *= 16777619
    }
    return int(hash % bucketCount)
}

func (h *HashMap) Put(key string, value int) {
    idx := h.hash(key)
    // Kiểm tra key đã tồn tại?
    for e := h.buckets[idx]; e != nil; e = e.next {
        if e.key == key {
            e.value = value // update
            return
        }
    }
    // Insert đầu linked list (prepend)
    h.buckets[idx] = &entry{key, value, h.buckets[idx]}
    h.size++
}

func (h *HashMap) Get(key string) (int, bool) {
    idx := h.hash(key)
    for e := h.buckets[idx]; e != nil; e = e.next {
        if e.key == key {
            return e.value, true
        }
    }
    return 0, false
}

func (h *HashMap) Delete(key string) {
    idx := h.hash(key)
    var prev *entry
    for e := h.buckets[idx]; e != nil; e = e.next {
        if e.key == key {
            if prev == nil {
                h.buckets[idx] = e.next
            } else {
                prev.next = e.next
            }
            h.size--
            return
        }
        prev = e
    }
}

func main() {
    m := &HashMap{}
    m.Put("user:123", 42)
    m.Put("user:456", 99)
    val, ok := m.Get("user:123")
    fmt.Printf("user:123 = %d, exists = %v\n", val, ok) // 42, true

    // Thiếu gì so với Go map thật?
    // 1. Dynamic resize (grow khi load factor cao)
    // 2. Tophash optimization (compare 1 byte trước khi compare full key)
    // 3. Incremental rehash (không copy hết cùng lúc)
    // 4. Runtime panic cho concurrent access
}
```

### Backend Relevance

```
╔═══════════════════════════════════════════════════════════════╗
║   HASH MAP TRONG BACKEND                                     ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ① Session storage: map[sessionID]UserData                  ║
║  → O(1) lookup per request → microsecond latency            ║
║                                                               ║
║  ② In-memory cache: map[cacheKey]CachedResponse             ║
║  → Tránh query DB lặp lại → giảm 90% DB load              ║
║                                                               ║
║  ③ Rate limiting: map[clientIP]RequestCount                  ║
║  → Đếm requests per second → O(1) check                    ║
║                                                               ║
║  ④ Redis: Hash table là nền tảng!                           ║
║  → GET/SET = hash table lookup = O(1)                       ║
║  → Database 0-15 = 16 hash tables                           ║
║                                                               ║
║  ⑤ Database: Hash index cho exact-match queries             ║
║  → WHERE id = 123 → hash(123) → O(1)                      ║
║  → KHÔNG hỗ trợ: WHERE id > 100 (range query!)            ║
║  → Đó là lý do PostgreSQL default B-Tree, KHÔNG Hash      ║
║                                                               ║
║  ⑥ Load Balancer: Consistent hashing                        ║
║  → Hash request → chọn server → O(1)                       ║
║  → Thêm/bớt server → chỉ remap ~1/n keys                 ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §3. Linked List — Khi Insert/Delete Quan Trọng Hơn Search

### Bài toán gốc: Insert O(1) mà không cần shift

Array insert ở giữa = O(n) vì phải shift. Linked List giải quyết: mỗi node "trỏ" đến node tiếp theo → insert/delete chỉ cần **đổi pointer** → O(1)! Nhưng đánh đổi: **mất random access**.

> **Analogy:** Linked List như một **đoàn tàu hỏa**:
>
> - Mỗi toa (node) chứa hàng hóa (data) + móc nối (pointer) đến toa sau
> - Thêm toa mới ở giữa? **Tháo móc cũ, gắn toa mới, nối lại** → nhanh!
> - Tìm toa thứ 500? Phải **đi từ toa đầu, đếm 1-2-3-...-500** → chậm!

### First Principles — Memory Layout

```
╔═══════════════════════════════════════════════════════════════╗
║   LINKED LIST vs ARRAY — BỘ NHỚ                             ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ARRAY: LIÊN TỤC trong RAM                                  ║
║  ┌────┬────┬────┬────┬────┐                                 ║
║  │ 10 │ 20 │ 30 │ 40 │ 50 │  địa chỉ liền nhau            ║
║  └────┴────┴────┴────┴────┘                                 ║
║  0x100 0x108 0x110 0x118 0x120                                ║
║  → CPU cache line = 64B → load tất cả cùng lúc!           ║
║                                                               ║
║  LINKED LIST: PHÂN TÁN trong RAM                            ║
║  ┌──────────┐    ┌──────────┐    ┌──────────┐               ║
║  │ data: 10 │    │ data: 20 │    │ data: 30 │               ║
║  │ next:  ──┼───►│ next:  ──┼───►│ next: nil│               ║
║  └──────────┘    └──────────┘    └──────────┘               ║
║  0x100            0x7F00          0x3A00                      ║
║  → Mỗi node ở vị trí NGẪU NHIÊN → cache miss liên tục!  ║
║                                                               ║
║  OVERHEAD per node:                                          ║
║  → Singly: data + 1 pointer (8B) = +8 bytes overhead       ║
║  → Doubly: data + 2 pointers (16B) = +16 bytes overhead    ║
║  → Với int (8B): doubly linked list dùng 24B/node          ║
║    vs array 8B/element → 3× memory!                         ║
║                                                               ║
║  ─────────────────────────────────────────────────────────    ║
║                                                               ║
║  INSERT Ở GIỮA (sau node P):                                ║
║                                                               ║
║  Array: shift tất cả phần tử sau → O(n)                    ║
║  [10][20][30][40] → insert 25 sau 20:                       ║
║  [10][20][ ][ ][ ] → shift 30,40 → [10][20][25][30][40]   ║
║                                                               ║
║  Linked List: đổi 2 pointers → O(1)                        ║
║  Before: [10]→[20]→[30]→[40]                               ║
║  After:  [10]→[20]→[25]→[30]→[40]                          ║
║          Change: 20.next = new(25), 25.next = 30            ║
║  → NHƯNG: tìm vị trí insert = O(n)!                       ║
║  → Tổng: O(n) search + O(1) insert = O(n)                  ║
║  → Chỉ O(1) nếu ĐÃ CÓ pointer đến node insert!          ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### Go Implementation — container/list

```go
package main

import (
    "container/list"
    "fmt"
)

func main() {
    // Go standard library: doubly linked list
    l := list.New()

    // Push: O(1)
    l.PushBack("A")                // [A]
    l.PushBack("B")                // [A, B]
    l.PushFront("Z")               // [Z, A, B]
    e := l.PushBack("C")           // [Z, A, B, C]

    // Insert: O(1) khi đã có reference đến element
    l.InsertBefore("X", e)         // [Z, A, B, X, C]

    // Remove: O(1)
    l.Remove(e)                     // [Z, A, B, X]

    // Iterate: O(n) — phải duyệt từ đầu
    for e := l.Front(); e != nil; e = e.Next() {
        fmt.Print(e.Value, " ")
    }
    // Output: Z A B X

    // ⚠️ container/list dùng interface{} → type assertion cần thiết
    // → Kể từ Go 1.18+, bạn nên tự implement generic linked list
}

// Generic Linked List (Go 1.18+)
type Node[T any] struct {
    Data T
    Next *Node[T]
}

type LinkedList[T any] struct {
    Head *Node[T]
    Size int
}

func (l *LinkedList[T]) Prepend(data T) {
    l.Head = &Node[T]{Data: data, Next: l.Head}
    l.Size++
}

func (l *LinkedList[T]) Find(pred func(T) bool) *Node[T] {
    for n := l.Head; n != nil; n = n.Next {
        if pred(n.Data) {
            return n
        }
    }
    return nil // O(n)
}
```

### 5 Whys: Linked List

```
╔═══════════════════════════════════════════════════════════════╗
║   5 WHYS: LINKED LIST                                        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  WHY 1: Tại sao linked list insert O(1)?                    ║
║  → Vì chỉ cần thay đổi 1-2 pointers, không shift data     ║
║                                                               ║
║  WHY 2: Tại sao chậm hơn array trong thực tế?              ║
║  → Vì nodes phân tán trong RAM → cache miss mỗi node!     ║
║  → Array: cache hit 95%, list: cache hit <20%               ║
║                                                               ║
║  WHY 3: Tại sao vẫn tồn tại nếu array tốt hơn?            ║
║  → Vì có những use cases cần insert/delete O(1) THẬT:      ║
║  → LRU cache: move-to-front = đổi pointer                  ║
║  → OS scheduler: process queue insert/remove               ║
║                                                               ║
║  WHY 4: Tại sao Go dùng slice nhiều hơn linked list?       ║
║  → Vì hardware hiện đại ưu tiên cache locality             ║
║  → Slice shift O(n) nhưng với cache = NHANH thực tế       ║
║  → Linked list O(1) nhưng cache miss = CHẬM thực tế      ║
║                                                               ║
║  WHY 5: Khi nào linked list THẮNG?                          ║
║  → Khi cần insert/remove Ở CHÍNH GIỮA CỰC NHANH          ║
║  → VÀ đã có pointer đến node đó (không cần search!)       ║
║  → Ví dụ: LRU cache, timer wheels, OS process queues       ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### Trade-off Analysis

| Tiêu chí                      | Linked List       | Array/Slice            |
| ----------------------------- | ----------------- | ---------------------- |
| Access by index               | O(n) ❌           | O(1) ★★★★★             |
| Insert at head                | O(1) ★★★★★        | O(n)                   |
| Insert at middle (có pointer) | O(1)              | O(n)                   |
| Delete (có pointer)           | O(1) ★★★★★        | O(n)                   |
| Search                        | O(n)              | O(n) / O(log n) sorted |
| Cache locality                | ❌ Rất kém        | ★★★★★ Cực tốt          |
| Memory per element            | 24-32 bytes       | 8 bytes (int64)        |
| **Khi nào thắng**             | LRU cache, queues | Hầu hết mọi trường hợp |

### Backend Relevance

```
╔═══════════════════════════════════════════════════════════════╗
║   LINKED LIST TRONG BACKEND                                  ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ① LRU Cache (Redis, Memcached):                            ║
║  → Doubly linked list + hash map                             ║
║  → Access key → move node to front (O(1)!)                  ║
║  → Cache full → remove last node (O(1)!)                    ║
║  → Hash map: key → node pointer (O(1) lookup)              ║
║                                                               ║
║  ② Go runtime: goroutine run queues                         ║
║  → Mỗi P có local run queue = linked list of goroutines    ║
║  → Push/pop goroutines = O(1)                               ║
║                                                               ║
║  ③ Linux kernel:                                             ║
║  → Process list, timer list, I/O request queue              ║
║  → Tất cả dùng doubly linked list (list_head struct)       ║
║                                                               ║
║  ④ Memory allocators:                                        ║
║  → Free list: linked list of free memory blocks             ║
║  → malloc() → tìm block đủ lớn trong free list            ║
║                                                               ║
║  KẾT LUẬN: Linked list HIẾM KHI dùng trực tiếp. Nhưng    ║
║  nó XUẤT HIỆN bên trong các cấu trúc khác:                 ║
║  Hash Map (chaining), LRU Cache, OS internals, allocators   ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §4. Stack & Queue — Hai Anh Em LIFO/FIFO

### Bài toán gốc: Thứ tự xử lý

Nhiều bài toán backend yêu cầu xử lý data theo **thứ tự cụ thể**:

- **Stack (LIFO)**: Ai đến SAU được xử lý TRƯỚC — như chồng đĩa, undo/redo, function call stack
- **Queue (FIFO)**: Ai đến TRƯỚC được xử lý TRƯỚC — như hàng đợi, message queue, BFS

> **Analogy:**
>
> - **Stack** = Chồng đĩa trong nhà hàng: đặt đĩa lên trên cùng (push), lấy đĩa trên cùng ra (pop)
> - **Queue** = Hàng người xếp hàng mua vé: người đến trước mua trước, người đến sau đứng cuối

### First Principles — Stack & Queue bằng Slice

```go
// ═══════════════════════════════════════════════
// STACK — Last In, First Out (LIFO)
// ═══════════════════════════════════════════════

type Stack[T any] struct {
    data []T
}

func (s *Stack[T]) Push(val T) {
    s.data = append(s.data, val) // O(1) amortized
}

func (s *Stack[T]) Pop() (T, bool) {
    if len(s.data) == 0 {
        var zero T
        return zero, false
    }
    val := s.data[len(s.data)-1]
    s.data = s.data[:len(s.data)-1] // O(1)
    return val, true
}

func (s *Stack[T]) Peek() (T, bool) {
    if len(s.data) == 0 {
        var zero T
        return zero, false
    }
    return s.data[len(s.data)-1], true
}

// ═══════════════════════════════════════════════
// QUEUE — First In, First Out (FIFO)
// ═══════════════════════════════════════════════

type Queue[T any] struct {
    data []T
}

func (q *Queue[T]) Enqueue(val T) {
    q.data = append(q.data, val) // O(1) amortized
}

func (q *Queue[T]) Dequeue() (T, bool) {
    if len(q.data) == 0 {
        var zero T
        return zero, false
    }
    val := q.data[0]
    q.data = q.data[1:] // ⚠️ O(1) nhưng memory leak!
    return val, true
}

// ⚠️ BẪY: q.data = q.data[1:] KHÔNG giải phóng memory!
// underlying array vẫn giữ tất cả elements cũ!
// FIX: dùng Ring Buffer:

type RingQueue[T any] struct {
    data       []T
    head, tail int
    size, cap  int
}

func NewRingQueue[T any](cap int) *RingQueue[T] {
    return &RingQueue[T]{data: make([]T, cap), cap: cap}
}

func (q *RingQueue[T]) Enqueue(val T) bool {
    if q.size == q.cap {
        return false // full
    }
    q.data[q.tail] = val
    q.tail = (q.tail + 1) % q.cap // wrap around!
    q.size++
    return true
}

func (q *RingQueue[T]) Dequeue() (T, bool) {
    if q.size == 0 {
        var zero T
        return zero, false
    }
    val := q.data[q.head]
    q.head = (q.head + 1) % q.cap // wrap around!
    q.size--
    return val, true
}
```

```
╔═══════════════════════════════════════════════════════════════╗
║   RING BUFFER — QUEUE KHÔNG BAO GIỜ REALLOC                ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Capacity = 5, Head=H, Tail=T                               ║
║                                                               ║
║  Ban đầu (rỗng):                                            ║
║  ┌───┬───┬───┬───┬───┐                                     ║
║  │   │   │   │   │   │  H=0, T=0, size=0                   ║
║  └───┴───┴───┴───┴───┘                                     ║
║   HT                                                         ║
║                                                               ║
║  Enqueue A, B, C:                                            ║
║  ┌───┬───┬───┬───┬───┐                                     ║
║  │ A │ B │ C │   │   │  H=0, T=3, size=3                   ║
║  └───┴───┴───┴───┴───┘                                     ║
║   H           T                                               ║
║                                                               ║
║  Dequeue A, B:                                               ║
║  ┌───┬───┬───┬───┬───┐                                     ║
║  │   │   │ C │   │   │  H=2, T=3, size=1                   ║
║  └───┴───┴───┴───┴───┘                                     ║
║           H   T                                               ║
║                                                               ║
║  Enqueue D, E, F (WRAP AROUND!):                             ║
║  ┌───┬───┬───┬───┬───┐                                     ║
║  │ F │   │ C │ D │ E │  H=2, T=1, size=4                   ║
║  └───┴───┴───┴───┴───┘                                     ║
║       T   H                                                   ║
║  → Tail "quay vòng" về đầu array!                          ║
║  → KHÔNG cần shift! KHÔNG cần realloc!                      ║
║  → O(1) enqueue, O(1) dequeue, FIXED memory!               ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 5 Whys: Stack & Queue

```
╔═══════════════════════════════════════════════════════════════╗
║   5 WHYS: STACK & QUEUE                                      ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  WHY 1: Tại sao function call dùng stack (LIFO)?            ║
║  → Vì function gọi cuối phải return TRƯỚC (nested calls)   ║
║  → main() → A() → B() → B returns trước, rồi A, rồi main ║
║                                                               ║
║  WHY 2: Tại sao message queue dùng FIFO?                    ║
║  → Vì ordering quan trọng: event xảy ra trước xử lý trước║
║  → Order created PHẢI trước order payment!                  ║
║                                                               ║
║  WHY 3: Tại sao dùng ring buffer thay linked list queue?    ║
║  → Vì ring buffer = array → cache-friendly                  ║
║  → Linked list node phân tán → cache miss mỗi dequeue     ║
║  → Ring buffer: O(1) dequeue + 0 allocations               ║
║                                                               ║
║  WHY 4: Tại sao Go channel = queue?                         ║
║  → Buffered channel = fixed-size ring buffer!               ║
║  → ch := make(chan T, 100) → ring buffer 100 elements      ║
║  → ch <- val = enqueue, val := <-ch = dequeue              ║
║  → Thread-safe (built-in lock)!                              ║
║                                                               ║
║  WHY 5: Tại sao stack dùng array-based trong Go?            ║
║  → Vì append/pop cuối slice = O(1), không cần linked list  ║
║  → Cache-friendly, zero overhead per element                 ║
║  → Go goroutine stack chính là array (contiguous stack!)    ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### Backend Relevance

```
╔═══════════════════════════════════════════════════════════════╗
║   STACK & QUEUE TRONG BACKEND                                ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ── STACK ──────────────────────────────────────────────      ║
║  ① Goroutine call stack: mỗi function call = 1 frame       ║
║  ② Undo/Redo: stack of operations                           ║
║  ③ Expression parsing: parentheses matching                  ║
║  ④ DFS traversal: explicit stack thay recursion             ║
║                                                               ║
║  ── QUEUE ──────────────────────────────────────────────      ║
║  ① Message Queue (Kafka, RabbitMQ, SQS):                    ║
║     → Producer enqueue → Consumer dequeue                    ║
║     → Ordering guarantee = FIFO                              ║
║                                                               ║
║  ② Go channel (buffered):                                    ║
║     → ch := make(chan Task, 1000)                            ║
║     → Workers dequeue tasks → process → acknowledge        ║
║                                                               ║
║  ③ Rate limiter (token bucket):                             ║
║     → Queue of tokens, refill at fixed rate                  ║
║     → Request arrives → dequeue token → allow/deny         ║
║                                                               ║
║  ④ BFS in graph algorithms:                                  ║
║     → Shortest path, level-order traversal                   ║
║     → Network routing: find shortest path between servers   ║
║                                                               ║
║  ⑤ Task scheduler (Go runtime):                             ║
║     → P's local run queue = ring buffer of goroutines       ║
║     → go func() = enqueue goroutine                          ║
║     → P picks next goroutine = dequeue                       ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §5. Tree — Dữ Liệu Phân Cấp & Tìm Kiếm O(log n)

### Bài toán gốc: Vừa search nhanh, vừa insert/delete nhanh

Array: search nhanh (binary search O(log n)), nhưng insert/delete O(n). Hash Map: insert/delete O(1), nhưng KHÔNG hỗ trợ ordered data, range query. **Tree** kết hợp cả hai: **O(log n) cho tất cả operations** + dữ liệu có thứ tự!

> **Analogy:** BST như **cây phả hệ ngược** (family tree upside down):
>
> - Mỗi người (node) có tối đa 2 con (left, right)
> - Con bên trái luôn **NHỎ HƠN** cha, con bên phải luôn **LỚN HƠN** cha
> - Tìm một người? Bắt đầu từ gốc, so sánh → rẽ trái hoặc phải → mỗi bước loại bỏ NỬA cây!

### First Principles — BST Operations

```
╔═══════════════════════════════════════════════════════════════╗
║   BINARY SEARCH TREE (BST)                                   ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  BST Property: left < parent < right                         ║
║                                                               ║
║           8                                                   ║
║         /   \                                                 ║
║        3     10                                               ║
║       / \      \                                              ║
║      1   6     14                                             ║
║         / \   /                                               ║
║        4   7 13                                               ║
║                                                               ║
║  SEARCH (tìm 6):                                             ║
║  8 → 6<8 → go LEFT → 3                                     ║
║  3 → 6>3 → go RIGHT → 6                                    ║
║  6 → FOUND! (2 bước thay vì scan 8 nodes)                  ║
║  → O(log n) nếu cây BALANCED                               ║
║                                                               ║
║  INSERT (thêm 5):                                            ║
║  8→3→6→4→ 5>4, go RIGHT → insert as right child of 4      ║
║  → O(log n)                                                  ║
║                                                               ║
║  DELETE:                                                      ║
║  → Node lá: xóa trực tiếp                                  ║
║  → Node 1 con: replace bằng con                             ║
║  → Node 2 con: replace bằng successor (smallest in right)   ║
║  → O(log n)                                                  ║
║                                                               ║
║  IN-ORDER TRAVERSAL (duyệt theo thứ tự):                    ║
║  1, 3, 4, 6, 7, 8, 10, 13, 14                               ║
║  → Kết quả ĐÚNG THỨ TỰ! Đây là sức mạnh của BST!        ║
║                                                               ║
║  ─────────────────────────────────────────────────────────    ║
║                                                               ║
║  VẤN ĐỀ: UNBALANCED TREE                                    ║
║  Insert 1, 2, 3, 4, 5 theo thứ tự:                          ║
║  1                                                            ║
║   \                                                           ║
║    2          → Trở thành LINKED LIST!                       ║
║     \         → Search = O(n), không còn O(log n)!          ║
║      3        → FIX: Self-balancing trees                    ║
║       \                                                       ║
║        4                                                      ║
║         \                                                     ║
║          5                                                    ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### Self-Balancing Trees — Giải quyết unbalanced

```
╔═══════════════════════════════════════════════════════════════╗
║   SO SÁNH CÁC LOẠI BALANCED TREE                            ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ┌─────────────┬──────────────────────────────────────┐      ║
║  │ Loại         │ Đặc điểm                            │      ║
║  ├─────────────┼──────────────────────────────────────┤      ║
║  │ AVL Tree    │ Strictly balanced (|height diff|≤1) │      ║
║  │              │ → Search nhanh nhất (thấp nhất)    │      ║
║  │              │ → Insert/delete chậm hơn (rebalance)│      ║
║  │              │ → Dùng khi READ >> WRITE            │      ║
║  ├─────────────┼──────────────────────────────────────┤      ║
║  │ Red-Black   │ Loosely balanced (≤2× height diff)  │      ║
║  │ Tree        │ → Insert/delete ít rotation hơn AVL │      ║
║  │              │ → Go runtime, Java TreeMap, Linux   │      ║
║  │              │ → Dùng khi READ ≈ WRITE            │      ║
║  ├─────────────┼──────────────────────────────────────┤      ║
║  │ B-Tree      │ Multi-way tree (nhiều keys/node)    │      ║
║  │              │ → Tối ưu cho DISK I/O              │      ║
║  │              │ → PostgreSQL, MySQL indexes!        │      ║
║  │              │ → 1 node = 1 disk page (4-16KB)    │      ║
║  ├─────────────┼──────────────────────────────────────┤      ║
║  │ B+Tree      │ B-Tree + leaves linked              │      ║
║  │              │ → Range query CỰC NHANH            │      ║
║  │              │ → ALL data ở leaves → sequential   │      ║
║  │              │ → PostgreSQL, InnoDB default index  │      ║
║  └─────────────┴──────────────────────────────────────┘      ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### B+Tree — Tại sao Database chọn nó?

```
╔═══════════════════════════════════════════════════════════════╗
║   B+TREE — VUA CỦA DATABASE INDEXES                         ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  5 Whys: Tại sao database dùng B+Tree?                      ║
║                                                               ║
║  WHY 1: Tại sao không dùng BST cho database index?          ║
║  → BST: mỗi node = 1 key = 1 disk read                     ║
║  → 1M rows, balanced BST: height = 20                       ║
║  → Search = 20 disk reads! (20 × 5ms = 100ms!)             ║
║                                                               ║
║  WHY 2: Tại sao B+Tree ít disk reads hơn?                  ║
║  → 1 node = 1 page (8KB) = chứa ~500 keys!                ║
║  → 1M rows: height = 3 (500^3 > 1M)                        ║
║  → Search = 3 disk reads! (3 × 5ms = 15ms!)                ║
║                                                               ║
║  WHY 3: Tại sao B+Tree tốt cho range query?                ║
║  → Tất cả data nằm ở leaf nodes                            ║
║  → Leaf nodes LINKED với nhau → sequential scan!           ║
║  → WHERE price BETWEEN 10 AND 50:                           ║
║    Tìm leaf 10 → scan sang phải → dừng khi > 50          ║
║                                                               ║
║            [30]                                               ║
║           /    \                                              ║
║        [10,20]  [40,50]                                      ║
║        / | \    / | \                                         ║
║  L1: [5,8]→[10,15,18]→[20,25]→[30,35]→[40,45]→[50,55]    ║
║  ◄──────── leaves linked list ────────────────────────►     ║
║                                                               ║
║  WHY 4: Tại sao Hash index KHÔNG thay thế B+Tree?          ║
║  → Hash: chỉ exact match (WHERE id = 123)                  ║
║  → B+Tree: exact + range + sort + prefix!                   ║
║  → WHERE name LIKE 'Ngu%' → B+Tree scan!                  ║
║  → ORDER BY created_at → B+Tree đã sorted!                ║
║                                                               ║
║  WHY 5: Tại sao PostgreSQL default B-Tree (thực ra B+Tree)?║
║  → Vì 90% queries cần range/sort → B+Tree tốt nhất       ║
║  → Hash index: chỉ dùng cho equality (hiếm khi cần)       ║
║  → GIN/GiST: cho full-text search, JSONB, geometry         ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

```go
// Go BST implementation
type TreeNode struct {
    Key   int
    Value interface{}
    Left  *TreeNode
    Right *TreeNode
}

func (t *TreeNode) Search(key int) *TreeNode {
    if t == nil || t.Key == key {
        return t
    }
    if key < t.Key {
        return t.Left.Search(key)   // go left
    }
    return t.Right.Search(key)      // go right
}

func (t *TreeNode) Insert(key int, val interface{}) *TreeNode {
    if t == nil {
        return &TreeNode{Key: key, Value: val}
    }
    if key < t.Key {
        t.Left = t.Left.Insert(key, val)
    } else if key > t.Key {
        t.Right = t.Right.Insert(key, val)
    } else {
        t.Value = val // update existing
    }
    return t
}

// In-order traversal → sorted output
func (t *TreeNode) InOrder(visit func(int, interface{})) {
    if t == nil { return }
    t.Left.InOrder(visit)
    visit(t.Key, t.Value)
    t.Right.InOrder(visit)
}
```

### Backend Relevance

```
╔═══════════════════════════════════════════════════════════════╗
║   TREE TRONG BACKEND                                         ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ① Database Indexes (B+Tree):                               ║
║  → PostgreSQL, MySQL, SQLite → B+Tree mặc định            ║
║  → CREATE INDEX idx ON users(email) → B+Tree!              ║
║  → EXPLAIN ANALYZE SELECT * FROM users WHERE email = '...'  ║
║    → "Index Scan using idx" = B+Tree lookup!               ║
║                                                               ║
║  ② Go runtime:                                               ║
║  → Timer heap: treap (tree + heap)                          ║
║  → Goroutine scheduling: treap for timers                   ║
║                                                               ║
║  ③ Linux kernel:                                             ║
║  → CFS scheduler: red-black tree (sort by vruntime)        ║
║  → Memory management: red-black tree (VMAs)                 ║
║                                                               ║
║  ④ File systems:                                             ║
║  → ext4: extent tree (variant of B-Tree)                    ║
║  → XFS: B+Tree cho file allocations                         ║
║  → Btrfs: B-Tree cho everything (copy-on-write)            ║
║                                                               ║
║  ⑤ Trie (prefix tree):                                      ║
║  → Autocomplete: search "ngu" → ["nguyen", "nguoi"...]    ║
║  → DNS routing: domain name lookup                           ║
║  → IP routing: longest prefix match                         ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §6. Heap / Priority Queue — Ai Quan Trọng Nhất?

### Bài toán gốc: Luôn lấy phần tử MIN/MAX nhanh nhất

Trong backend, thường cần: "task nào deadline sớm nhất?", "request nào priority cao nhất?", "goroutine nào timer hết hạn sớm nhất?". Sorted array: insert O(n). BST: O(log n) nhưng phức tạp. **Heap**: O(log n) insert, O(1) peek min/max, đơn giản hơn BST!

> **Analogy:** Min-Heap như **phòng cấp cứu bệnh viện**:
>
> - Bệnh nhân đến → xếp theo **mức độ nghiêm trọng** (priority), không theo thứ tự đến
> - Bác sĩ luôn khám người **nghiêm trọng nhất** trước (peek min = O(1)!)
> - Bệnh nhân mới → xếp vào đúng vị trí (insert = O(log n))

### First Principles

```
╔═══════════════════════════════════════════════════════════════╗
║   HEAP — COMPLETE BINARY TREE + HEAP PROPERTY               ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Min-Heap: parent ≤ children (root = MIN)                   ║
║                                                               ║
║           1          ← root = minimum!                       ║
║         /   \                                                 ║
║        3     5                                                ║
║       / \   /                                                 ║
║      7   8 9                                                  ║
║                                                               ║
║  LƯU TRỮ: ARRAY! (không cần pointers!)                     ║
║  Index:  [0] [1] [2] [3] [4] [5]                             ║
║  Value:  [ 1] [3] [5] [7] [8] [9]                            ║
║                                                               ║
║  Parent of i    = (i-1) / 2                                  ║
║  Left child of i  = 2*i + 1                                  ║
║  Right child of i = 2*i + 2                                  ║
║                                                               ║
║  → KHÔNG CẦN POINTER! Chỉ cần phép tính index!            ║
║  → Array-based → cache-friendly!                            ║
║                                                               ║
║  INSERT (push 2):                                            ║
║  ① Append cuối array: [1,3,5,7,8,9,2]                      ║
║  ② "Bubble up": 2<5 → swap → 2<1? NO → done              ║
║     [1,3,2,7,8,9,5]                                         ║
║  → O(log n)                                                  ║
║                                                               ║
║  EXTRACT MIN (pop root):                                     ║
║  ① Swap root với cuối: [9,3,2,7,8,1] → remove last         ║
║  ② "Bubble down" 9: 9>2 → swap → 9>5 → swap → done      ║
║     [2,3,5,7,8,9]                                            ║
║  → O(log n)                                                  ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### Go Implementation — container/heap

```go
package main

import (
    "container/heap"
    "fmt"
)

// Go heap.Interface: 5 methods
type MinHeap []int

func (h MinHeap) Len() int           { return len(h) }
func (h MinHeap) Less(i, j int) bool { return h[i] < h[j] } // Min-Heap
func (h MinHeap) Swap(i, j int)      { h[i], h[j] = h[j], h[i] }
func (h *MinHeap) Push(x interface{}) { *h = append(*h, x.(int)) }
func (h *MinHeap) Pop() interface{} {
    old := *h
    n := len(old)
    x := old[n-1]
    *h = old[:n-1]
    return x
}

func main() {
    h := &MinHeap{5, 3, 8, 1, 9}
    heap.Init(h)                    // O(n) — heapify!

    heap.Push(h, 2)                 // O(log n)
    fmt.Println((*h)[0])            // 1 — peek min O(1)!

    min := heap.Pop(h)              // O(log n)
    fmt.Println(min)                // 1 — extract min
}

// Production example: Task scheduler
type Task struct {
    Name     string
    Priority int // lower = higher priority
    Deadline time.Time
}

type TaskQueue []*Task

func (t TaskQueue) Less(i, j int) bool {
    return t[i].Deadline.Before(t[j].Deadline) // earliest deadline first
}
// ... implement other 4 methods
```

### 5 Whys: Heap

```
╔═══════════════════════════════════════════════════════════════╗
║   5 WHYS: HEAP                                               ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  WHY 1: Tại sao không dùng sorted array?                    ║
║  → Insert sorted array = O(n) (shift elements)              ║
║  → Heap insert = O(log n) (bubble up)                       ║
║                                                               ║
║  WHY 2: Tại sao heap dùng array thay vì tree pointers?     ║
║  → Vì complete binary tree → index tính được!              ║
║  → Array: cache-friendly + ít memory (không cần pointers)  ║
║                                                               ║
║  WHY 3: Tại sao Go timer dùng heap?                         ║
║  → time.After(), time.Ticker → timer heap                   ║
║  → 1M timers → tìm timer sắp hết hạn = O(1)!            ║
║  → Add/remove timer = O(log n)                              ║
║                                                               ║
║  WHY 4: Tại sao không dùng BST?                             ║
║  → Heap đơn giản hơn (không cần rebalance!)               ║
║  → Heap = array → ít allocation, cache-friendly            ║
║  → BST tốt hơn nếu cần: search, range query, iteration    ║
║                                                               ║
║  WHY 5: Khi nào heap THẤT BẠI?                              ║
║  → Search arbitrary element = O(n)! (phải scan toàn bộ)    ║
║  → Delete arbitrary element = O(n) (phải tìm trước)        ║
║  → Không hỗ trợ range query                                ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### Backend Relevance

```
╔═══════════════════════════════════════════════════════════════╗
║   HEAP TRONG BACKEND                                         ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ① Go runtime timer heap:                                   ║
║  → time.After(5*time.Second) → push vào timer heap         ║
║  → Runtime check min → timer hết hạn? → fire callback     ║
║                                                               ║
║  ② Task scheduling (priority queue):                        ║
║  → Kubernetes scheduler: pod priority → heap               ║
║  → Job queue: high-priority jobs processed first            ║
║                                                               ║
║  ③ Dijkstra's algorithm:                                    ║
║  → Shortest path in graphs = min-heap!                      ║
║  → Network routing: find shortest path between servers     ║
║                                                               ║
║  ④ Top-K problems:                                          ║
║  → "Top 10 most active users": min-heap of size 10         ║
║  → Stream 1M events → keep heap of 10 → O(n log k)       ║
║                                                               ║
║  ⑤ Merge K sorted streams:                                  ║
║  → Database: merge sort external → min-heap of K heads     ║
║  → Kafka: consume K partitions ordered → heap merge        ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §7. Graph — Mạng Lưới Kết Nối

### Bài toán gốc: Dữ liệu có QUAN HỆ NHIỀU-NHIỀU

Tree chỉ có 1 parent. Thực tế: user follow nhiều users (social), server kết nối nhiều servers (network), task phụ thuộc nhiều tasks (CI/CD). **Graph** = tập đỉnh (vertices) + cạnh (edges) → mô hình hóa MỌI loại quan hệ.

### First Principles — Representation

```
╔═══════════════════════════════════════════════════════════════╗
║   GRAPH — HAI CÁCH LƯU TRỮ                                 ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Graph example:  0 ── 1                                      ║
║                  |  / |                                       ║
║                  | /  |                                       ║
║                  2 ── 3                                       ║
║                                                               ║
║  1. ADJACENCY MATRIX (Ma trận kề):                          ║
║     0  1  2  3                                               ║
║  0 [0, 1, 1, 0]   → Space: O(V²)                           ║
║  1 [1, 0, 1, 1]   → Check edge(u,v): O(1)                  ║
║  2 [1, 1, 0, 1]   → All neighbors: O(V)                    ║
║  3 [0, 1, 1, 0]   → Tốt cho: dense graph (nhiều edges)    ║
║                                                               ║
║  2. ADJACENCY LIST (Danh sách kề):                          ║
║  0: [1, 2]         → Space: O(V + E)                        ║
║  1: [0, 2, 3]      → Check edge: O(degree)                  ║
║  2: [0, 1, 3]      → All neighbors: O(degree) — NHANH!    ║
║  3: [1, 2]          → Tốt cho: sparse graph (ít edges)     ║
║                                                               ║
║  Backend hầu hết dùng ADJACENCY LIST:                       ║
║  → Vì real-world graphs thường sparse                       ║
║  → Social: 1B users nhưng mỗi user ~500 friends            ║
║  → O(V²) = 10^18 → KHÔNG khả thi!                         ║
║  → O(V + E) = 10^9 + 500×10^9 → OK!                      ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### BFS & DFS — Hai cách duyệt graph

```go
package main

import "fmt"

type Graph struct {
    adj map[int][]int
}

func NewGraph() *Graph {
    return &Graph{adj: make(map[int][]int)}
}

func (g *Graph) AddEdge(u, v int) {
    g.adj[u] = append(g.adj[u], v)
    g.adj[v] = append(g.adj[v], u)
}

// BFS — Breadth First Search (dùng QUEUE)
// → Tìm đường NGẮN NHẤT (unweighted graph)
// → Level-order traversal
func (g *Graph) BFS(start int) []int {
    visited := make(map[int]bool)
    queue := []int{start}
    visited[start] = true
    var order []int

    for len(queue) > 0 {
        node := queue[0]
        queue = queue[1:]       // dequeue
        order = append(order, node)

        for _, neighbor := range g.adj[node] {
            if !visited[neighbor] {
                visited[neighbor] = true
                queue = append(queue, neighbor) // enqueue
            }
        }
    }
    return order // BFS order: level by level
}

// DFS — Depth First Search (dùng STACK / recursion)
// → Tìm connected components, cycle detection
// → Topological sort (DAG)
func (g *Graph) DFS(start int) []int {
    visited := make(map[int]bool)
    var order []int

    var dfs func(int)
    dfs = func(node int) {
        visited[node] = true
        order = append(order, node)
        for _, neighbor := range g.adj[node] {
            if !visited[neighbor] {
                dfs(neighbor)       // recursive = implicit stack
            }
        }
    }

    dfs(start)
    return order // DFS order: depth first
}

// Topological Sort (DAG — Directed Acyclic Graph)
// → Task dependencies, build systems, CI/CD pipelines
func TopologicalSort(numNodes int, edges [][2]int) []int {
    adj := make(map[int][]int)
    inDegree := make([]int, numNodes)

    for _, e := range edges {
        adj[e[0]] = append(adj[e[0]], e[1])
        inDegree[e[1]]++
    }

    // Kahn's algorithm (BFS-based)
    var queue []int
    for i := 0; i < numNodes; i++ {
        if inDegree[i] == 0 {
            queue = append(queue, i)
        }
    }

    var result []int
    for len(queue) > 0 {
        node := queue[0]
        queue = queue[1:]
        result = append(result, node)

        for _, neighbor := range adj[node] {
            inDegree[neighbor]--
            if inDegree[neighbor] == 0 {
                queue = append(queue, neighbor)
            }
        }
    }
    return result // topological order
}
```

### Backend Relevance

```
╔═══════════════════════════════════════════════════════════════╗
║   GRAPH TRONG BACKEND                                        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ① Microservice dependency graph:                           ║
║  → Service A → B → C: topological sort cho deploy order    ║
║  → Cycle detection: circular dependency = BUG!              ║
║                                                               ║
║  ② CI/CD pipeline:                                           ║
║  → Build → Test → Deploy: DAG + topological sort           ║
║  → GitHub Actions, GitLab CI = DAG execution                ║
║                                                               ║
║  ③ Social networks:                                          ║
║  → Friends-of-friends: BFS depth=2                           ║
║  → Mutual friends: intersection of adjacency lists          ║
║  → Recommendations: graph algorithms (PageRank, etc.)       ║
║                                                               ║
║  ④ Network routing:                                          ║
║  → Dijkstra: shortest path between servers                   ║
║  → BGP: internet routing = graph of AS (autonomous systems)║
║                                                               ║
║  ⑤ Database:                                                 ║
║  → Query execution plan = DAG of operations                 ║
║  → Foreign key relationships = graph                         ║
║  → Deadlock detection: cycle in wait-for graph!             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §8. Advanced Data Structures — Senior Level

### 8.1 Bloom Filter — Kiểm tra "CHẮC CHẮN KHÔNG CÓ" trong O(1)

```
╔═══════════════════════════════════════════════════════════════╗
║   BLOOM FILTER — XÁC SUẤT NHƯNG CỰC NHANH                 ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Trả lời: "Element có TRONG tập không?"                     ║
║  → "CHẮC CHẮN KHÔNG" (100% chính xác)                      ║
║  → "CÓ THỂ CÓ" (có xác suất false positive!)              ║
║                                                               ║
║  Cơ chế: Bit array + k hash functions                       ║
║                                                               ║
║  Insert "hello":                                             ║
║  h1("hello") = 2, h2("hello") = 5, h3("hello") = 8        ║
║  [0,0,1,0,0,1,0,0,1,0]  ← set bits 2, 5, 8                ║
║                                                               ║
║  Check "world":                                              ║
║  h1("world") = 1, h2("world") = 5, h3("world") = 9        ║
║  bit[1]=0 → CHẮC CHẮN KHÔNG CÓ! (dừng ngay)              ║
║                                                               ║
║  Check "test":                                               ║
║  h1("test") = 2, h2("test") = 5, h3("test") = 8           ║
║  bits 2,5,8 đều = 1 → "CÓ THỂ CÓ" (false positive!)      ║
║                                                               ║
║  Backend use cases:                                          ║
║  → Redis: check key exists trước khi query disk            ║
║  → CDN: check URL đã cache chưa                            ║
║  → Database: check row exists trước full disk scan          ║
║  → Spam filter: check email đã nhận chưa                   ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 8.2 Skip List — Redis Sorted Set dùng cái gì?

```
╔═══════════════════════════════════════════════════════════════╗
║   SKIP LIST — LINKED LIST + "ĐƯỜNG CAO TỐC"                ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Linked List: search O(n) — phải duyệt từng node           ║
║  Skip List: thêm "express lanes" → search O(log n)!        ║
║                                                               ║
║  Level 3: ─────────── 1 ──────────────────── 9 ──► nil     ║
║  Level 2: ───── 1 ────────── 4 ────────── 9 ──► nil        ║
║  Level 1: ── 1 ── 2 ── 4 ── 5 ── 7 ── 9 ──► nil           ║
║                                                               ║
║  Search 7:                                                   ║
║  L3: 1 → 9 (7<9, go down)                                  ║
║  L2: 1 → 4 → 9 (7<9, go down)                              ║
║  L1: 4 → 5 → 7 → FOUND!                                    ║
║  → Chỉ 5 comparisons thay vì 6 (skip L3, L2!)             ║
║                                                               ║
║  Tại sao Redis dùng Skip List thay Red-Black Tree?          ║
║  → Đơn giản hơn (dễ implement, debug, maintain)            ║
║  → Range query tự nhiên (follow level 1 links)              ║
║  → Concurrent-friendly hơn RB-Tree                          ║
║  → Memory tương đương (~2 pointers/node average)           ║
║                                                               ║
║  Redis ZRANGEBYSCORE: scan skip list level 1 → O(log n + k)║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 8.3 Consistent Hashing — Distributed Systems

```
╔═══════════════════════════════════════════════════════════════╗
║   CONSISTENT HASHING — PHÂN TẢI KHI SERVER THAY ĐỔI        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Vấn đề: hash(key) % N servers. Thêm 1 server → N+1       ║
║  → TOÀN BỘ keys bị remap! (cache miss hàng loạt!)         ║
║                                                               ║
║  Giải pháp: Hash ring (vòng tròn 0 → 2^32)                ║
║                                                               ║
║         S1(pos=100)                                          ║
║        /           \                                          ║
║       /    key1(90)  \                                        ║
║      /     ↗          \                                       ║
║  S3(pos=300)     S2(pos=200)                                 ║
║                                                               ║
║  key đi theo chiều kim đồng hồ → server gần nhất:         ║
║  hash("key1") = 90 → gần S1(100) nhất → đi đến S1!       ║
║                                                               ║
║  Thêm S4(pos=150):                                          ║
║  → Chỉ keys 101-150 bị remap từ S2 sang S4!               ║
║  → ~1/N keys bị ảnh hưởng, KHÔNG phải tất cả!            ║
║                                                               ║
║  Virtual nodes: mỗi server = nhiều điểm trên ring          ║
║  → Phân bố đều hơn, tránh hotspots                         ║
║                                                               ║
║  AI dùng: Cassandra, DynamoDB, Redis Cluster                 ║
║  → Memcached, CDN (Akamai), load balancers                  ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §9. Core Algorithms — Giải Thuật Cốt Lõi

### 9.1 Big-O Notation — Ngôn ngữ chung

```
╔═══════════════════════════════════════════════════════════════╗
║   BIG-O — ĐO LƯỜNG HIỆU SUẤT                               ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  N = 1,000,000 (1M elements):                               ║
║                                                               ║
║  O(1)       │ 1 op          │ Hash lookup    │ instant     ║
║  O(log n)   │ 20 ops        │ Binary search  │ instant     ║
║  O(n)       │ 1M ops        │ Linear scan    │ ~1ms        ║
║  O(n log n) │ 20M ops       │ Merge sort     │ ~20ms       ║
║  O(n²)      │ 10^12 ops     │ Bubble sort    │ ~17 minutes ║
║  O(2^n)     │ 10^301,029 ops│ Brute force    │ ∞           ║
║                                                               ║
║  BACKEND RULE OF THUMB:                                      ║
║  → O(1), O(log n): mọi request → OK                       ║
║  → O(n): batch job → OK. Per request → cẩn thận n lớn    ║
║  → O(n log n): sort → acceptable                            ║
║  → O(n²): TRÁNH cho production! Debug red flag!             ║
║                                                               ║
║  AMORTIZED: "Trung bình qua nhiều operations"               ║
║  → Slice append: mostly O(1), đôi khi O(n) realloc         ║
║  → Average = O(1) amortized                                  ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 9.2 Sorting — Khi nào dùng gì?

```go
import "sort"

// Go sort.Slice: Pattern Defeating Quicksort (pdqsort)
// → Hybrid: quicksort + heapsort + insertion sort
// → Average O(n log n), worst O(n log n) (guaranteed!)
users := []User{...}
sort.Slice(users, func(i, j int) bool {
    return users[i].Age < users[j].Age
})

// sort.SliceStable: Merge sort (stable — giữ thứ tự bằng nhau)
sort.SliceStable(users, func(i, j int) bool {
    return users[i].Name < users[j].Name
})
```

```
╔═══════════════════════════════════════════════════════════════╗
║   SORTING — KHI NÀO DÙNG GÌ?                               ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ┌──────────────┬────────────┬────────┬──────────────┐      ║
║  │ Algorithm    │ Average    │ Stable │ Khi nào dùng │      ║
║  ├──────────────┼────────────┼────────┼──────────────┤      ║
║  │ Quicksort    │ O(n log n) │ ❌     │ General use  │      ║
║  │ Mergesort    │ O(n log n) │ ✅     │ Stable req'd │      ║
║  │ Heapsort     │ O(n log n) │ ❌     │ O(1) space   │      ║
║  │ Tim Sort     │ O(n log n) │ ✅     │ Partially    │      ║
║  │ (Python/Java)│            │        │ sorted data  │      ║
║  │ Counting Sort│ O(n + k)   │ ✅     │ Small range  │      ║
║  │ Radix Sort   │ O(d × n)   │ ✅     │ Fixed-width  │      ║
║  └──────────────┴────────────┴────────┴──────────────┘      ║
║                                                               ║
║  Go dùng pdqsort: hybrid tự chuyển đổi!                    ║
║  → Small array: insertion sort (cache-friendly)              ║
║  → General: quicksort (fast average)                         ║
║  → Worst case: fallback to heapsort (guaranteed n log n)    ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 9.3 Binary Search — O(log n) trên sorted data

```go
// Go standard library
import "sort"

// sort.Search: tìm index nhỏ nhất thỏa điều kiện
idx := sort.Search(len(arr), func(i int) bool {
    return arr[i] >= target
})

// Hoặc Go 1.21+: slices.BinarySearch
import "slices"
idx, found := slices.BinarySearch(arr, target)

// Manual binary search — PHẢI biết implement!
func binarySearch(arr []int, target int) int {
    lo, hi := 0, len(arr)-1
    for lo <= hi {
        mid := lo + (hi-lo)/2  // tránh overflow!
        if arr[mid] == target {
            return mid
        } else if arr[mid] < target {
            lo = mid + 1
        } else {
            hi = mid - 1
        }
    }
    return -1  // not found
}

// Backend use case: binary search trên sorted log files
// → Log files sorted by timestamp
// → Tìm log entry closest to timestamp T
// → Binary search trên file offsets → O(log n) disk reads
```

### 9.4 Two Pointers & Sliding Window

```go
// Two Pointers: two ends moving inward
// → Dùng cho: sorted array problems, palindrome check

// Example: Two Sum (sorted array)
func twoSum(nums []int, target int) [2]int {
    lo, hi := 0, len(nums)-1
    for lo < hi {
        sum := nums[lo] + nums[hi]
        if sum == target {
            return [2]int{lo, hi}
        } else if sum < target {
            lo++  // need bigger sum
        } else {
            hi--  // need smaller sum
        }
    }
    return [2]int{-1, -1}
}

// Sliding Window: fixed/variable window moving right
// → Backend use: rate limiting (requests in last N seconds)

// Example: Max sum subarray of size K
func maxSumWindow(nums []int, k int) int {
    windowSum := 0
    for i := 0; i < k; i++ {
        windowSum += nums[i]
    }
    maxSum := windowSum

    for i := k; i < len(nums); i++ {
        windowSum += nums[i] - nums[i-k]  // slide: add right, remove left
        if windowSum > maxSum {
            maxSum = windowSum
        }
    }
    return maxSum
}
```

---

## Tổng Kết — Bảng So Sánh Toàn Diện

```
╔═══════════════════════════════════════════════════════════════════════════╗
║   CHEAT SHEET — CHỌN DATA STRUCTURE NÀO?                                ║
╠═══════════════════════════════════════════════════════════════════════════╣
║                                                                           ║
║  ┌───────────────┬────────┬────────┬────────┬──────┬──────────────┐     ║
║  │ Structure     │ Search │ Insert │ Delete │ Space│ Use Case     │     ║
║  ├───────────────┼────────┼────────┼────────┼──────┼──────────────┤     ║
║  │ Array/Slice   │ O(n)   │ O(n)   │ O(n)   │ O(n) │ Sequential   │     ║
║  │ Sorted Array  │O(logn) │ O(n)   │ O(n)   │ O(n) │ Static data  │     ║
║  │ Hash Map      │ O(1)*  │ O(1)*  │ O(1)*  │ O(n) │ Key lookup   │     ║
║  │ Linked List   │ O(n)   │ O(1)** │ O(1)** │ O(n) │ LRU, queues  │     ║
║  │ Stack         │  -     │ O(1)   │ O(1)   │ O(n) │ LIFO ops     │     ║
║  │ Queue         │  -     │ O(1)   │ O(1)   │ O(n) │ FIFO ops     │     ║
║  │ BST (balanced)│O(logn) │O(logn) │O(logn) │ O(n) │ Ordered data │     ║
║  │ B+Tree        │O(logn) │O(logn) │O(logn) │ O(n) │ DB indexes   │     ║
║  │ Heap          │ O(n)   │O(logn) │O(logn) │ O(n) │ Priority Q   │     ║
║  │ Bloom Filter  │ O(k)   │ O(k)   │  ❌    │ O(m) │ Membership   │     ║
║  │ Skip List     │O(logn) │O(logn) │O(logn) │ O(n) │ Redis SortSet│     ║
║  └───────────────┴────────┴────────┴────────┴──────┴──────────────┘     ║
║  * = amortized average   ** = with pointer to node                       ║
║                                                                           ║
║  DECISION TREE:                                                          ║
║  ① Cần O(1) lookup by key? → HASH MAP                                  ║
║  ② Cần sorted + range query? → B+TREE / BST                            ║
║  ③ Cần priority/min/max? → HEAP                                         ║
║  ④ Cần FIFO? → QUEUE (ring buffer)                                      ║
║  ⑤ Cần LIFO? → STACK (slice-based)                                      ║
║  ⑥ Cần relationships? → GRAPH                                           ║
║  ⑦ Default? → ARRAY/SLICE (cache-friendly!)                             ║
║                                                                           ║
╚═══════════════════════════════════════════════════════════════════════════╝
```

---

## Tài Liệu Tham Khảo

- [Introduction to Algorithms (CLRS)](https://mitpress.mit.edu/9780262046305/introduction-to-algorithms/) — "Bible" của DSA
- [Grokking Algorithms](https://www.manning.com/books/grokking-algorithms) — DSA trực quan cho người mới
- [Go Data Structures](https://research.swtch.com/godata) — Russ Cox (Go team)
- [The Go Programming Language Specification](https://go.dev/ref/spec) — Slice, Map internals
- [Redis Internals](https://redis.io/docs/reference/internals/) — Skip List, Hash Table
- [Use The Index, Luke!](https://use-the-index-luke.com/) — B-Tree / B+Tree cho Database
- [Designing Data-Intensive Applications](https://dataintensive.net/) — Martin Kleppmann, LSM Tree, B-Tree, Bloom Filter
