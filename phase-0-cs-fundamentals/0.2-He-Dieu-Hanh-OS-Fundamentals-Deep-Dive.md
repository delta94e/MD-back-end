# Hệ Điều Hành (OS Fundamentals) — Deep Dive Từ Kernel Đến Goroutine

> **Tài liệu học dành cho:** Người mới bắt đầu, chuẩn bị trở thành Senior Backend Engineer
> **Chủ đề:** Phase 0.2 — Hệ điều hành (OS Fundamentals)
> **Phương pháp phân tích:** 6 patterns (5 Whys, First Principles, Trade-off Analysis, Mental Mapping, Reverse Engineering, Contextual History)
> **Ngôn ngữ:** Hoàn toàn bằng Tiếng Việt

---

## Mục lục

| #   | Chủ đề                                      | Mô tả                                                                                                                                                |
| --- | ------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- |
| §1  | Process & Thread — Đơn Vị Thực Thi (10 mục) | Process vs Thread, PCB, Context Switch, Fork/Exec, Thread Models, Goroutines vs Threads, GMP Scheduler, Process States, IPC, Zombie/Orphan Processes |
| §2  | CPU Scheduling — Ai Được Chạy Tiếp? (8 mục) | Scheduling Algorithms, Preemptive vs Cooperative, Priority Inversion, Real-time, CFS Linux, Go Scheduler, Starvation, Multi-queue                    |
| §3  | Memory Management — Bộ Nhớ Ảo (10 mục)      | Virtual Memory, Page Table, TLB, Page Fault, Demand Paging, Copy-on-Write, mmap, malloc/free, GC, Go Memory Allocator                                |
| §4  | File System — Mọi Thứ Là File (8 mục)       | Inode, File Descriptor, VFS, ext4/XFS, Journaling, Buffered I/O, Directory Structure, Links                                                          |
| §5  | I/O & System Calls — Cổng Giao Tiếp (8 mục) | Syscall Mechanism, Blocking/Non-blocking, select/poll/epoll, io_uring, Signals, Everything-is-a-File, /proc & /sys, strace                           |
| §6  | Synchronization — Đồng Bộ Hóa (8 mục)       | Race Condition, Mutex, Semaphore, Deadlock, RWLock, Atomic, sync.Map, Go Channel Patterns                                                            |
| §7  | Deep Analysis Patterns (6 mục)              | 5 Whys, First Principles, Trade-off Analysis, Mental Mapping, Reverse Engineering, Contextual History                                                |
| §8  | Tổng Kết & Câu Hỏi Phỏng Vấn Senior         | Ôn tập & thực hành                                                                                                                                   |

---

## §1. Process & Thread — Đơn Vị Thực Thi

### 1.1 Process là gì? — Chương Trình Đang Sống

Khi bạn viết code Go và chạy `go run main.go`, file `.go` trên disk chỉ là **text file** — nó chưa phải process. Process chỉ xuất hiện khi OS **nạp chương trình vào bộ nhớ** và bắt đầu thực thi.

**Sự khác biệt giữa Program và Process** giống như sự khác biệt giữa công thức nấu ăn (nằm trong sách) và việc thực sự nấu ăn (nguyên liệu, bếp, hành động). Một công thức có thể tạo ra nhiều món ăn cùng lúc — tương tự, một program có thể tạo ra nhiều process.

```
╔═══════════════════════════════════════════════════════════════╗
║   PROGRAM vs PROCESS                                         ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  PROGRAM (Passive — nằm trên disk):                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  /usr/bin/nginx                               │             ║
║  │  → Chỉ là file binary (ELF format)           │             ║
║  │  → Chứa: machine code + data + metadata      │             ║
║  │  → KHÔNG chiếm CPU, KHÔNG có state           │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  PROCESS (Active — đang chạy trong RAM):                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  nginx (PID 1234)           nginx (PID 1235) │             ║
║  │  ┌──────────────────┐      ┌────────────────┐│             ║
║  │  │ Code (text)      │      │ Code (shared!) ││             ║
║  │  │ Data (heap+stack)│      │ Data (riêng!)  ││             ║
║  │  │ Open files       │      │ Open files     ││             ║
║  │  │ CPU registers    │      │ CPU registers  ││             ║
║  │  │ PID, PPID        │      │ PID, PPID      ││             ║
║  │  │ Memory map       │      │ Memory map     ││             ║
║  │  └──────────────────┘      └────────────────┘│             ║
║  │                                                │             ║
║  │  → 1 program → nhiều processes!              │             ║
║  │  → Mỗi process: address space RIÊNG          │             ║
║  │  → Process này KHÔNG thể đọc RAM process kia │             ║
║  │    (memory isolation = bảo mật!)              │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

Mỗi process được OS quản lý qua một cấu trúc gọi là **PCB (Process Control Block)** — đây là "hộ chiếu" của process, chứa mọi thông tin OS cần để quản lý nó.

```
╔═══════════════════════════════════════════════════════════════╗
║   PCB — PROCESS CONTROL BLOCK                               ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  struct task_struct {  // Linux kernel                        ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  PID:          1234                           │             ║
║  │  State:        RUNNING / SLEEPING / STOPPED   │             ║
║  │  Priority:     nice value (-20 đến +19)       │             ║
║  │  Parent PID:   1200                           │             ║
║  │                                                │             ║
║  │  CPU Context (saved khi bị tạm dừng):        │             ║
║  │  ├── Program Counter (RIP): 0x401020          │             ║
║  │  ├── Stack Pointer (RSP):   0x7fff8000        │             ║
║  │  ├── General Registers:     RAX, RBX, RCX...  │             ║
║  │  └── Flags Register:        EFLAGS            │             ║
║  │                                                │             ║
║  │  Memory Info:                                  │             ║
║  │  ├── Page Table Base:       CR3 register       │             ║
║  │  ├── Code segment:          0x400000-0x401000  │             ║
║  │  ├── Heap:                  0x600000-0x800000  │             ║
║  │  └── Stack:                 0x7fff0000-0x8000  │             ║
║  │                                                │             ║
║  │  I/O Info:                                     │             ║
║  │  ├── File Descriptor Table: [0,1,2,3,4...]    │             ║
║  │  ├── stdin(0), stdout(1), stderr(2)            │             ║
║  │  └── Open sockets, pipes...                    │             ║
║  │                                                │             ║
║  │  Scheduling Info:                              │             ║
║  │  ├── Time slice remaining: 4ms                 │             ║
║  │  ├── Total CPU time used:  150ms               │             ║
║  │  └── Wait channel:         (nếu đang sleep)   │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  → Linux kernel: mỗi process = 1 struct task_struct          ║
║  → Size: ~6KB trên Linux x86_64                              ║
║  → Kernel quản lý hàng ngàn task_struct đồng thời           ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.2 Process Memory Layout — Bản Đồ Bộ Nhớ

Mỗi process có **address space riêng** — từ góc nhìn của process, nó nghĩ mình sở hữu toàn bộ bộ nhớ. Đây là ảo giác do **Virtual Memory** tạo ra (sẽ nói chi tiết ở §3).

```
╔═══════════════════════════════════════════════════════════════╗
║   PROCESS MEMORY LAYOUT (Linux x86-64)                       ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  High Address (0x7FFF_FFFF_FFFF)                              ║
║  ┌──────────────────────────────────────────────┐             ║
║  │            KERNEL SPACE                       │             ║
║  │        (Process không được truy cập!)        │             ║
║  ├──────────────────────────────────────────────┤             ║
║  │            STACK  ↓                           │             ║
║  │  → Local variables, function call frames     │             ║
║  │  → Grow downward (từ cao xuống thấp)        │             ║
║  │  → Mỗi thread có stack riêng!               │             ║
║  │  → Default: 8MB (Linux), 1MB (Go goroutine   │             ║
║  │    bắt đầu 2KB, grow tự động!)              │             ║
║  │                                                │             ║
║  │         ↓ ↓ ↓  (grows down)                  │             ║
║  │  ┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈  │             ║
║  │         Unmapped region (guard page)         │             ║
║  │  ┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈  │             ║
║  │         ↑ ↑ ↑  (grows up)                    │             ║
║  │                                                │             ║
║  │            HEAP  ↑                            │             ║
║  │  → Dynamic allocation (malloc/new)            │             ║
║  │  → Go: runtime manages via mspan/mcache      │             ║
║  │  → Grow upward (từ thấp lên cao)            │             ║
║  ├──────────────────────────────────────────────┤             ║
║  │            BSS  (Uninitialized data)          │             ║
║  │  → var count int  // = 0, OS cấp zero pages │             ║
║  ├──────────────────────────────────────────────┤             ║
║  │            DATA (Initialized data)            │             ║
║  │  → var name = "hello" // giá trị cụ thể    │             ║
║  ├──────────────────────────────────────────────┤             ║
║  │            TEXT (Code)                         │             ║
║  │  → Machine instructions (read-only!)          │             ║
║  │  → Shared giữa các process chạy cùng binary │             ║
║  └──────────────────────────────────────────────┘             ║
║  Low Address (0x0000_0000_0000)                               ║
║                                                               ║
║  ☞ BACKEND RELEVANCE:                                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Stack overflow = khi stack grow quá mức   │             ║
║  │    → Go: goroutine stack tự grow, không sợ!  │             ║
║  │  • Heap fragmentation = malloc/free lặp lại  │             ║
║  │    → Go: GC + tcmalloc-style allocator       │             ║
║  │  • Memory leak = heap grow mãi không giảm   │             ║
║  │    → Go: pprof heap profile để detect        │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.3 Thread là gì? — Lightweight Process

Thread sinh ra để giải quyết bài toán: **Tôi muốn làm nhiều việc cùng lúc TRONG CÙNG 1 process** (chia sẻ memory, file descriptors, mà không cần IPC phức tạp).

Nếu process là **một văn phòng** (có không gian riêng, bàn ghế, tài liệu), thì thread là **nhân viên** trong văn phòng đó — họ chia sẻ cùng tài liệu, cùng máy in, nhưng mỗi người có bàn làm việc riêng (stack).

```
╔═══════════════════════════════════════════════════════════════╗
║   PROCESS vs THREAD                                          ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  PROCESS A (PID 100)         PROCESS B (PID 200)             ║
║  ┌───────────────────┐       ┌───────────────────┐           ║
║  │ Code   ████████   │       │ Code   ████████   │           ║
║  │ Heap   ████████   │       │ Heap   ████████   │           ║
║  │ Files  [0,1,2,3]  │       │ Files  [0,1,2,5]  │           ║
║  │ Stack  ████████   │       │ Stack  ████████   │           ║
║  └───────────────────┘       └───────────────────┘           ║
║  ↑ Hoàn toàn cách ly ↑       ↑ Hoàn toàn cách ly ↑         ║
║                                                               ║
║  PROCESS C (PID 300) — Multi-threaded:                       ║
║  ┌─────────────────────────────────────────────┐             ║
║  │ Code    ████████████  ← SHARED (read-only)  │             ║
║  │ Heap    ████████████  ← SHARED (read-write) │             ║
║  │ Files   [0,1,2,3,4]  ← SHARED               │             ║
║  │ Globals ████████████  ← SHARED               │             ║
║  │                                               │             ║
║  │ ┌─────────┐ ┌─────────┐ ┌─────────┐         │             ║
║  │ │Thread 1 │ │Thread 2 │ │Thread 3 │         │             ║
║  │ │Stack    │ │Stack    │ │Stack    │         │             ║
║  │ │Registers│ │Registers│ │Registers│         │             ║
║  │ │TID: 301 │ │TID: 302 │ │TID: 303 │         │             ║
║  │ └─────────┘ └─────────┘ └─────────┘         │             ║
║  │  ↑ Riêng ↑   ↑ Riêng ↑   ↑ Riêng ↑          │             ║
║  └─────────────────────────────────────────────┘             ║
║                                                               ║
║  SO SÁNH CHI TIẾT:                                           ║
║  ┌──────────────────┬──────────────┬──────────────┐          ║
║  │ Tiêu chí          │ Process      │ Thread       │          ║
║  ├──────────────────┼──────────────┼──────────────┤          ║
║  │ Address space    │ Riêng biệt  │ Chia sẻ      │          ║
║  │ Tạo mới (fork)  │ ~100μs       │ ~10μs        │          ║
║  │ Context switch   │ ~1-5μs       │ ~0.5-1μs     │          ║
║  │ Memory overhead  │ Nhiều (copy) │ Ít (chỉ stack)│         ║
║  │ Crash isolation  │ Process khác  │ CẢ process   │          ║
║  │                  │ không ảnh    │ chết theo!   │          ║
║  │ Communication    │ IPC (pipe,    │ Shared memory│          ║
║  │                  │ socket, shm) │ (trực tiếp)  │          ║
║  │ Stack size       │ 8MB default  │ 8MB default  │          ║
║  └──────────────────┴──────────────┴──────────────┘          ║
║                                                               ║
║  ⚠️ Cái giá của shared memory:                               ║
║  → Race conditions! Data corruption!                          ║
║  → Cần mutex/lock để đồng bộ (xem §6)                      ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.4 Context Switch — Cái Giá Của Đa Nhiệm

**Context switch** xảy ra khi OS tạm dừng process/thread đang chạy và chuyển sang chạy cái khác. Đây là cơ chế cho phép 1 CPU core "chạy" nhiều process cùng lúc (thực ra là chạy luân phiên rất nhanh).

Tưởng tượng bạn đang đọc sách A, rồi phải chuyển sang sách B: bạn phải **đánh dấu trang** (save state), **cất sách A** (flush cache), **lấy sách B** (load state), **tìm lại trang** (restore context). Tất cả thời gian "chuyển sách" là **overhead thuần** — không ai hoàn thành công việc gì trong khoảng đó.

```
╔═══════════════════════════════════════════════════════════════╗
║   CONTEXT SWITCH — WHAT REALLY HAPPENS                       ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Process A đang chạy → Timer interrupt! → Switch to B       ║
║                                                               ║
║  ┌─────────────────────────────────────────────────┐         ║
║  │ 1. SAVE Process A state:              ~0.5μs   │         ║
║  │    ├── Save tất cả CPU registers (16 GPR)      │         ║
║  │    ├── Save Program Counter (RIP)               │         ║
║  │    ├── Save Stack Pointer (RSP)                 │         ║
║  │    ├── Save FPU/SSE/AVX registers               │         ║
║  │    └── Save vào PCB của Process A              │         ║
║  │                                                   │         ║
║  │ 2. SCHEDULER quyết định:              ~0.2μs   │         ║
║  │    ├── Chọn process nào sẽ chạy tiếp?         │         ║
║  │    └── Dựa trên priority, fairness, timeslice  │         ║
║  │                                                   │         ║
║  │ 3. SWITCH memory context:             ~0.5-2μs  │         ║
║  │    ├── Load Page Table Base (CR3) → Process B   │         ║
║  │    ├── TLB FLUSH! (Translation Lookaside Buffer)│         ║
║  │    │   → TẤT CẢ cached translations mất!      │         ║
║  │    │   → Phải page walk lại: ~100 cycles/miss  │         ║
║  │    └── Thread switch: KHÔNG cần flush TLB!      │         ║
║  │                                                   │         ║
║  │ 4. RESTORE Process B state:           ~0.5μs   │         ║
║  │    ├── Load CPU registers từ PCB của B         │         ║
║  │    ├── Load Program Counter                     │         ║
║  │    └── Resume execution!                        │         ║
║  │                                                   │         ║
║  │ 5. CACHE POLLUTION (hidden cost):     ~5-50μs! │         ║
║  │    ├── L1/L2 cache: data của A vẫn ở đây     │         ║
║  │    │   nhưng B cần data KHÁC → cache miss!     │         ║
║  │    ├── Cache warm-up: phải load data B vào     │         ║
║  │    └── → Đây là chi phí LỚN NHẤT!            │         ║
║  └─────────────────────────────────────────────────┘         ║
║                                                               ║
║  TỔNG CHI PHÍ:                                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Process switch:  ~1-5μs (direct)             │             ║
║  │                 + ~5-50μs (cache pollution)    │             ║
║  │                 = ~10-55μs TOTAL               │             ║
║  │                                                │             ║
║  │  Thread switch:   ~0.5-1μs (direct)           │             ║
║  │                 + ~2-10μs (partial cache hit) │             ║
║  │                 = ~3-11μs TOTAL                │             ║
║  │                                                │             ║
║  │  Goroutine switch: ~0.1-0.3μs!               │             ║
║  │  → Userspace only, không cần kernel!          │             ║
║  │  → Không flush TLB, same address space!       │             ║
║  │  → Cache vẫn warm (cùng process)!            │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ 10,000 context switches/sec = 10K × 50μs = 500ms        ║
║    → CPU mất 50% thời gian chỉ để SWITCH!                  ║
║    → Đây là lý do Go dùng goroutines!                        ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.5 Fork & Exec — Cách Unix Tạo Process

Trên Unix/Linux, tạo process mới LUÔN dùng 2 bước: **fork()** (clone process hiện tại) rồi **exec()** (thay thế bằng chương trình mới). Đây là thiết kế kinh điển của Unix từ 1969.

```
╔═══════════════════════════════════════════════════════════════╗
║   FORK & EXEC                                               ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  FORK — Clone process:                                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Parent (PID 100)        Child (PID 101)      │             ║
║  │  ┌──────────────┐       ┌──────────────┐      │             ║
║  │  │ Code  (shared)│══════│ Code  (shared)│     │             ║
║  │  │ Heap  (CoW)   │······│ Heap  (CoW)   │     │             ║
║  │  │ Stack (copy)  │      │ Stack (copy)  │     │             ║
║  │  │ Files (copy)  │      │ Files (copy)  │     │             ║
║  │  └──────────────┘       └──────────────┘      │             ║
║  │                                                │             ║
║  │  CoW = Copy-on-Write:                          │             ║
║  │  → Ban đầu: child SHARE memory với parent    │             ║
║  │  → Khi child/parent WRITE: OS mới copy page  │             ║
║  │  → Tối ưu: fork() rẻ vì không copy ngay!    │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  FORK + EXEC — Chạy chương trình mới:                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Shell (bash, PID 100):                       │             ║
║  │  $ ./myserver                                  │             ║
║  │                                                │             ║
║  │  Step 1: fork()                                │             ║
║  │  ┌──────┐           ┌──────┐                   │             ║
║  │  │bash  │──fork()──►│bash  │ (child, PID 101) │             ║
║  │  │PID100│           │PID101│ (bản sao bash!)  │             ║
║  │  └──────┘           └──┬───┘                   │             ║
║  │                        │                        │             ║
║  │  Step 2: exec("./myserver")                    │             ║
║  │                        │                        │             ║
║  │                        ▼                        │             ║
║  │                   ┌──────────┐                  │             ║
║  │                   │myserver  │ (thay thế bash) │             ║
║  │                   │PID101    │ (PID giữ nguyên)│             ║
║  │                   └──────────┘                  │             ║
║  │                                                │             ║
║  │  Step 3: bash (parent) gọi wait()             │             ║
║  │  → Chờ myserver kết thúc                      │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ Go KHÔNG dùng fork/exec kiểu này:                        ║
║  → os/exec.Command() internally dùng clone() trên Linux    ║
║  → Goroutines KHÔNG phải process, KHÔNG fork!               ║
║  → Nhưng Docker containers fork+exec rất nhiều!             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.6 Process States — Vòng Đời Của Process

Process không phải lúc nào cũng chạy. Nó có nhiều trạng thái khác nhau, và hiểu các trạng thái này giải thích tại sao server đôi khi "nặng" dù CPU usage thấp (nhiều process ở trạng thái Waiting).

```
╔═══════════════════════════════════════════════════════════════╗
║   PROCESS STATE MACHINE                                      ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║                     ┌──────────┐                              ║
║            fork()──►│  CREATED │                              ║
║                     └────┬─────┘                              ║
║                          │ admitted                           ║
║                          ▼                                    ║
║                     ┌──────────┐  scheduler  ┌──────────┐    ║
║              ┌─────►│  READY   │────────────►│ RUNNING  │    ║
║              │      └──────────┘  dispatch   └─────┬────┘    ║
║              │           ▲                         │  │       ║
║              │           │ preempt (timer IRQ)     │  │       ║
║              │           └─────────────────────────┘  │       ║
║              │                                        │       ║
║              │  I/O done                   I/O wait   │       ║
║              │  / signal                   / sleep     │       ║
║              │                                        │       ║
║              │      ┌──────────┐                      │       ║
║              └──────│ WAITING  │◄─────────────────────┘       ║
║                     │(Blocked) │                              ║
║                     └──────────┘                              ║
║                          │                                    ║
║                          │                                    ║
║                     ┌──────────┐                              ║
║     (parent wait())│TERMINATED│◄── exit() / signal            ║
║              ┌─────│ (Zombie) │                               ║
║              │     └──────────┘                               ║
║              ▼                                                ║
║         [Reaped — resources freed]                            ║
║                                                               ║
║  LINUX-SPECIFIC STATES:                                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  R  Running/Runnable (đang hoặc sẵn sàng)   │             ║
║  │  S  Sleeping (interruptible — chờ I/O)       │             ║
║  │  D  Disk sleep (uninterruptible — chờ disk) │             ║
║  │     → KHÔNG THỂ kill! → "D state" bug       │             ║
║  │  T  Stopped (SIGSTOP / debugger)              │             ║
║  │  Z  Zombie (exited, chờ parent wait())       │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ BACKEND RELEVANCE:                                         ║
║  → ps aux: nhiều process "S" = I/O-bound (bình thường)     ║
║  → ps aux: nhiều process "D" = disk/NFS bottleneck! ⚠️      ║
║  → ps aux: nhiều "Z" = parent không wait() → bug!          ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.7 Goroutine vs Thread vs Process — So Sánh Toàn Diện

Đây là **phần quan trọng nhất** cho Go backend engineer. Hiểu sự khác biệt giải thích tại sao Go handle 100K concurrent connections dễ dàng trong khi Java truyền thống gặp khó.

```
╔═══════════════════════════════════════════════════════════════╗
║   GOROUTINE vs THREAD vs PROCESS                             ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ┌──────────────┬──────────┬──────────┬──────────────┐       ║
║  │ Tiêu chí      │ Process  │ Thread   │ Goroutine    │       ║
║  ├──────────────┼──────────┼──────────┼──────────────┤       ║
║  │ Quản lý bởi  │ OS       │ OS       │ Go runtime   │       ║
║  │ Stack size   │ 8MB      │ 1-8MB    │ 2KB (grow!)  │       ║
║  │ Tạo mới      │ ~100μs   │ ~10μs    │ ~0.3μs       │       ║
║  │ Switch cost  │ ~50μs    │ ~10μs    │ ~0.2μs       │       ║
║  │ Memory/unit  │ ~10MB    │ ~1MB     │ ~2KB         │       ║
║  │ Max practical│ ~1K      │ ~10K     │ ~1M          │       ║
║  │ Scheduling   │ Kernel   │ Kernel   │ Userspace    │       ║
║  │ Isolation    │ Full     │ Partial  │ None (same   │       ║
║  │              │          │          │ address)     │       ║
║  │ Crash impact │ Only self│ Entire   │ Entire       │       ║
║  │              │          │ process  │ process      │       ║
║  └──────────────┴──────────┴──────────┴──────────────┘       ║
║                                                               ║
║  TRỰC QUAN HÓA - 10K concurrent connections:                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Apache (1 process/conn):                     │             ║
║  │  10K × 10MB = 100GB RAM ← KHÔNG KHẢ THI!    │             ║
║  │                                                │             ║
║  │  Java Tomcat (1 thread/conn):                 │             ║
║  │  10K × 1MB = 10GB RAM ← Nặng nhưng khả thi  │             ║
║  │  10K context switches/s = vấn đề!            │             ║
║  │                                                │             ║
║  │  Go (1 goroutine/conn):                       │             ║
║  │  10K × 2KB = 20MB RAM ← DƯ SỨC!             │             ║
║  │  Switch: userspace, microseconds              │             ║
║  │  Thậm chí 100K goroutines = 200MB → OK!      │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.8 GMP Model — Go Runtime Scheduler

Go scheduler là trái tim của concurrency trong Go. Nó implement **M:N threading** — map M goroutines lên N OS threads, kết hợp ưu điểm của cả hai thế giới.

```
╔═══════════════════════════════════════════════════════════════╗
║   GMP MODEL — GO RUNTIME SCHEDULER                          ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  G = Goroutine (đơn vị work)                                ║
║  M = Machine  (OS thread thật)                              ║
║  P = Processor (logical processor, = GOMAXPROCS)            ║
║                                                               ║
║  ┌──────────────────────────────────────────────────┐        ║
║  │                                                    │        ║
║  │  P0 (Local Queue)     P1 (Local Queue)            │        ║
║  │  ┌─────────────┐     ┌─────────────┐              │        ║
║  │  │ G1 G2 G3 G4 │     │ G5 G6 G7    │              │        ║
║  │  └──────┬──────┘     └──────┬──────┘              │        ║
║  │         │                    │                      │        ║
║  │         ▼                    ▼                      │        ║
║  │  ┌──────────┐        ┌──────────┐                  │        ║
║  │  │ M0       │        │ M1       │                  │        ║
║  │  │(OS thrd) │        │(OS thrd) │                  │        ║
║  │  └──────────┘        └──────────┘                  │        ║
║  │       ↕                    ↕                        │        ║
║  │  ┌──────────┐        ┌──────────┐                  │        ║
║  │  │CPU Core 0│        │CPU Core 1│                  │        ║
║  │  └──────────┘        └──────────┘                  │        ║
║  │                                                    │        ║
║  │  Global Queue: [ G8, G9, G10 ]                    │        ║
║  │  → Khi local queue đầy, goroutine vào đây       │        ║
║  │                                                    │        ║
║  └──────────────────────────────────────────────────┘        ║
║                                                               ║
║  WORK STEALING:                                              ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  P0: [G1, G2, G3, G4]    P1: [  ] (empty!)   │             ║
║  │                                                │             ║
║  │  P1 idle → steal NỬA queue từ P0:           │             ║
║  │  P0: [G1, G2]            P1: [G3, G4]         │             ║
║  │                                                │             ║
║  │  → Load balancing tự động!                    │             ║
║  │  → Không cần global lock (mỗi P có local!)   │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  KHI GOROUTINE BỊ BLOCK (syscall):                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  G1 gọi syscall (disk read, CGo call):       │             ║
║  │                                                │             ║
║  │  BEFORE:  P0 ←→ M0 running G1                │             ║
║  │                                                │             ║
║  │  1. G1 blocks on syscall                       │             ║
║  │  2. P0 DETACH from M0                          │             ║
║  │  3. P0 tìm M2 (hoặc create mới) để chạy G2  │             ║
║  │  4. M0 blocked trên syscall cùng G1           │             ║
║  │                                                │             ║
║  │  AFTER:   P0 ←→ M2 running G2                │             ║
║  │           M0 blocked (G1 waiting)              │             ║
║  │                                                │             ║
║  │  → P0 KHÔNG BAO GIỜ bị block!                │             ║
║  │  → Luôn có M available để chạy G!            │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.9 IPC — Giao Tiếp Giữa Các Process

Khi 2 processes cần nói chuyện với nhau (ví dụ web server gửi request đến database), chúng cần **IPC (Inter-Process Communication)** vì mỗi process có address space riêng.

```
╔═══════════════════════════════════════════════════════════════╗
║   IPC — INTER-PROCESS COMMUNICATION                         ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ┌──────────────────┬───────────┬──────────┬────────────┐    ║
║  │ Mechanism        │ Speed     │ Data     │ Use Case   │    ║
║  ├──────────────────┼───────────┼──────────┼────────────┤    ║
║  │ Pipe             │ Fast      │ Stream   │ cmd1|cmd2  │    ║
║  │ Named Pipe(FIFO) │ Fast      │ Stream   │ Unrelated  │    ║
║  │ Unix Socket      │ Very fast │ Stream/  │ Same host  │    ║
║  │                  │           │ Datagram │ DB conns   │    ║
║  │ TCP Socket       │ Medium    │ Stream   │ Network    │    ║
║  │ Shared Memory    │ Fastest!  │ Random   │ High perf  │    ║
║  │ Message Queue    │ Medium    │ Messages │ Async      │    ║
║  │ Signal           │ Fast      │ Tiny     │ SIGTERM    │    ║
║  │ mmap file        │ Fast      │ Random   │ Shared DB  │    ║
║  └──────────────────┴───────────┴──────────┴────────────┘    ║
║                                                               ║
║  PIPE — Shell pipeline:                                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  $ cat access.log | grep "500" | wc -l       │             ║
║  │                                                │             ║
║  │  cat ──pipe──► grep ──pipe──► wc             │             ║
║  │  (write end)   (read|write)   (read end)      │             ║
║  │                                                │             ║
║  │  → Kernel buffer: 64KB (pipe_buf)             │             ║
║  │  → Nếu buffer FULL: writer BLOCKS            │             ║
║  │  → Nếu buffer EMPTY: reader BLOCKS           │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  UNIX DOMAIN SOCKET:                                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  PostgreSQL default connection:               │             ║
║  │  → /var/run/postgresql/.s.PGSQL.5432         │             ║
║  │                                                │             ║
║  │  Go → PostgreSQL (Unix socket):              │             ║
║  │  db, _ := sql.Open("postgres",               │             ║
║  │    "host=/var/run/postgresql dbname=mydb")    │             ║
║  │                                                │             ║
║  │  → 2-3× faster than TCP (skip network stack!)│             ║
║  │  → No TCP overhead (handshake, checksums)     │             ║
║  │  → Same machine only!                         │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ Go PHILOSOPHY:                                             ║
║  → "Do not communicate by sharing memory;                    ║
║     share memory by communicating." — Go Proverb             ║
║  → Channels > Shared Memory cho goroutines!                  ║
║  → Nhưng IPC (socket/pipe) vẫn cần cho cross-process!      ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.10 Zombie & Orphan — Hai Loại Process Bất Thường

Trong production, **zombie processes** và **orphan processes** là source of bugs phổ biến nhưng developer thường không biết.

```
╔═══════════════════════════════════════════════════════════════╗
║   ZOMBIE & ORPHAN PROCESSES                                  ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ZOMBIE PROCESS — "Chết nhưng chưa được chôn":             ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Parent (PID 100)         Child (PID 101)     │             ║
║  │  ┌──────────────┐        ┌──────────────┐     │             ║
║  │  │ Running...   │        │ exit(0)      │     │             ║
║  │  │              │        │ ↓            │     │             ║
║  │  │ KHÔNG gọi   │        │ ZOMBIE (Z)   │     │             ║
║  │  │ wait()!      │        │ → PID vẫn    │     │             ║
║  │  │              │        │   tồn tại    │     │             ║
║  │  │              │        │ → PCB vẫn    │     │             ║
║  │  │              │        │   chiếm slot │     │             ║
║  │  └──────────────┘        └──────────────┘     │             ║
║  │                                                │             ║
║  │  Tại sao nguy hiểm?                           │             ║
║  │  → Mỗi zombie chiếm 1 PID slot               │             ║
║  │  → Linux default: max 32768 PIDs              │             ║
║  │  → 32K zombies = KHÔNG THỂ tạo process mới! │             ║
║  │                                                │             ║
║  │  Fix: Parent phải gọi wait()/waitpid()        │             ║
║  │  Go: os/exec.Cmd.Wait() tự handle!           │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ORPHAN PROCESS — "Mồ côi":                                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Parent exit TRƯỚC child:                     │             ║
║  │                                                │             ║
║  │  Parent (PID 100)         Child (PID 101)     │             ║
║  │  ┌──────────────┐        ┌──────────────┐     │             ║
║  │  │ exit()       │        │ Running...   │     │             ║
║  │  │ (chết)       │        │              │     │             ║
║  │  └──────────────┘        │ PPID: 100→1 │     │             ║
║  │                           │ (adopted by │     │             ║
║  │                           │  PID 1 init)│     │             ║
║  │                           └──────────────┘     │             ║
║  │                                                │             ║
║  │  → PID 1 (init/systemd) "nhận nuôi"         │             ║
║  │  → PID 1 tự động gọi wait() khi orphan exit │             ║
║  │  → Orphan ít nguy hiểm hơn zombie           │             ║
║  │                                                │             ║
║  │  ⚠️ Docker: container PID 1 = entrypoint!    │             ║
║  │  → Nếu Go binary là PID 1, phải handle       │             ║
║  │    SIGCHLD để reap zombies!                   │             ║
║  │  → Hoặc dùng tini/dumb-init làm PID 1       │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §2. CPU Scheduling — Ai Được Chạy Tiếp?

### 2.1 Bài Toán Scheduling — Tại Sao Cần Thuật Toán?

Khi có 100 processes muốn chạy nhưng chỉ có 4 CPU cores, OS phải quyết định: **ai chạy trước, ai chờ, chạy bao lâu?** Quyết định sai = user thấy lag, database timeout, API chậm.

Scheduling giống như quản lý hàng đợi tại ngân hàng: bạn có thể phục vụ ai đến trước (FIFO), ai cần ít thời gian nhất (SJF), hay ai VIP (Priority)?

```
╔═══════════════════════════════════════════════════════════════╗
║   SCHEDULING ALGORITHMS                                     ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  1. FCFS (First Come First Served):                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Queue: [P1:24ms] [P2:3ms] [P3:3ms]          │             ║
║  │                                                │             ║
║  │  Timeline:                                     │             ║
║  │  |───P1 (24ms)───────────|P2(3)|P3(3)|        │             ║
║  │  0                       24    27    30        │             ║
║  │                                                │             ║
║  │  Waiting: P1=0, P2=24, P3=27                  │             ║
║  │  Average wait: (0+24+27)/3 = 17ms ← TỆ!     │             ║
║  │                                                │             ║
║  │  "Convoy Effect": 1 task dài block hết!      │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  2. SJF (Shortest Job First):                                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Queue: [P2:3ms] [P3:3ms] [P1:24ms]          │             ║
║  │                                                │             ║
║  │  Timeline:                                     │             ║
║  │  |P2(3)|P3(3)|───P1 (24ms)───────────|        │             ║
║  │  0     3     6                       30        │             ║
║  │                                                │             ║
║  │  Waiting: P2=0, P3=3, P1=6                    │             ║
║  │  Average wait: (0+3+6)/3 = 3ms ← TỐT!      │             ║
║  │                                                │             ║
║  │  Vấn đề: Làm sao biết task dài bao lâu?     │             ║
║  │  → Prediction based on history!                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  3. ROUND ROBIN (time slicing):                              ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Quantum = 4ms                                 │             ║
║  │                                                │             ║
║  │  |P1|P2|P3|P1|P1|P1|P1|P1|                    │             ║
║  │  0  4  7  10 14 18 22 26 30                    │             ║
║  │                                                │             ║
║  │  → Mỗi process chạy tối đa 4ms rồi nhường  │             ║
║  │  → Fair! Không ai bị starve                   │             ║
║  │  → Trade-off: context switch overhead         │             ║
║  │                                                │             ║
║  │  Quantum quá nhỏ (1ms): switch liên tục!     │             ║
║  │  Quantum quá lớn (100ms): giống FCFS!        │             ║
║  │  Sweet spot: 10-100ms (Linux default)         │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  4. PRIORITY SCHEDULING:                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Mỗi process có priority (nice: -20 đến +19)│             ║
║  │  → DB process: nice -5 (ưu tiên cao)        │             ║
║  │  → Backup cron: nice +19 (ưu tiên thấp)     │             ║
║  │                                                │             ║
║  │  ⚠️ Starvation: low priority KHÔNG BAO GIỜ  │             ║
║  │     được chạy nếu luôn có high priority      │             ║
║  │  → Fix: Aging — tăng priority theo wait time │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.2 Preemptive vs Cooperative Scheduling

```
╔═══════════════════════════════════════════════════════════════╗
║   PREEMPTIVE vs COOPERATIVE                                  ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  COOPERATIVE (Non-preemptive):                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Process tự "nhường" CPU khi sẵn sàng:     │             ║
║  │  → yield() / sleep() / I/O                    │             ║
║  │                                                │             ║
║  │  Vấn đề: Nếu process KHÔNG nhường?          │             ║
║  │  → Mọi process khác bị ĐÓNG BĂNG!           │             ║
║  │  → Windows 3.1, Classic Mac OS dùng kiểu này│             ║
║  │  → 1 app treo = CẢ hệ thống treo!          │             ║
║  │                                                │             ║
║  │  Go trước 1.14: goroutines cooperative!       │             ║
║  │  → for {} loop = KHÔNG BAO GIỜ yield!       │             ║
║  │  → Block tất cả goroutines trên P đó!       │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  PREEMPTIVE:                                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  OS CƯỠNG CHẾ dừng process via timer IRQ:   │             ║
║  │                                                │             ║
║  │  ┌─────────┐    timer    ┌──────────┐         │             ║
║  │  │Process A│───IRQ!────►│ Kernel   │         │             ║
║  │  │ running │            │scheduler │         │             ║
║  │  └─────────┘            │→ switch  │         │             ║
║  │                          │  to B    │         │             ║
║  │                          └──────────┘         │             ║
║  │                                                │             ║
║  │  → Process KHÔNG THỂ monopolize CPU          │             ║
║  │  → Linux, Windows NT, macOS đều preemptive   │             ║
║  │                                                │             ║
║  │  Go 1.14+: goroutines preemptive!             │             ║
║  │  → Async preemption via signals (SIGURG)      │             ║
║  │  → for {} loop bị preempt sau ~10ms!         │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.3 CFS — Linux Completely Fair Scheduler

CFS là scheduler default của Linux từ kernel 2.6.23 (2007). Thay vì time slices cố định, CFS dùng **virtual runtime** — ai đã được chạy ÍT nhất sẽ chạy tiếp.

```
╔═══════════════════════════════════════════════════════════════╗
║   CFS — COMPLETELY FAIR SCHEDULER                           ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Ý TƯỞNG: "Ideal fair CPU" chia đều thời gian             ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  4 processes, 1 CPU:                          │             ║
║  │  Ideal: mỗi process chạy 25% thời gian      │             ║
║  │                                                │             ║
║  │  CFS track vruntime (virtual runtime):        │             ║
║  │  → vruntime = actual_runtime / weight         │             ║
║  │  → weight phụ thuộc vào nice value           │             ║
║  │  → nice 0: weight 1024                        │             ║
║  │  → nice -5: weight 3121 (chạy NHIỀU hơn)    │             ║
║  │  → nice +5: weight 335 (chạy ÍT hơn)        │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  RED-BLACK TREE (Data Structure của CFS):                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Leftmost node = process có vruntime THẤP nhất│             ║
║  │  → Luôn được chạy tiếp!                      │             ║
║  │                                                │             ║
║  │         ┌───[50ms]───┐                         │             ║
║  │     [20ms]        [80ms]                       │             ║
║  │    /     \       /      \                      │             ║
║  │  [10ms] [30ms] [60ms] [100ms]                  │             ║
║  │  ↑                                              │             ║
║  │  Leftmost! → chạy process này!               │             ║
║  │                                                │             ║
║  │  Lookup: O(1) (cached leftmost pointer!)      │             ║
║  │  Insert/Delete: O(log n)                       │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ BACKEND TUNING:                                            ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  # Đặt DB process priority cao hơn:          │             ║
║  │  $ nice -n -5 postgres                        │             ║
║  │  $ renice -5 -p $(pidof postgres)             │             ║
║  │                                                │             ║
║  │  # Scheduler tunables:                        │             ║
║  │  sched_latency_ns = 6000000    # 6ms target   │             ║
║  │  sched_min_granularity = 750000 # min 0.75ms  │             ║
║  │                                                │             ║
║  │  # Real-time priority cho latency-critical:   │             ║
║  │  $ chrt -f 99 ./my-realtime-service           │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.4 Go Scheduler vs OS Scheduler — Hai Tầng Scheduling

Go có **2 tầng scheduling**: OS scheduler quản lý M (threads), Go scheduler quản lý G (goroutines) trên P. Hiểu sự khác biệt này là chìa khóa để tune Go performance.

```
╔═══════════════════════════════════════════════════════════════╗
║   TWO-LEVEL SCHEDULING                                       ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ┌─────────────────────────────────────────────┐             ║
║  │                                               │             ║
║  │  TẦNG 1: Go Runtime Scheduler                │             ║
║  │  ┌─────────────────────────────────────────┐ │             ║
║  │  │ G1 G2 G3 ... G100000                    │ │             ║
║  │  │         ↓ (M:N mapping)                 │ │             ║
║  │  │ P0→M0   P1→M1   P2→M2   P3→M3         │ │             ║
║  │  └──────────────────────┬──────────────────┘ │             ║
║  │                          │                     │             ║
║  │  TẦNG 2: OS (Linux CFS)                      │             ║
║  │  ┌──────────────────────┴──────────────────┐ │             ║
║  │  │ M0 M1 M2 M3 (OS threads)               │ │             ║
║  │  │         ↓ (CFS scheduling)              │ │             ║
║  │  │ Core0   Core1   Core2   Core3           │ │             ║
║  │  └─────────────────────────────────────────┘ │             ║
║  │                                               │             ║
║  └─────────────────────────────────────────────┘             ║
║                                                               ║
║  KHI NÀO MỖI TẦNG HOẠT ĐỘNG:                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Go scheduler (goroutine switch):             │             ║
║  │  → channel send/receive                        │             ║
║  │  → network I/O (netpoller)                     │             ║
║  │  → time.Sleep()                                │             ║
║  │  → runtime.Gosched()                           │             ║
║  │  → async preemption (>10ms running)           │             ║
║  │  → sync.Mutex contention                       │             ║
║  │                                                │             ║
║  │  OS scheduler (thread switch):                │             ║
║  │  → syscall (disk I/O, CGo)                    │             ║
║  │  → Timer interrupt (CFS preemption)           │             ║
║  │  → Page fault                                  │             ║
║  │  → Signal delivery                             │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  GOMAXPROCS:                                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  GOMAXPROCS = số P = số goroutines chạy     │             ║
║  │  ĐỒNG THỜI thực sự (parallel)                │             ║
║  │                                                │             ║
║  │  Default: runtime.NumCPU()                     │             ║
║  │  → 4 cores → GOMAXPROCS=4 → 4P → 4M min    │             ║
║  │                                                │             ║
║  │  Container gotcha:                             │             ║
║  │  → Docker CPU limit = 2 cores                 │             ║
║  │  → Nhưng runtime.NumCPU() = 16 (host CPUs!)  │             ║
║  │  → GOMAXPROCS=16 → quá nhiều context switch! │             ║
║  │  → Fix: import _ "go.uber.org/automaxprocs"   │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.5 Priority Inversion — Bug Kinh Điển

Priority Inversion xảy ra khi **high-priority task bị chờ low-priority task** giữ lock. Bug này từng làm crash Mars Pathfinder năm 1997!

```
╔═══════════════════════════════════════════════════════════════╗
║   PRIORITY INVERSION                                         ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  3 tasks: H (High), M (Medium), L (Low priority)            ║
║                                                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. L lấy mutex lock                          │             ║
║  │  2. H cần mutex → BLOCKED (chờ L unlock)    │             ║
║  │  3. M ready → M chạy (priority cao hơn L!)  │             ║
║  │  4. L KHÔNG ĐƯỢC CHẠY vì M đang chạy!       │             ║
║  │  5. H VẪN BLOCKED vì L chưa unlock!         │             ║
║  │                                                │             ║
║  │  Timeline:                                     │             ║
║  │  L: |██lock██|----blocked by M----|██unlock██|│             ║
║  │  M: |        |████████████████████|          | │             ║
║  │  H: |        blocked by L!!!!!!!!!!!|████████| │             ║
║  │                                                │             ║
║  │  → H (highest!) chạy SAU M (medium)!        │             ║
║  │  → Priority bị "đảo ngược"!                   │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  FIX — Priority Inheritance:                                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Khi H chờ lock do L giữ:                    │             ║
║  │  → Tạm NÂNG priority L lên = H!             │             ║
║  │  → L chạy ngay (priority cao), unlock nhanh  │             ║
║  │  → H được lock, chạy ngay                    │             ║
║  │  → L trở về priority gốc                    │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ Go KHÔNG CÓ priority cho goroutines!                     ║
║  → Tất cả goroutines "bình đẳng"                           ║
║  → Không bị priority inversion kiểu OS                      ║
║  → Nhưng sync.Mutex starvation vẫn có thể xảy ra!         ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.6 Starvation & Livelock

```
╔═══════════════════════════════════════════════════════════════╗
║   STARVATION & LIVELOCK                                      ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  STARVATION — "Chết đói":                                   ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Process/goroutine KHÔNG BAO GIỜ được chạy  │             ║
║  │  vì luôn có cái khác ưu tiên hơn            │             ║
║  │                                                │             ║
║  │  Ví dụ: sync.RWMutex trong Go                │             ║
║  │  → Continuous readers = writer STARVED!       │             ║
║  │  → Go fix: writer có priority sau khi chờ    │             ║
║  │                                                │             ║
║  │  Ví dụ: Kafka consumer với slow processing   │             ║
║  │  → Consumer lag tăng mãi không giảm          │             ║
║  │  → Messages cũ bị "starved" không xử lý     │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  LIVELOCK — "Chạy nhưng không tiến":                        ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  2 goroutines nhường nhau mãi:               │             ║
║  │                                                │             ║
║  │  G1: lock A → try B → fail → unlock A       │             ║
║  │  G2: lock B → try A → fail → unlock B       │             ║
║  │  G1: lock A → try B → fail → unlock A       │             ║
║  │  ... lặp mãi, không ai tiến!                 │             ║
║  │                                                │             ║
║  │  Khác deadlock: processes ĐANG chạy (CPU > 0%)│             ║
║  │  Nhưng KHÔNG làm được gì useful!             │             ║
║  │                                                │             ║
║  │  Fix: Random backoff (giống Ethernet CSMA/CD)│             ║
║  │  → time.Sleep(rand.Intn(100) * time.Ms)      │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.7 Real-time vs General Purpose Scheduling

```
╔═══════════════════════════════════════════════════════════════╗
║   REAL-TIME SCHEDULING                                       ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  GENERAL PURPOSE (Linux CFS):                                ║
║  → "Best effort" fairness                                    ║
║  → No deadline guarantees                                    ║
║  → OK cho web servers, databases                             ║
║                                                               ║
║  REAL-TIME:                                                   ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Hard real-time:                               │             ║
║  │  → Deadline BẮT BUỘC (miss = failure!)       │             ║
║  │  → VD: airbag controller, ABS brakes         │             ║
║  │                                                │             ║
║  │  Soft real-time:                               │             ║
║  │  → Deadline ưu tiên (miss = degraded)        │             ║
║  │  → VD: video streaming, VoIP                  │             ║
║  │  → Linux SCHED_FIFO, SCHED_RR                 │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ BACKEND: Khi nào cần real-time priority?                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  → Trading systems (microsecond latency)      │             ║
║  │  → Game servers (tick rate consistency)        │             ║
║  │  → Thường KHÔNG cần cho web APIs             │             ║
║  │  → Go GC: STW pause = soft real-time concern!│             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.8 Multi-Queue Scheduling — Server Đa CPU

```
╔═══════════════════════════════════════════════════════════════╗
║   MULTI-QUEUE MULTIPROCESSOR SCHEDULING (MQMS)              ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  SINGLE QUEUE (SMP — đơn giản nhưng chậm):                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Global Queue: [P1, P2, P3, P4, P5, P6...]   │             ║
║  │       ↓        ↓        ↓        ↓             │             ║
║  │    Core 0   Core 1   Core 2   Core 3          │             ║
║  │                                                │             ║
║  │  Vấn đề: Global lock contention!             │             ║
║  │  → 64 cores tranh 1 lock = bottleneck!       │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  MULTI-QUEUE (Per-CPU — Linux & Go dùng):                   ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Queue 0: [P1, P3]     → Core 0              │             ║
║  │  Queue 1: [P2, P4]     → Core 1              │             ║
║  │  Queue 2: [P5]         → Core 2              │             ║
║  │  Queue 3: [  ]         → Core 3 (idle!)      │             ║
║  │                                                │             ║
║  │  → Mỗi core lock riêng = no contention!      │             ║
║  │  → Nhưng: load imbalance!                     │             ║
║  │  → Fix: work stealing (Core 3 steal từ Q0)  │             ║
║  │  → Go P's local queue = chính xác pattern này!│             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CACHE AFFINITY:                                              ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Process P1 chạy trên Core 0:                │             ║
║  │  → Data P1 đã nằm trong L1/L2 cache Core 0  │             ║
║  │  → Nếu migrate P1 sang Core 1: cache COLD!  │             ║
║  │  → Cache warm-up = ~5-50μs!                   │             ║
║  │                                                │             ║
║  │  → CFS: prefer giữ process trên cùng core   │             ║
║  │  → Go: goroutine "sticky" to P, P "sticky"   │             ║
║  │    to M → cache locality                      │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §3. Memory Management — Bộ Nhớ Ảo

### 3.1 Virtual Memory — Ảo Giác Vĩ Đại

Virtual Memory là một trong những phát minh quan trọng nhất của OS. Nó cho mỗi process **ảo giác** rằng nó sở hữu toàn bộ bộ nhớ, trong khi thực tế nhiều process chia sẻ cùng RAM vật lý.

```
╔═══════════════════════════════════════════════════════════════╗
║   VIRTUAL MEMORY — THE BIG PICTURE                          ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Process A             Process B          Physical RAM       ║
║  Virtual Space          Virtual Space                        ║
║  ┌──────────┐          ┌──────────┐     ┌──────────┐        ║
║  │ 0x400000 │───map───►│          │     │ Frame 0  │        ║
║  │ (code)   │          │ 0x400000 │──┐  │ Frame 1  │◄──A    ║
║  │          │          │ (code)   │  │  │ Frame 2  │◄──B    ║
║  │ 0x600000 │───map──┐ │          │  │  │ Frame 3  │◄──A    ║
║  │ (heap)   │        │ │ 0x600000 │──┼─►│ Frame 4  │        ║
║  │          │        └─┼──────────┼──┘  │ Frame 5  │◄──B    ║
║  │ 0x7fff.. │───map──┐ │ 0x7fff.. │──┐  │ Frame 6  │        ║
║  │ (stack)  │        └─┼──────────┼──┼─►│ Frame 7  │        ║
║  └──────────┘          └──────────┘  │  │ ....     │        ║
║                                       │  └──────────┘        ║
║  → A và B dùng CÙNG virtual address  │                       ║
║    nhưng map tới KHÁC physical frame! │                       ║
║  → Process A KHÔNG THỂ đọc RAM       │                       ║
║    của Process B! (isolation!)        │                       ║
║                                                               ║
║  TẠI SAO CẦN VIRTUAL MEMORY?                                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  1. ISOLATION: mỗi process address space riêng│             ║
║  │     → Crash A không ảnh hưởng B              │             ║
║  │  2. ABSTRACTION: process không cần biết       │             ║
║  │     physical layout                            │             ║
║  │  3. OVERCOMMIT: cấp phát > RAM thật          │             ║
║  │     → 16GB RAM nhưng tổng process dùng 50GB? │             ║
║  │     → OK! Vì không phải tất cả access cùng lúc│             ║
║  │  4. SHARING: shared libraries (libc) map 1 lần│             ║
║  │     → 100 process dùng chung 1 copy!          │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.2 Page Table — Bản Dịch Địa Chỉ

OS chia memory thành các **page** cố định (4KB trên Linux). Page table chuyển virtual address → physical address.

```
╔═══════════════════════════════════════════════════════════════╗
║   PAGE TABLE — ADDRESS TRANSLATION                          ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Virtual Address (64-bit, nhưng chỉ dùng 48-bit):           ║
║  ┌────────────────────────────────────────┐                   ║
║  │ PML4 │ PDPT │  PD  │  PT  │  OFFSET  │                   ║
║  │ 9bit │ 9bit │ 9bit │ 9bit │  12bit   │                   ║
║  └──┬───┴──┬───┴──┬───┴──┬───┴────┬─────┘                   ║
║     │      │      │      │        │                           ║
║     │   4-LEVEL PAGE TABLE WALK:  │                           ║
║     │      │      │      │        │                           ║
║     ▼      ▼      ▼      ▼        │                           ║
║  ┌─────┐┌─────┐┌─────┐┌─────┐    │                           ║
║  │PML4 ││PDPT ││ PD  ││ PT  │    │                           ║
║  │table││table││table││table│    │                           ║
║  │[idx]││[idx]││[idx]││[idx]│────┼──► Physical Frame         ║
║  └──┬──┘└──┬──┘└──┬──┘└──┬──┘    │      + OFFSET            ║
║     └──►   └──►   └──►   └──►    │      = Physical Address!  ║
║                                   │                           ║
║  → Mỗi level = 1 memory access: 4 levels = 4 accesses!     ║
║  → 4 × ~100ns = 400ns per translation! ← QUÁ CHẬM!       ║
║  → Giải pháp: TLB cache (xem 3.3)                          ║
║                                                               ║
║  PAGE TABLE ENTRY (PTE):                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Physical Frame Number  │ Flags:              │             ║
║  │  (chỉ tới RAM thật)    │ P  = Present        │             ║
║  │                          │ R/W = Read/Write    │             ║
║  │                          │ U/S = User/Kernel   │             ║
║  │                          │ D  = Dirty          │             ║
║  │                          │ A  = Accessed        │             ║
║  │                          │ NX = No Execute      │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ Huge Pages (2MB/1GB thay vì 4KB):                        ║
║  → Giảm số TLB entries cần → ít TLB miss hơn              ║
║  → PostgreSQL: huge_pages = try                               ║
║  → Redis: echo always > /sys/transparent_hugepage/enabled    ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.3 TLB — Cache Cho Địa Chỉ

**TLB (Translation Lookaside Buffer)** cache kết quả page table lookup. Không có TLB, mọi memory access chậm 4-5× vì page walk.

```
╔═══════════════════════════════════════════════════════════════╗
║   TLB — TRANSLATION LOOKASIDE BUFFER                        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  CPU muốn access 0x7fff8004:                                 ║
║                                                               ║
║  ┌──────────┐    TLB hit?     ┌───────────┐                  ║
║  │   CPU    │───────────────►│   TLB     │                  ║
║  │          │   YES (~1ns)    │ 64-1024   │                  ║
║  │          │◄───────────────│ entries   │                  ║
║  │          │                 └───────────┘                  ║
║  │          │   NO (~400ns!)                                  ║
║  │          │───────────────► Page Table Walk                ║
║  │          │                 (4 memory accesses)             ║
║  │          │◄───────────────                                ║
║  └──────────┘                                                 ║
║                                                               ║
║  TLB PERFORMANCE:                                             ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  TLB hit rate: 99%+ cho normal workloads     │             ║
║  │  → 99% × 1ns + 1% × 400ns = ~5ns average    │             ║
║  │                                                │             ║
║  │  TLB miss rate cao khi:                       │             ║
║  │  • Random memory access (pointer chasing)     │             ║
║  │  • Working set > TLB coverage                 │             ║
║  │    (1024 entries × 4KB = 4MB coverage)       │             ║
║  │  • Context switch (TLB flush!)                │             ║
║  │                                                │             ║
║  │  Huge Pages: 1024 entries × 2MB = 2GB!       │             ║
║  │  → Database workloads TLB miss giảm 10×!    │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.4 Page Fault — Khi Trang Chưa Sẵn Sàng

**Page fault** xảy ra khi process truy cập page chưa có trong RAM. Không phải error — đây là cơ chế bình thường của demand paging!

```
╔═══════════════════════════════════════════════════════════════╗
║   PAGE FAULTS                                                ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  3 LOẠI PAGE FAULT:                                          ║
║                                                               ║
║  1. MINOR (Soft) Page Fault:           ~1-10μs              ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Page nằm trong RAM nhưng chưa map          │             ║
║  │  → OS cập nhật page table, done!            │             ║
║  │  → malloc(): OS chưa cấp RAM thật ngay     │             ║
║  │  → First access → minor fault → map page   │             ║
║  │                                                │             ║
║  │  Go: runtime allocator pre-map → ít fault   │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  2. MAJOR (Hard) Page Fault:           ~1-10ms!             ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Page KHÔNG nằm trong RAM!                    │             ║
║  │  → Đã bị swap ra disk                        │             ║
║  │  → OS phải đọc disk → load vào RAM          │             ║
║  │  → Nếu RAM full: swap page KHÁC ra disk!    │             ║
║  │                                                │             ║
║  │  ⚠️ CHẬM 1000× so với minor fault!          │             ║
║  │  → Đây là "performance cliff" khi OOM!      │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  3. INVALID Page Fault → SIGSEGV!                            ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Access ĐỊA CHỈ KHÔNG HỢP LỆ:              │             ║
║  │  → NULL pointer dereference (0x0000)          │             ║
║  │  → Write vào read-only memory                 │             ║
║  │  → Access kernel space từ userspace           │             ║
║  │                                                │             ║
║  │  → OS gửi SIGSEGV signal                     │             ║
║  │  → Go: panic: runtime error: invalid memory   │             ║
║  │    address or nil pointer dereference          │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  MONITOR:                                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  $ ps -o min_flt,maj_flt -p <PID>            │             ║
║  │  MIN_FLT  MAJ_FLT                            │             ║
║  │  423891   12          ← maj_flt thấp = OK   │             ║
║  │                                                │             ║
║  │  $ perf stat -e page-faults ./myserver        │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.5 Demand Paging & Overcommit

```
╔═══════════════════════════════════════════════════════════════╗
║   DEMAND PAGING & OVERCOMMIT                                ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  DEMAND PAGING — "Lazy Allocation":                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  malloc(100MB):                                │             ║
║  │                                                │             ║
║  │  1. OS: "OK, đánh dấu 100MB virtual space"  │             ║
║  │     → KHÔNG cấp RAM thật!                    │             ║
║  │     → Chỉ update page table entries           │             ║
║  │                                                │             ║
║  │  2. First access page 0: Minor fault!         │             ║
║  │     → OS cấp 1 physical page (4KB)           │             ║
║  │                                                │             ║
║  │  3. First access page 1: Minor fault!         │             ║
║  │     → OS cấp thêm 1 page...                  │             ║
║  │                                                │             ║
║  │  → Chỉ cấp pages THỰC SỰ được dùng!        │             ║
║  │  → malloc(100MB) nhưng dùng 1MB → 1MB RAM!  │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  OVERCOMMIT MEMORY (Linux):                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  /proc/sys/vm/overcommit_memory:              │             ║
║  │                                                │             ║
║  │  0 (default): Heuristic — OS quyết định      │             ║
║  │  1: Always — cho phép overcommit vô hạn!     │             ║
║  │  2: Never — chỉ commit ≤ swap + RAM×ratio   │             ║
║  │                                                │             ║
║  │  Khi overcommit + dùng hết:                   │             ║
║  │  → OOM Killer! OS kill process chiếm RAM nhất│             ║
║  │  → oom_score_adj = -1000: never kill (DB!)   │             ║
║  │  → oom_score_adj = +1000: kill first (cache) │             ║
║  │                                                │             ║
║  │  Go: GOGC=100 (default) → heap ≤ 2× live    │             ║
║  │  → GOMEMLIMIT=1GiB (Go 1.19+) hard limit!   │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.6 Copy-on-Write (CoW)

```
╔═══════════════════════════════════════════════════════════════╗
║   COPY-ON-WRITE (CoW)                                        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  fork() KHÔNG copy toàn bộ memory!                          ║
║                                                               ║
║  STEP 1 — Fork:                                              ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Parent & Child SHARE same physical pages     │             ║
║  │  → Tất cả pages đánh dấu READ-ONLY!        │             ║
║  │                                                │             ║
║  │  Parent   Physical    Child                    │             ║
║  │  VPage 0 ──→ Frame 5 ←── VPage 0             │             ║
║  │  VPage 1 ──→ Frame 8 ←── VPage 1             │             ║
║  │  VPage 2 ──→ Frame 2 ←── VPage 2             │             ║
║  │                                                │             ║
║  │  → fork() = gần như FREE! (chỉ copy table)  │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  STEP 2 — Write (Parent writes VPage 1):                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  1. CPU trap: write to read-only page!        │             ║
║  │  2. OS: đây là CoW page                       │             ║
║  │  3. OS copy Frame 8 → Frame 12 (new!)       │             ║
║  │  4. Parent VPage 1 → Frame 12 (private!)    │             ║
║  │  5. Child VPage 1 vẫn → Frame 8 (original)  │             ║
║  │                                                │             ║
║  │  → Chỉ page THỰC SỰ WRITE mới bị copy!     │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ Redis fork() cho RDB snapshot:                             ║
║  → Redis fork child để dump data ra disk                    ║
║  → CoW: child share memory với parent                       ║
║  → Chỉ pages parent WRITE mới copy                         ║
║  → 10GB Redis, 5% write → chỉ cần thêm 500MB!            ║
║  → Nếu không có CoW: cần 20GB RAM! (2× copy)              ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.7 mmap — Memory-Mapped Files

```
╔═══════════════════════════════════════════════════════════════╗
║   mmap — MEMORY-MAPPED I/O                                   ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  TRADITIONAL I/O vs mmap:                                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  read() syscall:                               │             ║
║  │  Disk → Kernel buffer → User buffer (2 copy!)│             ║
║  │                                                │             ║
║  │  mmap:                                         │             ║
║  │  File mapped vào virtual address space        │             ║
║  │  → Access file = access memory!               │             ║
║  │  → Page fault → OS load page từ disk         │             ║
║  │  → ZERO copy vào userspace!                   │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  USE CASES:                                                   ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Shared libraries: libc.so mmap 1 lần     │             ║
║  │    → 100 processes share cùng physical pages  │             ║
║  │  • Database: MongoDB WiredTiger mmap engine   │             ║
║  │  • SQLite: mmap mode cho reads               │             ║
║  │  • Log files: mmap cho random access          │             ║
║  │                                                │             ║
║  │  Go: syscall.Mmap() hoặc                     │             ║
║  │      golang.org/x/exp/mmap                     │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ⚠️ CAVEATS:                                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • mmap NOT good cho sequential large reads   │             ║
║  │    → read() + readahead tốt hơn!            │             ║
║  │  • mmap page faults unpredictable              │             ║
║  │    → Latency spike! (1-10ms per major fault)  │             ║
║  │  • Error handling khó: SIGBUS on I/O error!  │             ║
║  │  • Andy Pavlo (CMU): "mmap for DB is bad"     │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.8 malloc/free — Dynamic Memory Allocation

```
╔═══════════════════════════════════════════════════════════════╗
║   malloc/free & MEMORY ALLOCATORS                           ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  malloc(size) — Cấp phát bộ nhớ trên heap:                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Kernel cấp pages qua brk()/mmap()           │             ║
║  │  → brk(): mở rộng heap (small allocations)   │             ║
║  │  → mmap(): anonymous mapping (large allocs)   │             ║
║  │                                                │             ║
║  │  Allocator (glibc ptmalloc, jemalloc, tcmalloc)│             ║
║  │  quản lý sub-division pages thành chunks:     │             ║
║  │                                                │             ║
║  │  ┌────┐┌────────┐┌──┐┌──────┐┌───────────┐   │             ║
║  │  │ 16 ││  128   ││32││  64  ││   free    │   │             ║
║  │  └────┘└────────┘└──┘└──────┘└───────────┘   │             ║
║  │  ↑ allocated     ↑     ↑        ↑ free        │             ║
║  │                                                │             ║
║  │  Fragmentation: có free space nhưng            │             ║
║  │  KHÔNG đủ contiguous cho request lớn!        │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  COMMON BUGS:                                                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  C:                   Go:                      │             ║
║  │  ─────                ────                     │             ║
║  │  Memory leak          goroutine leak          │             ║
║  │  (забыl free)        (goroutine chờ mãi)    │             ║
║  │                                                │             ║
║  │  Double free          reference kept alive    │             ║
║  │  (crash!)             (GC không collect)     │             ║
║  │                                                │             ║
║  │  Use-after-free       N/A (GC prevents this!) │             ║
║  │  (undefined behavior!)                         │             ║
║  │                                                │             ║
║  │  Buffer overflow      slice bounds check!     │             ║
║  │  (security exploit!)  (runtime panic)          │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.9 Garbage Collection — Tự Động Dọn Rác

```
╔═══════════════════════════════════════════════════════════════╗
║   GARBAGE COLLECTION                                         ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  GC ALGORITHMS:                                              ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Reference Counting (Python, Swift):       │             ║
║  │     Mỗi object đếm số references            │             ║
║  │     → count = 0 → free immediately!          │             ║
║  │     → Vấn đề: circular references!           │             ║
║  │     A → B → A (count never = 0!)            │             ║
║  │                                                │             ║
║  │  2. Mark-and-Sweep (Go, Java, JS):            │             ║
║  │     Phase 1 (Mark): trace từ root objects    │             ║
║  │     → Đánh dấu tất cả reachable objects     │             ║
║  │     Phase 2 (Sweep): free unreachable objects │             ║
║  │                                                │             ║
║  │  3. Generational (Java, .NET):                │             ║
║  │     Objects chia thành generations:            │             ║
║  │     Gen 0 (Young): collect thường xuyên      │             ║
║  │     Gen 1 (Old): collect ít hơn              │             ║
║  │     → Hypothesis: "most objects die young"    │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  GO GC — TRI-COLOR MARK & SWEEP:                            ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  WHITE: chưa visit (potential garbage)        │             ║
║  │  GRAY:  visited, chưa scan children          │             ║
║  │  BLACK: visited + scanned (definitely alive)  │             ║
║  │                                                │             ║
║  │  Step 1: Root scan (stacks, globals)          │             ║
║  │  → Root objects = GRAY                        │             ║
║  │                                                │             ║
║  │  Step 2: Trace (concurrent!)                  │             ║
║  │  → GRAY → scan children → children = GRAY   │             ║
║  │  → Original object = BLACK                    │             ║
║  │  → Lặp lại đến hết GRAY                     │             ║
║  │                                                │             ║
║  │  Step 3: Sweep                                 │             ║
║  │  → WHITE objects = garbage → free!            │             ║
║  │                                                │             ║
║  │  Key insight: CONCURRENT với application!     │             ║
║  │  → STW pause chỉ ~0.1-0.5ms (Go 1.18+)     │             ║
║  │  → Write barrier để track mutations          │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  GO GC TUNING:                                                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  GOGC=100 (default): GC khi heap = 2× live   │             ║
║  │  GOGC=50: GC thường hơn, ít RAM, nhiều CPU │             ║
║  │  GOGC=200: GC ít hơn, nhiều RAM, ít CPU    │             ║
║  │  GOGC=off: TẮT GC (nguy hiểm!)              │             ║
║  │                                                │             ║
║  │  GOMEMLIMIT=512MiB (Go 1.19+):               │             ║
║  │  → Hard memory limit                          │             ║
║  │  → GC chạy aggressive hơn khi gần limit     │             ║
║  │  → Container-friendly! (match Docker limit)   │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.10 Go Memory Allocator — TCMalloc-Inspired

```
╔═══════════════════════════════════════════════════════════════╗
║   GO MEMORY ALLOCATOR                                        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Go allocator lấy cảm hứng từ TCMalloc (Google):           ║
║                                                               ║
║  3-LEVEL HIERARCHY:                                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  mcache (per-P, lock-free!):                  │             ║
║  │  ┌─────────────────────────────────────┐      │             ║
║  │  │ Size class 8:   [span] [span]       │      │             ║
║  │  │ Size class 16:  [span]              │      │             ║
║  │  │ Size class 32:  [span] [span] [span]│      │             ║
║  │  │ ...                                  │      │             ║
║  │  │ Size class 32KB: [span]             │      │             ║
║  │  └─────────────────────────────────────┘      │             ║
║  │  → Mỗi P (processor) có mcache riêng        │             ║
║  │  → NO LOCK cho small allocations!             │             ║
║  │                                                │             ║
║  │  mcentral (shared, per-size-class):           │             ║
║  │  ┌─────────────────────────────────────┐      │             ║
║  │  │ Khi mcache hết span → lấy từ đây │      │             ║
║  │  │ → Cần lock (nhưng per-size-class!) │      │             ║
║  │  └─────────────────────────────────────┘      │             ║
║  │                                                │             ║
║  │  mheap (global, OS memory):                   │             ║
║  │  ┌─────────────────────────────────────┐      │             ║
║  │  │ Khi mcentral hết → mheap xin OS   │      │             ║
║  │  │ → mmap() syscall lấy pages mới     │      │             ║
║  │  │ → Cần global lock (hiếm khi dùng) │      │             ║
║  │  └─────────────────────────────────────┘      │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  SIZE CLASSES:                                                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  ≤ 32KB: small object → mcache (fast!)      │             ║
║  │  32KB-32MB: large object → mheap direct     │             ║
║  │  > 32MB: very large → direct mmap()          │             ║
║  │                                                │             ║
║  │  ~67 size classes: 8, 16, 32, 48, 64...       │             ║
║  │  → Giảm fragmentation!                        │             ║
║  │  → Request 20B → allocate 32B (12B wasted)   │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ ZERO-ALLOC PATTERNS (Performance):                        ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  // ❌ Allocates: slice header escape to heap │             ║
║  │  func getIDs() []int { return []int{1,2,3} }  │             ║
║  │                                                │             ║
║  │  // ✅ Pre-allocate:                          │             ║
║  │  ids := make([]int, 0, expectedCap)            │             ║
║  │                                                │             ║
║  │  // ✅ sync.Pool: reuse objects               │             ║
║  │  var bufPool = sync.Pool{                      │             ║
║  │    New: func() any { return new(bytes.Buffer) }│             ║
║  │  }                                              │             ║
║  │  buf := bufPool.Get().(*bytes.Buffer)           │             ║
║  │  defer bufPool.Put(buf)                         │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §4. File System — Mọi Thứ Là File

### 4.1 "Everything is a File" — Triết Lý Unix

Trên Unix/Linux, gần như **mọi thứ** được trừu tượng hóa dưới dạng file: file thật, thư mục, thiết bị (disk, keyboard), network socket, pipe, thậm chí thông tin process (`/proc`). Đây là một trong những quyết định thiết kế quan trọng nhất của Unix, cho phép sử dụng cùng API (`open/read/write/close`) cho mọi loại I/O.

```
╔═══════════════════════════════════════════════════════════════╗
║   EVERYTHING IS A FILE                                       ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ┌──────────────────┬──────────────────────────┐             ║
║  │ "File" type       │ Ví dụ thực tế            │             ║
║  ├──────────────────┼──────────────────────────┤             ║
║  │ Regular file      │ /etc/nginx/nginx.conf     │             ║
║  │ Directory         │ /var/log/                  │             ║
║  │ Symlink           │ /usr/bin/python→python3   │             ║
║  │ Block device      │ /dev/sda (disk)            │             ║
║  │ Character device  │ /dev/tty (terminal)        │             ║
║  │ Named pipe (FIFO) │ /tmp/myfifo                │             ║
║  │ Unix socket       │ /var/run/docker.sock       │             ║
║  │ /proc file        │ /proc/1234/status          │             ║
║  │ /sys file         │ /sys/class/net/eth0/mtu    │             ║
║  └──────────────────┴──────────────────────────┘             ║
║                                                               ║
║  → TẤT CẢ đều dùng: open(), read(), write(), close()       ║
║  → Thống nhất interface = simple, composable, powerful!     ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 4.2 Inode — Danh Tính Thật Của File

**Inode** (index node) là cấu trúc dữ liệu trong filesystem chứa **metadata** của file. Tên file chỉ là "alias" — inode mới là danh tính thật.

```
╔═══════════════════════════════════════════════════════════════╗
║   INODE STRUCTURE                                            ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  $ ls -li /etc/passwd                                        ║
║  1234567 -rw-r--r-- 1 root root 2048 Jan 1 passwd            ║
║  ↑ inode number                                               ║
║                                                               ║
║  INODE chứa:                                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  File type (regular/dir/symlink/...)          │             ║
║  │  Permissions (rwxr-xr-x)                      │             ║
║  │  Owner UID, Group GID                         │             ║
║  │  Size (bytes)                                  │             ║
║  │  Timestamps: atime, mtime, ctime              │             ║
║  │  Link count (hard links)                       │             ║
║  │  Data block pointers:                          │             ║
║  │  ├── 12 direct pointers → 48KB              │             ║
║  │  ├── 1 indirect → 4MB                        │             ║
║  │  ├── 1 double indirect → 4GB                 │             ║
║  │  └── 1 triple indirect → 4TB                 │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  INODE KHÔNG chứa: TÊN FILE!                                ║
║  → Tên nằm trong directory entry (dentry)                   ║
║  → Nhiều tên có thể chỉ tới cùng 1 inode = hard link      ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 4.3 File Descriptor — "Tay Cầm" Của Process

Khi process `open()` file, kernel trả về **file descriptor (fd)** — một số nguyên dùng cho mọi thao tác tiếp theo.

```
╔═══════════════════════════════════════════════════════════════╗
║   FILE DESCRIPTOR TABLE                                      ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Process (PID 1234):                                         ║
║  ┌─────┬───────────────────────────────────────┐             ║
║  │ fd  │ Trỏ tới (Open File Description)       │             ║
║  ├─────┼───────────────────────────────────────┤             ║
║  │  0  │ stdin  (terminal /dev/pts/0)           │             ║
║  │  1  │ stdout (terminal /dev/pts/0)           │             ║
║  │  2  │ stderr (terminal /dev/pts/0)           │             ║
║  │  3  │ /var/log/app.log (offset: 4096)        │             ║
║  │  4  │ TCP socket (port 8080)                  │             ║
║  │  5  │ PostgreSQL unix socket                  │             ║
║  └─────┴───────────────────────────────────────┘             ║
║                                                               ║
║  ⚠️ FILE DESCRIPTOR LIMIT:                                   ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  $ ulimit -n                                   │             ║
║  │  1024     ← default trên nhiều Linux!        │             ║
║  │                                                │             ║
║  │  → 1 TCP connection = 1 fd                    │             ║
║  │  → 1024 connections = HẾT fd!                │             ║
║  │  → "too many open files" error ← phổ biến!  │             ║
║  │                                                │             ║
║  │  Fix cho production:                           │             ║
║  │  $ ulimit -n 65535                             │             ║
║  │  /etc/security/limits.conf:                    │             ║
║  │  * soft nofile 65535                            │             ║
║  │  * hard nofile 65535                            │             ║
║  │                                                │             ║
║  │  → 10K connections Go server: cần ≥ 10K fds  │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 4.4 VFS — Virtual File System Layer

**VFS** là abstraction layer trong kernel, cho phép Linux hỗ trợ hàng chục filesystem types (ext4, XFS, Btrfs, NFS, procfs...) thông qua cùng một API.

```
╔═══════════════════════════════════════════════════════════════╗
║   VFS — VIRTUAL FILE SYSTEM                                 ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  User space: open("/data/myfile", O_RDONLY)                  ║
║  ──────────────────────────────────────────────              ║
║  Kernel:                                                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │              VFS Layer                         │             ║
║  │  (Chung cho TẤT CẢ filesystem types)         │             ║
║  │  → struct inode, struct dentry, struct file   │             ║
║  │  → Routing request tới đúng FS driver       │             ║
║  ├──────────┬──────────┬──────────┬─────────────┤             ║
║  │   ext4   │   XFS    │   NFS   │   procfs    │             ║
║  │  driver  │  driver  │  driver │   driver    │             ║
║  ├──────────┴──────────┴─────────┴──────────────┤             ║
║  │           Block I/O Layer                      │             ║
║  │    (I/O scheduling, request merging)           │             ║
║  ├──────────────────────────────────────────────┤             ║
║  │           Device Drivers                       │             ║
║  │    (SCSI, NVMe, virtio-blk)                    │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  → Go os.Open() → syscall.Open() → VFS → ext4 → disk     ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 4.5 ext4 & Journaling — Chống Corrupt Dữ Liệu

```
╔═══════════════════════════════════════════════════════════════╗
║   ext4 JOURNALING                                            ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  VẤN ĐỀ: Mất điện giữa lúc write file!                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  1. Update inode metadata        ✓ done       │             ║
║  │  2. Write data blocks            ✓ partial    │             ║
║  │  3. Update bitmap (free space)   ✗ chưa kịp! │             ║
║  │                                                │             ║
║  │  → Mất điện! → filesystem INCONSISTENT!      │             ║
║  │  → File corrupt, data mất, bitmap sai!       │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  JOURNALING — Write-Ahead Logging cho filesystem:           ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  1. Ghi JOURNAL ENTRY trước (what will change)│             ║
║  │  2. COMMIT journal entry                      │             ║
║  │  3. Apply changes to actual data/metadata     │             ║
║  │  4. Mark journal entry done                    │             ║
║  │                                                │             ║
║  │  Mất điện ở step 2? → Replay journal!        │             ║
║  │  Mất điện ở step 3? → Replay journal!        │             ║
║  │  → LUÔN consistent sau recovery!              │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  JOURNAL MODES (ext4):                                       ║
║  ┌──────────────────┬───────────────────────────┐             ║
║  │ Mode             │ Ghi gì vào journal?       │             ║
║  ├──────────────────┼───────────────────────────┤             ║
║  │ journal          │ metadata + data (chậm, safe)│             ║
║  │ ordered (default)│ metadata (data write first)│             ║
║  │ writeback        │ metadata only (nhanh, rủi ro)│             ║
║  └──────────────────┴───────────────────────────┘             ║
║                                                               ║
║  ☞ PostgreSQL + ext4:                                         ║
║  → DB có WAL riêng → ext4 ordered mode là đủ              ║
║  → full_page_writes=on (PG) bảo vệ thêm                   ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 4.6 Buffered I/O vs Direct I/O

```
╔═══════════════════════════════════════════════════════════════╗
║   BUFFERED vs DIRECT I/O                                     ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  BUFFERED I/O (default):                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  App write() → Page Cache → (later) Disk    │             ║
║  │                                                │             ║
║  │  ┌─────┐    ┌────────────┐    ┌──────┐       │             ║
║  │  │ App │──►│ Page Cache │──►│ Disk │       │             ║
║  │  └─────┘    │ (RAM)      │    └──────┘       │             ║
║  │             │ kernel quản│                     │             ║
║  │             └────────────┘                     │             ║
║  │                                                │             ║
║  │  ✅ write() return NGAY (dữ liệu ở RAM)    │             ║
║  │  ✅ read() từ cache = nhanh!                 │             ║
║  │  ⚠️ Mất điện = mất data chưa flush!         │             ║
║  │  → fsync() để force flush cache → disk       │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  DIRECT I/O (O_DIRECT):                                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  App write() → BYPASS Page Cache → Disk     │             ║
║  │                                                │             ║
║  │  ┌─────┐              ┌──────┐                │             ║
║  │  │ App │────────────►│ Disk │                │             ║
║  │  └─────┘              └──────┘                │             ║
║  │                                                │             ║
║  │  ✅ Database tự manage cache hiệu quả hơn   │             ║
║  │  ✅ Tránh double caching (DB cache + page)   │             ║
║  │  ⚠️ Chậm hơn cho workload nhỏ              │             ║
║  │                                                │             ║
║  │  Ai dùng O_DIRECT?                            │             ║
║  │  → MySQL InnoDB (innodb_flush_method=O_DIRECT)│             ║
║  │  → PostgreSQL: effective_io_concurrency       │             ║
║  │  → RocksDB, ScyllaDB                          │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 4.7 Hard Links vs Soft Links

```
╔═══════════════════════════════════════════════════════════════╗
║   HARD LINKS vs SOFT LINKS (SYMLINKS)                       ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  HARD LINK:                                                   ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  $ ln original.txt hardlink.txt               │             ║
║  │                                                │             ║
║  │  "original.txt" ──→ inode 12345 ←── "hardlink"│             ║
║  │  (cùng inode = cùng data!)                    │             ║
║  │                                                │             ║
║  │  → Delete "original.txt": file VẪN TỒN TẠI! │             ║
║  │  → Vì inode link count = 1 (hardlink còn!)   │             ║
║  │  → Không thể hard link across filesystems    │             ║
║  │  → Không thể hard link directories           │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  SOFT LINK (Symlink):                                        ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  $ ln -s /usr/bin/go /usr/local/bin/go        │             ║
║  │                                                │             ║
║  │  "symlink" ──→ "/usr/bin/go" (path string)   │             ║
║  │  (inode KHÁC, chỉ chứa path!)               │             ║
║  │                                                │             ║
║  │  → Delete target: symlink BROKEN (dangling!) │             ║
║  │  → Có thể cross filesystem                   │             ║
║  │  → Có thể link directories                   │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 4.8 Directory Structure — Cây Thư Mục Linux

```
╔═══════════════════════════════════════════════════════════════╗
║   LINUX DIRECTORY HIERARCHY (FHS)                           ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  /                           Root                             ║
║  ├── bin/                    Essential binaries               ║
║  ├── etc/                    Configuration files              ║
║  │   ├── nginx/              → Nginx config                  ║
║  │   └── postgresql/         → PG config                     ║
║  ├── var/                    Variable data                    ║
║  │   ├── log/                → Log files                     ║
║  │   ├── lib/postgresql/     → DB data files                 ║
║  │   └── run/                → Runtime data (PID, sockets)   ║
║  ├── proc/                   Process pseudo-filesystem       ║
║  │   ├── 1234/               → Process PID 1234 info        ║
║  │   │   ├── status          → Process state, memory        ║
║  │   │   ├── fd/             → Open file descriptors        ║
║  │   │   └── maps            → Memory mappings              ║
║  │   ├── cpuinfo             → CPU information               ║
║  │   └── meminfo             → Memory statistics             ║
║  ├── sys/                    Kernel/hardware tuning          ║
║  │   ├── class/net/          → Network interfaces            ║
║  │   └── block/              → Block devices                 ║
║  ├── dev/                    Device files                     ║
║  │   ├── sda                 → First disk                    ║
║  │   ├── null                → Discard output                ║
║  │   └── urandom             → Random bytes                  ║
║  └── tmp/                    Temporary files                  ║
║                                                               ║
║  ☞ Go debug production server:                                ║
║  → cat /proc/<pid>/status    (goroutine count, memory)      ║
║  → ls -la /proc/<pid>/fd/   (open file descriptors)         ║
║  → cat /proc/<pid>/maps     (memory regions)                ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §5. I/O & System Calls — Cổng Giao Tiếp

### 5.1 System Call — Cánh Cửa Vào Kernel

User-space programs **không thể** trực tiếp truy cập hardware. Muốn đọc file, gửi network packet, hay tạo process — phải nhờ kernel qua **system call** (syscall). Đây là ranh giới bảo mật giữa user mode và kernel mode.

```
╔═══════════════════════════════════════════════════════════════╗
║   SYSTEM CALL — USER MODE → KERNEL MODE                     ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Go code: os.ReadFile("/etc/hosts")                          ║
║                                                               ║
║  ┌─────────────────────────────────────────────┐             ║
║  │ USER MODE (Ring 3):                           │             ║
║  │ ┌───────────────────────────────────────────┐ │             ║
║  │ │ Go: os.ReadFile()                         │ │             ║
║  │ │   → os.Open() → syscall.Open()           │ │             ║
║  │ │   → os.Read() → syscall.Read()           │ │             ║
║  │ │   → os.Close() → syscall.Close()         │ │             ║
║  │ └──────────────────┬────────────────────────┘ │             ║
║  │                     │ SYSCALL instruction      │             ║
║  │                     │ (x86: syscall/int 0x80)  │             ║
║  ├─────────────────────┼───────────────────────┤ ║             ║
║  │ KERNEL MODE (Ring 0):                         │             ║
║  │ ┌──────────────────┴────────────────────────┐ │             ║
║  │ │ 1. Save user registers                    │ │             ║
║  │ │ 2. Lookup syscall table (RAX = syscall #) │ │             ║
║  │ │    → read = 0, write = 1, open = 2...     │ │             ║
║  │ │ 3. Execute kernel function                │ │             ║
║  │ │ 4. Return result to user space            │ │             ║
║  │ └───────────────────────────────────────────┘ │             ║
║  └─────────────────────────────────────────────┘             ║
║                                                               ║
║  SYSCALL COST:                                                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Normal function call:  ~1-2ns                │             ║
║  │  System call:           ~100-500ns            │             ║
║  │  Ratio:                 50-250× chậm hơn!   │             ║
║  │                                                │             ║
║  │  Tại sao chậm?                                │             ║
║  │  → Mode switch (user → kernel → user)        │             ║
║  │  → Save/restore registers                      │             ║
║  │  → TLB & cache pollution                       │             ║
║  │  → Security checks                             │             ║
║  │                                                │             ║
║  │  Go optimization:                              │             ║
║  │  → Batch syscalls khi có thể                 │             ║
║  │  → Netpoller: 1 epoll_wait thay vì N reads   │             ║
║  │  → Buffered I/O: giảm số write() calls       │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 5.2 Blocking vs Non-blocking I/O

```
╔═══════════════════════════════════════════════════════════════╗
║   BLOCKING vs NON-BLOCKING I/O                              ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  BLOCKING (default):                                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  conn.Read(buf)                                │             ║
║  │  → Thread BLOCKED cho đến khi có data!       │             ║
║  │  → Thread không làm gì = lãng phí!          │             ║
║  │                                                │             ║
║  │  Thread 1: |██read()██████████████|──data!──| │             ║
║  │             ↑ blocked, doing nothing ↑         │             ║
║  │                                                │             ║
║  │  1 thread per connection model:                │             ║
║  │  10K connections = 10K threads = 10GB RAM!    │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  NON-BLOCKING:                                                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  fcntl(fd, F_SETFL, O_NONBLOCK)               │             ║
║  │  read(fd) → EAGAIN (no data yet!)            │             ║
║  │  → Return NGAY, không chờ!                   │             ║
║  │                                                │             ║
║  │  Vấn đề: phải poll liên tục (busy waiting!)  │             ║
║  │  while (true) {                                │             ║
║  │    if read(fd) != EAGAIN { process(data) }    │             ║
║  │    // CPU quay tít = lãng phí!               │             ║
║  │  }                                              │             ║
║  │                                                │             ║
║  │  → Giải pháp: I/O multiplexing! (5.3)        │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ Go hides complexity:                                       ║
║  → conn.Read() LOOKS blocking (đơn giản!)                   ║
║  → Nhưng INTERNALLY: non-blocking + epoll!                   ║
║  → Goroutine bị park, M chạy goroutine khác                │             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 5.3 select/poll/epoll — I/O Multiplexing

Thay vì 1 thread per connection, **multiplexing** cho phép 1 thread giám sát HÀNG NGÀN connections cùng lúc.

```
╔═══════════════════════════════════════════════════════════════╗
║   I/O MULTIPLEXING EVOLUTION                                 ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  1. select() — 1983 (BSD):                                   ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  fd_set readfds;                               │             ║
║  │  FD_SET(fd1, &readfds);                        │             ║
║  │  FD_SET(fd2, &readfds);                        │             ║
║  │  select(maxfd+1, &readfds, ...);               │             ║
║  │                                                │             ║
║  │  ⚠️ Giới hạn: FD_SETSIZE = 1024!            │             ║
║  │  ⚠️ O(n) scan toàn bộ fd_set mỗi lần call  │             ║
║  │  ⚠️ Copy fd_set user↔kernel mỗi lần         │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  2. poll() — 1986 (System V):                                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Giống select nhưng KHÔNG giới hạn 1024      │             ║
║  │  → Nhưng vẫn O(n) scan!                     │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  3. epoll() — 2002 (Linux 2.6):                ★ QUAN TRỌNG ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  epfd = epoll_create()                         │             ║
║  │  epoll_ctl(epfd, ADD, fd, events)     ← O(1) │             ║
║  │  events = epoll_wait(epfd, ...)       ← O(k) │             ║
║  │  (k = số fd READY, không phải tổng fds!)    │             ║
║  │                                                │             ║
║  │  ✅ O(1) add/remove fd                        │             ║
║  │  ✅ O(k) return CHỈ ready fds                │             ║
║  │  ✅ Kernel quản lý state (không copy mỗi lần)│             ║
║  │  ✅ Scale tới 1M+ connections!               │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  SO SÁNH PERFORMANCE:                                        ║
║  ┌──────────┬───────────┬──────────┬──────────┐              ║
║  │ FDs      │ select    │ poll     │ epoll    │              ║
║  ├──────────┼───────────┼──────────┼──────────┤              ║
║  │ 10       │ Fast      │ Fast     │ Fast     │              ║
║  │ 1,000    │ Slow      │ Slow     │ Fast     │              ║
║  │ 10,000   │ N/A (1024)│ Very slow│ Fast     │              ║
║  │ 100,000  │ N/A       │ Unusable │ Fast!    │              ║
║  └──────────┴───────────┴──────────┴──────────┘              ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 5.4 Go Netpoller — Epoll Trong Go Runtime

```
╔═══════════════════════════════════════════════════════════════╗
║   GO NETPOLLER                                               ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Go MAGIC: code viết sync, chạy async!                      ║
║                                                               ║
║  Developer viết:                                              ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  conn, _ := net.Dial("tcp", "db:5432")        │             ║
║  │  data := make([]byte, 4096)                    │             ║
║  │  n, _ := conn.Read(data)  // "blocking"       │             ║
║  │  // Nhưng KHÔNG block OS thread!              │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  BEHIND THE SCENES:                                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  1. conn.Read() → fd set to non-blocking     │             ║
║  │  2. read() returns EAGAIN (no data)           │             ║
║  │  3. Goroutine PARKED (not running, no thread!)│             ║
║  │  4. fd registered with epoll                   │             ║
║  │  5. Netpoller goroutine: epoll_wait()          │             ║
║  │  6. Data arrives! epoll reports fd ready       │             ║
║  │  7. Goroutine UNPARKED → back to run queue   │             ║
║  │  8. Goroutine scheduled → read() succeeds!   │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  → 100K goroutines waiting on I/O:                           ║
║    100K connections, nhưng chỉ ~4 OS threads!               ║
║  → epoll_wait() handle TẤT CẢ pending I/O                  ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 5.5 io_uring — Tương Lai Của Linux I/O

```
╔═══════════════════════════════════════════════════════════════╗
║   io_uring — ASYNC I/O REVOLUTION (Linux 5.1+, 2019)       ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  VẤN ĐỀ với epoll:                                          ║
║  → Mỗi I/O vẫn cần syscall (read/write)!                  ║
║  → syscall = ~200ns overhead × millions = bottleneck!       ║
║                                                               ║
║  io_uring GIẢI QUYẾT — NO syscall per I/O!                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Shared ring buffers between user & kernel:   │             ║
║  │                                                │             ║
║  │  Submission Queue (SQ):     Completion Q (CQ):│             ║
║  │  ┌──────────────────┐      ┌────────────────┐ │             ║
║  │  │ User puts I/O    │      │ Kernel puts    │ │             ║
║  │  │ requests here    │      │ results here   │ │             ║
║  │  │ (no syscall!)    │      │ (no syscall!)  │ │             ║
║  │  └──────────────────┘      └────────────────┘ │             ║
║  │                                                │             ║
║  │  → Batch submit: 1000 I/Os with 1 syscall!   │             ║
║  │  → Kernel polls SQ: 0 syscalls! (SQPOLL mode)│             ║
║  │  → Supports: read, write, accept, connect...  │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ Go + io_uring:                                             ║
║  → Chưa native support (Go 1.22 thảo luận)                 ║
║  → Library: github.com/iceber/iouring-go                     ║
║  → Tương lai: có thể thay thế netpoller                    ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 5.6 Signals — Thông Báo Bất Đồng Bộ

```
╔═══════════════════════════════════════════════════════════════╗
║   SIGNALS                                                    ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ┌─────────┬──────┬─────────────────────────────┐            ║
║  │ Signal   │ Num  │ Mô tả & Use Case           │            ║
║  ├─────────┼──────┼─────────────────────────────┤            ║
║  │ SIGTERM  │ 15   │ "Hãy tắt đi" (graceful)   │            ║
║  │ SIGKILL  │ 9    │ KILL ngay (không bắt được!)│            ║
║  │ SIGINT   │ 2    │ Ctrl+C                      │            ║
║  │ SIGHUP   │ 1    │ Reload config (nginx)       │            ║
║  │ SIGUSR1  │ 10   │ User-defined                │            ║
║  │ SIGCHLD  │ 17   │ Child process exited        │            ║
║  │ SIGSEGV  │ 11   │ Segmentation fault!         │            ║
║  │ SIGPIPE  │ 13   │ Write to broken pipe        │            ║
║  └─────────┴──────┴─────────────────────────────┘            ║
║                                                               ║
║  GO GRACEFUL SHUTDOWN:                                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  ctx, stop := signal.NotifyContext(            │             ║
║  │    context.Background(),                       │             ║
║  │    syscall.SIGTERM, syscall.SIGINT,            │             ║
║  │  )                                              │             ║
║  │  defer stop()                                   │             ║
║  │                                                │             ║
║  │  go func() {                                    │             ║
║  │    srv.ListenAndServe()                         │             ║
║  │  }()                                            │             ║
║  │                                                │             ║
║  │  <-ctx.Done() // chờ SIGTERM                   │             ║
║  │  srv.Shutdown(context.Background()) // graceful│             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ⚠️ SIGPIPE in Go:                                           ║
║  → Go ignores SIGPIPE by default (khác C!)                  ║
║  → Write to closed connection = error, not crash!           ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 5.7 /proc & /sys — Pseudo-Filesystems

```
╔═══════════════════════════════════════════════════════════════╗
║   /proc & /sys — KERNEL KNOBS                               ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  /proc — Process & kernel info:                              ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  # Xem memory info                             │             ║
║  │  $ cat /proc/meminfo                           │             ║
║  │  MemTotal: 16384000 kB                         │             ║
║  │  MemFree:   2048000 kB                         │             ║
║  │                                                │             ║
║  │  # Xem TCP connections                         │             ║
║  │  $ cat /proc/net/tcp                           │             ║
║  │                                                │             ║
║  │  # Xem file descriptors của process           │             ║
║  │  $ ls /proc/$(pidof myserver)/fd | wc -l      │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  /sys — Kernel tuning:                                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  # Network tuning cho Go servers:              │             ║
║  │  echo 65535 > /proc/sys/net/core/somaxconn    │             ║
║  │  echo 1 > /proc/sys/net/ipv4/tcp_tw_reuse    │             ║
║  │                                                │             ║
║  │  # Memory tuning:                              │             ║
║  │  echo 1 > /proc/sys/vm/overcommit_memory      │             ║
║  │                                                │             ║
║  │  # File descriptors system-wide:               │             ║
║  │  echo 1000000 > /proc/sys/fs/file-max         │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 5.8 strace — Nhìn Thấy Syscalls

```
╔═══════════════════════════════════════════════════════════════╗
║   strace — DEBUGGING TOOL                                    ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  strace trace TẤT CẢ syscalls của 1 process:               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  $ strace -f -c ./myserver                     │             ║
║  │                                                │             ║
║  │  % time   calls  syscall                       │             ║
║  │  ------  ------  --------                      │             ║
║  │  45.23    12456  futex        ← lock contention│             ║
║  │  23.11     8901  epoll_wait   ← I/O waiting   │             ║
║  │  15.67     3456  write        ← logging        │             ║
║  │   8.34     2345  read         ← network read   │             ║
║  │   4.12      890  nanosleep    ← time.Sleep     │             ║
║  │   3.53      234  openat       ← file opens     │             ║
║  │                                                │             ║
║  │  → futex 45%? Mutex contention problem!       │             ║
║  │  → Too many write? Logging overhead!          │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  COMMON USE CASES:                                            ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  # Xem file access patterns:                   │             ║
║  │  $ strace -e trace=file ./myserver              │             ║
║  │                                                │             ║
║  │  # Xem network operations:                     │             ║
║  │  $ strace -e trace=network ./myserver           │             ║
║  │                                                │             ║
║  │  # Attach to running process:                  │             ║
║  │  $ strace -p $(pidof myserver) -c               │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §6. Synchronization — Đồng Bộ Hóa

### 6.1 Race Condition — Khi Hai Goroutine Cùng Viết

**Race condition** xảy ra khi nhiều goroutine/thread cùng truy cập shared data mà không đồng bộ. Kết quả phụ thuộc vào thứ tự thực thi — **không deterministic**.

```
╔═══════════════════════════════════════════════════════════════╗
║   RACE CONDITION                                             ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  var counter = 0 // shared!                                  ║
║                                                               ║
║  // 2 goroutines cùng chạy: counter++                       ║
║  // counter++ = READ → ADD 1 → WRITE (3 bước!)            ║
║                                                               ║
║  Goroutine A:    Goroutine B:    counter:                    ║
║  READ  = 0                        0                           ║
║                  READ  = 0        0                           ║
║  ADD 1 = 1                        0                           ║
║                  ADD 1 = 1        0                           ║
║  WRITE = 1                        1                           ║
║                  WRITE = 1        1 ← EXPECTED 2!           ║
║                                                               ║
║  DETECT IN GO:                                                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  $ go run -race main.go                       │             ║
║  │  WARNING: DATA RACE                            │             ║
║  │  Write by goroutine 7:                         │             ║
║  │    main.main.func1()                           │             ║
║  │        main.go:12 +0x38                        │             ║
║  │  Previous write by goroutine 6:                │             ║
║  │    main.main.func1()                           │             ║
║  │        main.go:12 +0x38                        │             ║
║  │                                                │             ║
║  │  → CI pipeline: go test -race ./...           │             ║
║  │  → LUÔN chạy race detector khi test!         │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 6.2 Mutex — Khóa Độc Quyền

```
╔═══════════════════════════════════════════════════════════════╗
║   MUTEX (Mutual Exclusion)                                   ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  var (                                                        ║
║    mu      sync.Mutex                                        ║
║    counter int                                                ║
║  )                                                            ║
║                                                               ║
║  func increment() {                                           ║
║    mu.Lock()           // Chỉ 1 goroutine vào!              ║
║    counter++           // Critical section                    ║
║    mu.Unlock()         // Cho goroutine khác vào             ║
║  }                                                            ║
║                                                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  G1: |──Lock──|██critical██|──Unlock──|       │             ║
║  │  G2:      |──wait──────────|──Lock──|██|──U── │             ║
║  │  G3:      |──wait──────────────────|──Lock──  │             ║
║  │           ↑ G2,G3 BLOCKED chờ G1 xong!       │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  GO MUTEX INTERNALS:                                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Normal mode: FIFO-ish (new goroutines        │             ║
║  │  can steal lock = better throughput)            │             ║
║  │                                                │             ║
║  │  Starvation mode: STRICT FIFO khi goroutine   │             ║
║  │  chờ > 1ms (Go 1.9+)                         │             ║
║  │  → Tránh goroutine starvation!               │             ║
║  │                                                │             ║
║  │  Spin: goroutine spin vài lần trước khi park  │             ║
║  │  → Nếu lock release nhanh → không cần sleep │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ⚠️ GOLDEN RULES:                                            ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  1. LUÔN dùng defer mu.Unlock()               │             ║
║  │     → Tránh quên unlock khi panic/return!    │             ║
║  │  2. KHÔNG copy Mutex (embed trong struct)     │             ║
║  │  3. KHÔNG lock trong performance hot path     │             ║
║  │     → Xem atomic, sync.Map, channel thay thế │             ║
║  │  4. Giữ critical section NGẮN nhất có thể   │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 6.3 RWMutex — Đọc Nhiều, Viết Ít

```
╔═══════════════════════════════════════════════════════════════╗
║   RWMutex — READ-WRITE LOCK                                 ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  var (                                                        ║
║    rwmu  sync.RWMutex                                        ║
║    cache map[string]string                                    ║
║  )                                                            ║
║                                                               ║
║  func get(key string) string {                                ║
║    rwmu.RLock()           // Nhiều readers CÙNG LÚC!        ║
║    defer rwmu.RUnlock()                                      ║
║    return cache[key]                                          ║
║  }                                                            ║
║                                                               ║
║  func set(key, val string) {                                  ║
║    rwmu.Lock()            // Writer: EXCLUSIVE!               ║
║    defer rwmu.Unlock()                                        ║
║    cache[key] = val                                           ║
║  }                                                            ║
║                                                               ║
║  RULES:                                                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • N readers đồng thời: ✅ OK                │             ║
║  │  • 1 writer + 0 readers: ✅ OK                │             ║
║  │  • 1 writer + N readers: ❌ BLOCKED!          │             ║
║  │                                                │             ║
║  │  Tốt cho: read-heavy workloads               │             ║
║  │  (config cache, feature flags, routing table)  │             ║
║  │                                                │             ║
║  │  Xấu cho: write-heavy workloads              │             ║
║  │  → Writer phải chờ TẤT CẢ readers xong     │             ║
║  │  → Overhead lớn hơn Mutex!                   │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 6.4 Deadlock — Bế Tắc

```
╔═══════════════════════════════════════════════════════════════╗
║   DEADLOCK — 4 COFFIN CONDITIONS                            ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Deadlock = 2+ goroutines chờ nhau VĨNH VIỄN!              ║
║                                                               ║
║  func transfer(from, to *Account, amount int) {               ║
║    from.mu.Lock()     // Lock A                               ║
║    to.mu.Lock()       // Lock B                               ║
║    from.balance -= amount                                     ║
║    to.balance += amount                                       ║
║    to.mu.Unlock()                                             ║
║    from.mu.Unlock()                                           ║
║  }                                                            ║
║                                                               ║
║  // G1: transfer(A→B) locks A, waits B                      ║
║  // G2: transfer(B→A) locks B, waits A                      ║
║  // → DEADLOCK! Cả 2 chờ nhau mãi mãi!                    ║
║                                                               ║
║  4 ĐIỀU KIỆN CẦN (Coffin Conditions):                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  1. Mutual Exclusion (lock exclusive)         │             ║
║  │  2. Hold and Wait (giữ lock + chờ lock khác) │             ║
║  │  3. No Preemption (không ai cướp lock)       │             ║
║  │  4. Circular Wait (A→B→A)                    │             ║
║  │                                                │             ║
║  │  Phá BẤT KỲ 1 điều kiện → không deadlock!  │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  FIX — Lock Ordering:                                        ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  func transfer(a, b *Account, amount int) {    │             ║
║  │    // LUÔN lock theo thứ tự ID!               │             ║
║  │    first, second := a, b                       │             ║
║  │    if a.id > b.id {                             │             ║
║  │      first, second = b, a                      │             ║
║  │    }                                            │             ║
║  │    first.mu.Lock()                              │             ║
║  │    second.mu.Lock()                             │             ║
║  │    // ... transfer ...                         │             ║
║  │    second.mu.Unlock()                           │             ║
║  │    first.mu.Unlock()                            │             ║
║  │  }                                              │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  GO RUNTIME DEADLOCK DETECTION:                              ║
║  → "fatal error: all goroutines are asleep - deadlock!"     ║
║  → Chỉ detect khi TẤT CẢ goroutines blocked!             ║
║  → Partial deadlock (vài goroutines) = KHÔNG detect!       ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 6.5 Channels — CSP Model

```
╔═══════════════════════════════════════════════════════════════╗
║   GO CHANNELS — "Share Memory By Communicating"             ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  "Don't communicate by sharing memory;                       ║
║   share memory by communicating." — Go Proverbs              ║
║                                                               ║
║  UNBUFFERED CHANNEL (synchronous):                           ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  ch := make(chan int)                          │             ║
║  │                                                │             ║
║  │  G1: ch <- 42   // BLOCK cho đến G2 nhận!   │             ║
║  │  G2: v := <-ch  // BLOCK cho đến G1 gửi!    │             ║
║  │                                                │             ║
║  │  → Synchronization point!                     │             ║
║  │  → Cả 2 phải "gặp nhau" (rendezvous)         │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  BUFFERED CHANNEL (async up to capacity):                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  ch := make(chan int, 100) // buffer 100      │             ║
║  │                                                │             ║
║  │  ch <- 42  // Không block nếu buffer chưa đầy│             ║
║  │  ch <- 43  // ...                              │             ║
║  │  // Block khi buffer FULL!                    │             ║
║  │                                                │             ║
║  │  → Back-pressure tự nhiên!                   │             ║
║  │  → Producer nhanh hơn consumer → block!      │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  PATTERNS:                                                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Fan-out: 1 producer → N consumers (workers) │             ║
║  │  Fan-in:  N producers → 1 consumer (merge)   │             ║
║  │  Pipeline: stage1 → stage2 → stage3          │             ║
║  │  Semaphore: sem := make(chan struct{}, N)      │             ║
║  │  Done/Cancel: ctx.Done() channel              │             ║
║  │  Timeout: select + time.After()               │             ║
║  │  Rate limit: time.Ticker channel              │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 6.6 Atomic Operations — Lock-Free

```
╔═══════════════════════════════════════════════════════════════╗
║   ATOMIC OPERATIONS                                          ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  atomic: CPU instruction, KHÔNG cần lock!                   ║
║  → Nhanh hơn Mutex 5-10×!                                  ║
║                                                               ║
║  var counter atomic.Int64                                     ║
║  counter.Add(1)      // atomic increment                     ║
║  counter.Load()      // atomic read                           ║
║  counter.Store(42)   // atomic write                          ║
║  counter.CompareAndSwap(old, new) // CAS                     ║
║                                                               ║
║  PERFORMANCE:                                                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  mutex lock+unlock:  ~25-50ns                  │             ║
║  │  atomic add:         ~5-10ns                   │             ║
║  │  (contended mutex:   ~500ns-5μs!)             │             ║
║  │                                                │             ║
║  │  Use atomic for:                               │             ║
║  │  → Simple counters (metrics, stats)            │             ║
║  │  → Flags (isRunning, isClosed)                 │             ║
║  │  → Single-value config updates                 │             ║
║  │                                                │             ║
║  │  Use mutex for:                                │             ║
║  │  → Complex data structures                     │             ║
║  │  → Multiple related fields                     │             ║
║  │  → Anything needing consistent reads           │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 6.7 sync.Pool — Object Reuse

```
╔═══════════════════════════════════════════════════════════════╗
║   sync.Pool — REDUCE GC PRESSURE                            ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  VẤN ĐỀ:                                                     ║
║  HTTP handler: mỗi request tạo buffer mới                  ║
║  → 10K req/s × buffer → 10K allocations/s → GC pressure!  ║
║                                                               ║
║  GIẢI PHÁP — sync.Pool:                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  var bufPool = sync.Pool{                      │             ║
║  │    New: func() any {                            │             ║
║  │      return bytes.NewBuffer(make([]byte,0,4096))│             ║
║  │    },                                           │             ║
║  │  }                                              │             ║
║  │                                                │             ║
║  │  func handler(w http.ResponseWriter, r *req) { │             ║
║  │    buf := bufPool.Get().(*bytes.Buffer)         │             ║
║  │    buf.Reset()                                  │             ║
║  │    defer bufPool.Put(buf) // trả lại pool!    │             ║
║  │                                                │             ║
║  │    // dùng buf...                              │             ║
║  │  }                                              │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  HOW IT WORKS:                                                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Per-P private + per-P shared + victim cache  │             ║
║  │  → Get(): private first → shared → New()    │             ║
║  │  → Put(): vào private cache                   │             ║
║  │  → GC sweep: clear pool (objects not permanent)│             ║
║  │                                                │             ║
║  │  ☞ stdlib uses: fmt, encoding/json, net/http  │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 6.8 Semaphore vs WaitGroup vs Once

```
╔═══════════════════════════════════════════════════════════════╗
║   SYNCHRONIZATION PRIMITIVES COMPARISON                     ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  sync.WaitGroup — Chờ N goroutines hoàn thành:              ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  var wg sync.WaitGroup                         │             ║
║  │  for i := 0; i < 10; i++ {                     │             ║
║  │    wg.Add(1)                                    │             ║
║  │    go func() {                                  │             ║
║  │      defer wg.Done()                            │             ║
║  │      doWork()                                   │             ║
║  │    }()                                          │             ║
║  │  }                                              │             ║
║  │  wg.Wait() // block cho đến 10 goroutines done│             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  sync.Once — Chạy ĐÚNG 1 LẦN (singleton, init):            ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  var (                                          │             ║
║  │    once sync.Once                               │             ║
║  │    db   *sql.DB                                 │             ║
║  │  )                                              │             ║
║  │  func getDB() *sql.DB {                         │             ║
║  │    once.Do(func() {                              │             ║
║  │      db, _ = sql.Open("postgres", dsn)          │             ║
║  │    })                                            │             ║
║  │    return db                                     │             ║
║  │  }                                              │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  Semaphore (golang.org/x/sync/semaphore):                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  sem := semaphore.NewWeighted(10) // max 10   │             ║
║  │  sem.Acquire(ctx, 1)  // giống Lock + counter │             ║
║  │  defer sem.Release(1)                          │             ║
║  │                                                │             ║
║  │  → Giới hạn concurrent DB connections         │             ║
║  │  → Rate limiting goroutines                    │             ║
║  │  → Connection pool                             │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  KHI NÀO DÙNG GÌ?                                           ║
║  ┌───────────────┬──────────────────────────────┐             ║
║  │ Primitive      │ Use Case                      │             ║
║  ├───────────────┼──────────────────────────────┤             ║
║  │ Mutex          │ Protect shared state          │             ║
║  │ RWMutex        │ Read-heavy shared state       │             ║
║  │ Channel        │ Communication + signaling     │             ║
║  │ WaitGroup      │ Wait for goroutines to finish │             ║
║  │ Once           │ One-time initialization       │             ║
║  │ Atomic         │ Simple counters/flags          │             ║
║  │ Semaphore      │ Limit concurrency              │             ║
║  │ sync.Pool      │ Reuse expensive objects        │             ║
║  │ sync.Map       │ Concurrent map (specific cases)│             ║
║  └───────────────┴──────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §7. Deep Analysis Patterns — 6 Tư Duy Phân Tích Áp Dụng Cho OS

### 7.1 Pattern 1: Đệ Quy "Tại Sao" (5 Whys)

```
╔═══════════════════════════════════════════════════════════════╗
║   5 WHYS — TẠI SAO GO DÙNG GOROUTINES THAY VÌ THREADS?    ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  WHY 1: Tại sao Go dùng goroutine?                          ║
║  → Vì thread quá nặng cho concurrent server.               ║
║                                                               ║
║  WHY 2: Tại sao thread nặng?                                ║
║  → Mỗi thread cần ~1-8MB stack, context switch ~1-5μs.     ║
║                                                               ║
║  WHY 3: Tại sao stack thread phải lớn?                      ║
║  → Vì OS KHÔNG BIẾT app cần bao nhiêu stack.               ║
║  → Phải allocate trước vì không thể grow giữa chừng!      ║
║                                                               ║
║  WHY 4: Tại sao OS không grow stack?                         ║
║  → Vì thread stack phải contiguous (performance, simplicity).║
║  → Grow = realloc + copy = quá chậm cho kernel!            ║
║                                                               ║
║  WHY 5: Goroutine giải quyết thế nào?                       ║
║  → Stack bắt đầu 2KB, grow/shrink dynamically!             ║
║  → Go runtime control → biết khi nào cần grow.            ║
║  → Copy stack khi grow (update pointers)                     ║
║  → GIỚI HẠN VẬT LÝ: memory bandwidth cho copy!           ║
║                                                               ║
║  → INSIGHT: Go trade CPU (copy stack) lấy Memory (nhỏ)    ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 7.2 Pattern 2: First Principles Thinking

```
╔═══════════════════════════════════════════════════════════════╗
║   FIRST PRINCIPLES — XÂY DỰNG OS TỪ SỐ 0                  ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Nếu bạn phải thiết kế OS từ đầu:                          ║
║                                                               ║
║  NGUYÊN LÝ GỐC:                                             ║
║  1. CPU chỉ chạy instructions tuần tự                      ║
║  2. RAM có giới hạn và volatile                              ║
║  3. I/O devices chậm hơn CPU 10^6 lần                      ║
║  4. Nhiều programs cần chạy "đồng thời"                    ║
║                                                               ║
║  TỪ NGUYÊN LÝ → XÂY DỰNG:                                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  1 CPU + N programs → cần SCHEDULING         │             ║
║  │  RAM giới hạn → cần VIRTUAL MEMORY           │             ║
║  │  I/O chậm → cần ASYNC / MULTIPLEXING        │             ║
║  │  Isolation → cần PROCESS / PROTECTION        │             ║
║  │  Persistence → cần FILE SYSTEM               │             ║
║  │  Shared data → cần SYNCHRONIZATION           │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  → Mọi OS concept đều là HỆ QUẢ TẤT YẾU                 ║
║    của hardware constraints!                                  ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 7.3 Pattern 3: Trade-off Analysis

```
╔═══════════════════════════════════════════════════════════════╗
║   TRADE-OFFS TRONG OS                                        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  1. THREAD vs GOROUTINE vs PROCESS:                          ║
║  ┌──────────┬────────────┬──────────┬───────────┐            ║
║  │          │ Process     │ Thread   │ Goroutine │            ║
║  ├──────────┼────────────┼──────────┼───────────┤            ║
║  │ Isolation│ ★★★Full   │ ★ Shared │ ★ Shared  │            ║
║  │ Memory   │ ★ Heavy    │ ★★ 1-8MB│ ★★★ 2KB  │            ║
║  │ Create   │ ~ms        │ ~100μs   │ ~1μs      │            ║
║  │ Switch   │ ~5-10μs    │ ~1-5μs   │ ~200ns    │            ║
║  │ Scale    │ ~1K        │ ~10K     │ ~1M       │            ║
║  │ Debug    │ ★★★Easy   │ ★★ Hard │ ★ Harder  │            ║
║  └──────────┴────────────┴──────────┴───────────┘            ║
║                                                               ║
║  2. MUTEX vs CHANNEL vs ATOMIC:                              ║
║  ┌──────────┬──────────┬──────────┬──────────┐               ║
║  │          │ Mutex     │ Channel  │ Atomic   │               ║
║  ├──────────┼──────────┼──────────┼──────────┤               ║
║  │ Speed    │ ~50ns     │ ~200ns   │ ~5ns     │               ║
║  │ Flexibility│ ★★★    │ ★★★    │ ★ Limited│               ║
║  │ Deadlock │ Possible  │ Possible │ ★★★ No  │               ║
║  │ Pattern  │ Shared    │ Message  │ Counter  │               ║
║  │          │ state     │ passing  │ / flag   │               ║
║  └──────────┴──────────┴──────────┴──────────┘               ║
║                                                               ║
║  3. BUFFERED vs DIRECT I/O:                                  ║
║  ┌──────────┬──────────────┬──────────────┐                   ║
║  │          │ Buffered      │ Direct       │                   ║
║  ├──────────┼──────────────┼──────────────┤                   ║
║  │ Latency  │ Low (cache)   │ Higher       │                   ║
║  │ Throughput│ Good         │ Good (big IO)│                   ║
║  │ Control  │ OS decides    │ App decides  │                   ║
║  │ Use case │ General       │ Database     │                   ║
║  └──────────┴──────────────┴──────────────┘                   ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 7.4 Pattern 4: Mental Mapping

```
╔═══════════════════════════════════════════════════════════════╗
║   MENTAL MAP — GO HTTP REQUEST LIFECYCLE (OS View)          ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Client sends HTTP request...                                ║
║                                                               ║
║  ① NETWORK I/O (§5):                                        ║
║  → NIC receives packet → interrupt → kernel                ║
║  → TCP stack processes → data in socket buffer              ║
║  → epoll_wait() notifies Go netpoller                        ║
║  → Goroutine unparked → conn.Read() returns                 ║
║                                                               ║
║  ② SCHEDULING (§2):                                          ║
║  → Goroutine placed in P's runqueue                          ║
║  → M picks goroutine → runs handler                         ║
║  → If blocked (DB query): goroutine parks                   ║
║  → M picks another goroutine (no thread wasted!)             ║
║                                                               ║
║  ③ MEMORY (§3):                                              ║
║  → Request buffer from sync.Pool (avoid GC)                  ║
║  → Parse JSON: heap allocation (escape analysis)             ║
║  → Stack growth if deep call chain                           ║
║  → GC runs concurrently (tri-color mark)                     ║
║                                                               ║
║  ④ DB QUERY (§5 + §6):                                      ║
║  → Connection from pool (semaphore pattern)                  ║
║  → Write query → socket → kernel → network                 ║
║  → Goroutine parks (epoll waits for response)                ║
║  → Response arrives → goroutine resumes                     ║
║                                                               ║
║  ⑤ RESPONSE (§4 + §5):                                      ║
║  → Marshal JSON → buffered write                            ║
║  → If log: file write → page cache → async disk            ║
║  → TCP response → kernel socket → NIC → client             ║
║  → Goroutine: defer cleanup → back to pool                  ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 7.5 Pattern 5: Reverse Engineering & Implementation

```
╔═══════════════════════════════════════════════════════════════╗
║   REVERSE ENGINEERING — DOCKER = OS FEATURES!               ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Docker KHÔNG phải VM! Docker = Linux kernel features:      ║
║                                                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Docker Feature    →  OS Feature              │             ║
║  │  ───────────────────────────────────────────  │             ║
║  │  Container          = namespaces + cgroups     │             ║
║  │  Image layers       = OverlayFS (union mount)  │             ║
║  │  Resource limits    = cgroups (CPU, memory)    │             ║
║  │  Network isolation  = network namespaces       │             ║
║  │  Process isolation  = PID namespace             │             ║
║  │  Filesystem isolation = mount namespace        │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  NAMESPACES (isolation):                                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  PID:     Container thấy PID 1 = app process │             ║
║  │  NET:     Container có network stack riêng    │             ║
║  │  MNT:     Container thấy filesystem riêng    │             ║
║  │  UTS:     Container có hostname riêng         │             ║
║  │  IPC:     Container isolated shared memory    │             ║
║  │  USER:    Container map UID (root trong = user)│             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CGROUPS (resource limits):                                   ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  docker run --memory=512m --cpus=2 myapp      │             ║
║  │  → cgroup limit: 512MB RAM, 2 CPU cores       │             ║
║  │                                                │             ║
║  │  Go + cgroups:                                  │             ║
║  │  → GOMAXPROCS tự detect cgroup CPU limit     │             ║
║  │    (Go 1.19+, automaxprocs trước đó)          │             ║
║  │  → GOMEMLIMIT match cgroup memory limit       │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 7.6 Pattern 6: Historical Evolution

```
╔═══════════════════════════════════════════════════════════════╗
║   LỊCH SỬ TIẾN HÓA OS                                      ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  1960s: Batch processing (1 job at a time)                   ║
║  → VẤN ĐỀ: CPU idle khi chờ I/O!                          ║
║                                                               ║
║  1970s: Unix (AT&T Bell Labs, Thompson & Ritchie)            ║
║  → Process model, file abstraction, shell                    ║
║  → "Everything is a file" philosophy born                    ║
║                                                               ║
║  1980s: Networking + Multi-user                               ║
║  → BSD TCP/IP stack (foundation of internet!)                ║
║  → select() system call (I/O multiplexing)                   ║
║  → Thread concept (Mach microkernel)                          ║
║                                                               ║
║  1991: Linux (Linus Torvalds)                                ║
║  → Monolithic kernel, free & open source                     ║
║  → Explosive growth through community                         ║
║                                                               ║
║  2000s: Scalability                                           ║
║  → epoll (2002): handle 1M+ connections                      ║
║  → NPTL threads: lightweight user-space threads              ║
║  → Cgroups + namespaces (2007-2008): containerization        ║
║                                                               ║
║  2010s: Containers & Cloud Native                             ║
║  → Docker (2013): package + distribute apps                  ║
║  → Kubernetes (2014): orchestrate containers                 ║
║  → Go runtime evolves: GC < 1ms (Go 1.8, 2017)              ║
║                                                               ║
║  2019+: io_uring revolution                                   ║
║  → Zero-copy, async I/O without syscall overhead             ║
║  → Future: Go may adopt io_uring for netpoller               ║
║                                                               ║
║  INSIGHT: Mỗi OS feature ra đời để giải quyết             ║
║  bottleneck CỤ THỂ của thời đại trước!                    ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §8. Tổng Kết & Câu Hỏi Phỏng Vấn Senior

### 8.1 Bản Đồ Tổng Quan

```
╔═══════════════════════════════════════════════════════════════╗
║   OS FUNDAMENTALS — COMPLETE MAP                             ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ┌─────────────────────────────────────────────┐             ║
║  │           APPLICATION (Go server)             │             ║
║  │  goroutine ─ channel ─ mutex ─ atomic        │             ║
║  └──────────────────┬──────────────────────────┘             ║
║                      │ syscall                                ║
║  ┌──────────────────┴──────────────────────────┐             ║
║  │              OS KERNEL                         │             ║
║  │  ┌──────┐ ┌────────┐ ┌──────┐ ┌──────────┐  │             ║
║  │  │Sched │ │ VMM    │ │ VFS  │ │ Net stack│  │             ║
║  │  │      │ │        │ │      │ │          │  │             ║
║  │  │ CFS  │ │ Page   │ │ ext4 │ │ TCP/IP   │  │             ║
║  │  │ MQMS │ │ Table  │ │ XFS  │ │ epoll    │  │             ║
║  │  │      │ │ TLB    │ │      │ │ io_uring │  │             ║
║  │  └──────┘ └────────┘ └──────┘ └──────────┘  │             ║
║  └──────────────────┬──────────────────────────┘             ║
║                      │ driver                                 ║
║  ┌──────────────────┴──────────────────────────┐             ║
║  │              HARDWARE                          │             ║
║  │  CPU ─ RAM ─ SSD/HDD ─ NIC ─ BUS            │             ║
║  └─────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 8.2 Câu Hỏi Phỏng Vấn Senior Backend

```
╔═══════════════════════════════════════════════════════════════╗
║   INTERVIEW QUESTIONS — OS FUNDAMENTALS                     ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Process & Thread:                                            ║
║  Q1: Process vs Thread vs Goroutine — khác gì?              ║
║  Q2: Context switch là gì? Chi phí bao nhiêu?              ║
║  Q3: Goroutine có phải green thread không? Khác gì?        ║
║  Q4: fork() + exec() hoạt động thế nào?                    ║
║  Q5: Zombie process là gì? Cách phòng tránh?               ║
║                                                               ║
║  CPU Scheduling:                                              ║
║  Q6: CFS hoạt động thế nào? Tại sao dùng red-black tree?  ║
║  Q7: Go scheduler GMP model là gì?                          ║
║  Q8: Priority Inversion là gì? Mars Pathfinder example?     ║
║  Q9: GOMAXPROCS nên set bao nhiêu trong Docker container?   ║
║                                                               ║
║  Memory Management:                                           ║
║  Q10: Virtual Memory hoạt động thế nào?                     ║
║  Q11: Page fault là gì? Minor vs Major?                     ║
║  Q12: TLB là gì? Tại sao context switch flush TLB?         ║
║  Q13: Copy-on-Write dùng ở đâu? Redis RDB snapshot?       ║
║  Q14: Go GC tri-color algorithm giải thích chi tiết?       ║
║  Q15: GOGC vs GOMEMLIMIT — khi nào dùng cái nào?          ║
║  Q16: Go memory allocator: mcache → mcentral → mheap?     ║
║                                                               ║
║  File System:                                                ║
║  Q17: "Everything is a file" nghĩa là gì?                  ║
║  Q18: Inode là gì? Hard link vs Symlink?                    ║
║  Q19: File descriptor limit — ảnh hưởng server thế nào?   ║
║  Q20: Journaling (WAL) trong ext4 — tại sao cần?          ║
║  Q21: Buffered vs Direct I/O — database dùng cái nào?      ║
║                                                               ║
║  I/O & System Calls:                                         ║
║  Q22: System call hoạt động thế nào? Chi phí?              ║
║  Q23: select vs poll vs epoll — khác gì?                    ║
║  Q24: Go netpoller hoạt động thế nào?                       ║
║  Q25: io_uring là gì? Tại sao nhanh hơn epoll?            ║
║  Q26: Graceful shutdown trong Go — implement thế nào?       ║
║                                                               ║
║  Synchronization:                                             ║
║  Q27: Race condition là gì? Phát hiện bằng gì?             ║
║  Q28: Deadlock — 4 điều kiện cần? Cách phòng tránh?       ║
║  Q29: Mutex vs RWMutex vs Channel — khi nào dùng gì?      ║
║  Q30: Atomic operations — khi nào dùng thay Mutex?         ║
║  Q31: sync.Pool — giải quyết vấn đề gì?                   ║
║                                                               ║
║  System Design (OS-level):                                    ║
║  Q32: Docker container dùng OS features nào?                ║
║  Q33: "Too many open files" — debug + fix thế nào?         ║
║  Q34: OOM Killer — process nào bị kill? Config thế nào?    ║
║  Q35: strace cho output gì? Dùng debug vấn đề nào?        ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 8.3 Key Takeaways

```
╔═══════════════════════════════════════════════════════════════╗
║   KEY TAKEAWAYS                                               ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  1. OS KHÔNG chỉ là lý thuyết — nó ẢNH HƯỞNG            ║
║     trực tiếp đến performance backend của bạn!             ║
║                                                               ║
║  2. Go runtime LÀ một mini-OS:                               ║
║     → Scheduler (GMP) ≈ OS scheduler (CFS)                  ║
║     → Memory allocator ≈ TCMalloc                            ║
║     → Netpoller ≈ epoll                                      ║
║     → GC ≈ memory management                                 ║
║                                                               ║
║  3. Performance bottleneck thường ở OS layer:              ║
║     → fd limit, TLB miss, page fault, lock contention       ║
║     → Biết OS = debug nhanh hơn 10×!                       ║
║                                                               ║
║  4. Docker = Linux kernel features:                           ║
║     → namespaces + cgroups + overlayfs                       ║
║     → KHÔNG PHẢI virtualization!                             ║
║                                                               ║
║  5. Senior mindset:                                           ║
║     → Đừng chỉ biết API, hãy hiểu OS ĐẰNG SAU           ║
║     → conn.Read() = goroutine park + epoll + syscall        ║
║     → mutex.Lock() = futex + spin + park                     ║
║     → malloc() = demand paging + page fault + TLB           ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

> **📚 Tài liệu tham khảo:**
>
> - _Operating Systems: Three Easy Pieces_ — Remzi & Andrea Arpaci-Dusseau
> - _The Linux Programming Interface_ — Michael Kerrisk
> - _Understanding the Linux Kernel_ — Daniel P. Bovet
> - _Go runtime source code_ — github.com/golang/go/src/runtime
> - _Linux kernel source_ — kernel.org
> - _BPF Performance Tools_ — Brendan Gregg
