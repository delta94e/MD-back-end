# Cách Máy Tính Hoạt Động — Deep Dive Từ Transistor Đến Code

> **Tài liệu học dành cho:** Người mới bắt đầu, chuẩn bị trở thành Senior Backend Engineer
> **Chủ đề:** Phase 0.1 — Cách máy tính hoạt động
> **Phương pháp phân tích:** 6 patterns (5 Whys, First Principles, Trade-off Analysis, Mental Mapping, Reverse Engineering, Contextual History)
> **Ngôn ngữ:** Hoàn toàn bằng Tiếng Việt

---

## Mục lục

| #   | Chủ đề                                            | Mô tả                                                                                                                                                                                                      |
| --- | ------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| §1  | CPU — Bộ Não Của Máy Tính (19 mục)                | FDE Cycle, Pipelining, Branch Prediction, OoOE, Multi-Core, CISC/RISC, ISA, Spectre/Meltdown, Syscalls, SIMD, IEEE-754, Endianness, Context Switching, Go Benchmarks, Latency Numbers                      |
| §2  | Memory Hierarchy — Tháp Tốc Độ (19 mục)           | Cache Associativity, TLB, Prefetching, Virtual Memory, NUMA, mmap, Memory Barriers, Alignment, MESI, False Sharing, CoW, DMA, Go Allocator                                                                 |
| §3  | RAM — Bộ Nhớ Chính (12 mục)                       | DRAM Internals, DDR Generations, ECC, Memory Channels, Process Layout, Goroutine Stacks, Fragmentation, Profiling, Zero-Alloc Patterns                                                                     |
| §4  | Disk & Storage — Lưu Trữ Vĩnh Viễn (10 mục)       | HDD vs SSD, SSD Internals (NAND/WA/TRIM), I/O Schedulers, Filesystem (fsync/journal), NVMe, DB I/O Patterns, RAID, Go I/O, Monitoring                                                                      |
| §5  | Bus & Data Flow — Đường Cao Tốc Dữ Liệu (10 mục)  | Bus System, I/O Bottleneck, PCIe, DMA/Zero-Copy, Interrupts (MSI-X/NAPI), MMIO, Network Path, I/O Models, Go Netpoller, Linux Tuning                                                                       |
| §6  | Từ Code Đến Thực Thi — Hành Trình Của 1 Dòng Code | Compiler, binary, OS, CPU                                                                                                                                                                                  |
| §7  | Deep Analysis Patterns (6 mục)                    | 5 Whys (Redis/Goroutine leak/Kafka), First Principles (DB/Microservices), Trade-offs (CAP/Latency/Simplicity), Mental Map, Reverse Engineering (Go KV+WAL), Historical Evolution (CPU/Storage/Concurrency) |
| §8  | Tổng Kết & Câu Hỏi Phỏng Vấn                      | Ôn tập & thực hành                                                                                                                                                                                         |

---

## §1. CPU — Bộ Não Của Máy Tính

### 1.1 CPU thực thi instructions như thế nào?

```
╔═══════════════════════════════════════════════════════════════╗
║   CPU — CENTRAL PROCESSING UNIT                              ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  CPU = BỘ NÃO duy nhất của máy tính.                        ║
║  Nó CHỈ làm MỘT việc: thực thi INSTRUCTIONS.                ║
║                                                               ║
║  Mỗi instruction = 1 thao tác CỰC NHỎ:                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Cộng 2 số                                  │             ║
║  │  • So sánh 2 giá trị                         │             ║
║  │  • Đọc dữ liệu từ bộ nhớ                    │             ║
║  │  • Ghi dữ liệu vào bộ nhớ                   │             ║
║  │  • Nhảy đến instruction khác (branching)     │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  → Mọi thứ bạn thấy trên máy tính — video, game,           ║
║    website — đều là HÀNG TỶ thao tác nhỏ này               ║
║    thực thi MỖI GIÂY.                                        ║
║                                                               ║
║  CPU hiện đại: 3-5 GHz = 3-5 TỶ cycles/giây!               ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.2 Fetch → Decode → Execute Cycle

```
╔═══════════════════════════════════════════════════════════════╗
║   FETCH-DECODE-EXECUTE — VÒNG LẶP BẤT TẬN                  ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  CPU lặp lại 3 bước này HÀNG TỶ lần mỗi giây:              ║
║                                                               ║
║       ┌──────────┐     ┌──────────┐     ┌──────────┐        ║
║       │  FETCH   │────►│  DECODE  │────►│ EXECUTE  │        ║
║       │          │     │          │     │          │        ║
║       │ Lấy      │     │ Giải mã  │     │ Thực thi │        ║
║       │ lệnh từ  │     │ lệnh     │     │ lệnh     │        ║
║       │ bộ nhớ   │     │ thành    │     │          │        ║
║       │          │     │ tín hiệu │     │          │        ║
║       └──────────┘     └──────────┘     └─────┬────┘        ║
║            ▲                                   │             ║
║            └───────────────────────────────────┘             ║
║                     Lặp lại mãi mãi                          ║
║                                                               ║
║  CHI TIẾT TỪNG BƯỚC:                                         ║
║                                                               ║
║  1. FETCH (Lấy lệnh):                                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Program Counter (PC) chứa ĐỊA CHỈ của   │             ║
║  │    instruction TIẾP THEO cần thực thi        │             ║
║  │  • CPU gửi địa chỉ ra memory bus            │             ║
║  │  • Memory trả về instruction (dạng binary)   │             ║
║  │  • Instruction được lưu vào Instruction      │             ║
║  │    Register (IR)                              │             ║
║  │  • PC tự động tăng lên (trỏ lệnh kế tiếp)  │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  2. DECODE (Giải mã):                                        ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Control Unit đọc instruction từ IR        │             ║
║  │  • Phân tích:                                 │             ║
║  │    → Opcode: làm GÌ? (cộng, trừ, nhảy...)  │             ║
║  │    → Operands: dùng DỮ LIỆU nào?            │             ║
║  │  • Tạo tín hiệu điều khiển cho ALU          │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  3. EXECUTE (Thực thi):                                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • ALU (Arithmetic Logic Unit) thực hiện     │             ║
║  │    phép tính hoặc logic                       │             ║
║  │  • Kết quả lưu vào Register hoặc Memory      │             ║
║  │  • Cập nhật flags (zero, carry, overflow)     │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.3 Bên trong CPU — Các thành phần chính

```
╔═══════════════════════════════════════════════════════════════╗
║   CẤU TRÚC BÊN TRONG CPU                                    ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ┌─────────────────────────────────────────────────────┐     ║
║  │                    CPU CHIP                          │     ║
║  │  ┌───────────────┐    ┌───────────────────────┐    │     ║
║  │  │ Control Unit   │    │  Registers            │    │     ║
║  │  │ (Bộ điều khiển)│    │  (Bộ nhớ siêu nhanh)  │    │     ║
║  │  │                │    │                       │    │     ║
║  │  │ → Giải mã lệnh│    │  → PC (Program Counter)│   │     ║
║  │  │ → Điều phối   │    │  → IR (Instruction Reg)│   │     ║
║  │  │   mọi thứ     │    │  → R0-R15 (General)   │    │     ║
║  │  │                │    │  → SP (Stack Pointer)  │    │     ║
║  │  │                │    │  → Flags Register     │    │     ║
║  │  └───────┬────────┘    └───────────┬───────────┘    │     ║
║  │          │                         │                │     ║
║  │          ▼                         ▼                │     ║
║  │  ┌─────────────────────────────────────────────┐    │     ║
║  │  │           ALU (Arithmetic Logic Unit)        │    │     ║
║  │  │                                             │    │     ║
║  │  │  Arithmetic: +, -, ×, ÷                     │    │     ║
║  │  │  Logic:      AND, OR, NOT, XOR              │    │     ║
║  │  │  Compare:    ==, <, >, !=                    │    │     ║
║  │  │  Shift:      <<, >>                          │    │     ║
║  │  └─────────────────────────────────────────────┘    │     ║
║  │                                                      │     ║
║  │  ┌───────────────────────────────────────────┐      │     ║
║  │  │  L1 Cache (32-64KB) — siêu nhanh (~1ns)  │      │     ║
║  │  │  L2 Cache (256KB-1MB)  — rất nhanh (~4ns) │      │     ║
║  │  └───────────────────────────────────────────┘      │     ║
║  └─────────────────────────────────────────────────────┘     ║
║                              │                                ║
║                    Memory Bus │                                ║
║                              ▼                                ║
║  ┌─────────────────────────────────────────────────────┐     ║
║  │  L3 Cache (Shared, 8-32MB)         (~10ns)          │     ║
║  └─────────────────────────────────────────────────────┘     ║
║                              │                                ║
║                              ▼                                ║
║  ┌─────────────────────────────────────────────────────┐     ║
║  │  RAM (8-128GB)                      (~100ns)        │     ║
║  └─────────────────────────────────────────────────────┘     ║
║                                                               ║
║  REGISTERS — Tại sao quan trọng?                             ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • TỐC ĐỘ: truy cập trong < 1 nanosecond   │             ║
║  │  • SỐ LƯỢNG: rất ít (thường 16-32 cái)     │             ║
║  │  • KÍCH THƯỚC: 32 hoặc 64 bits mỗi cái     │             ║
║  │  • CPU CHỈ tính toán với dữ liệu TRONG      │             ║
║  │    registers! Muốn tính → phải LOAD vào     │             ║
║  │    register trước!                            │             ║
║  │                                                │             ║
║  │  → Đây là lý do compiler OPTIMIZE để giữ     │             ║
║  │    biến trong register càng lâu càng tốt!    │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.4 Instruction Pipelining — Dây chuyền sản xuất của CPU

Nếu CPU chỉ làm Fetch → Decode → Execute tuần tự cho MỖI instruction, nó sẽ **lãng phí cực kỳ nhiều tài nguyên**. Hãy tưởng tượng một nhà máy mà mỗi khi có 1 sản phẩm đang ở khâu đóng gói thì khâu sản xuất và kiểm tra đều... NGỒI KHÔNG.

Giải pháp? **Instruction Pipelining** — làm giống dây chuyền lắp ráp nhà máy.

```
╔═══════════════════════════════════════════════════════════════╗
║   INSTRUCTION PIPELINING — DÂY CHUYỀN SẢN XUẤT              ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  KHÔNG CÓ Pipeline (tuần tự):                                ║
║                                                               ║
║  Cycle:  1  2  3  4  5  6  7  8  9                           ║
║  Inst 1: F  D  E                                              ║
║  Inst 2:          F  D  E                                     ║
║  Inst 3:                   F  D  E                            ║
║  → 3 instructions mất 9 cycles!                              ║
║                                                               ║
║  ─────────────────────────────────────────────────────────    ║
║                                                               ║
║  CÓ Pipeline (chồng chéo):                                   ║
║                                                               ║
║  Cycle:  1  2  3  4  5                                       ║
║  Inst 1: F  D  E                                              ║
║  Inst 2:    F  D  E                                           ║
║  Inst 3:       F  D  E                                        ║
║  → 3 instructions chỉ mất 5 cycles!                          ║
║  → Mỗi cycle đều CÓ instruction hoàn thành!                 ║
║                                                               ║
║  Thực tế CPU hiện đại còn chia NHỎ HƠN NỮA:                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Pipeline THỰC TẾ = 14-20 stages:            │             ║
║  │                                                │             ║
║  │  Fetch1 → Fetch2 → Decode1 → Decode2 →      │             ║
║  │  Rename → Schedule → Dispatch → Execute1 →   │             ║
║  │  Execute2 → Memory → Writeback → Commit      │             ║
║  │                                                │             ║
║  │  → Càng nhiều stages → throughput CAO hơn    │             ║
║  │  → NHƯNG: penalty khi sai cũng NẶNG hơn     │             ║
║  │    (phải FLUSH toàn bộ pipeline!)             │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ⚠️ VẤN ĐỀ: Pipeline Hazards                                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. DATA HAZARD:                               │             ║
║  │     x = a + b    ← Inst 1                    │             ║
║  │     y = x + c    ← Inst 2 CẦN kết quả Inst 1│             ║
║  │     → Inst 2 phải CHỜ Inst 1 xong!          │             ║
║  │     → Giải pháp: Data Forwarding              │             ║
║  │       (chuyển kết quả trực tiếp, không qua   │             ║
║  │        register file)                          │             ║
║  │                                                │             ║
║  │  2. CONTROL HAZARD (Branch):                   │             ║
║  │     if (x > 0) {                               │             ║
║  │         // path A                              │             ║
║  │     } else {                                   │             ║
║  │         // path B                              │             ║
║  │     }                                          │             ║
║  │     → CPU KHÔNG BIẾT chọn path nào cho đến   │             ║
║  │       khi DECODE xong → pipeline stall!       │             ║
║  │     → Giải pháp: Branch Prediction!           │             ║
║  │                                                │             ║
║  │  3. STRUCTURAL HAZARD:                         │             ║
║  │     2 instructions cùng cần ALU →             │             ║
║  │     Giải pháp: duplicate hardware units       │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ Backend relevance:                                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Pipeline stall = giảm throughput CPU       │             ║
║  │  • Code có nhiều if/else lồng nhau → nhiều   │             ║
║  │    branch → nhiều misprediction → CHẬM       │             ║
║  │  • Branchless programming là kỹ thuật tối ưu │             ║
║  │    mà các database engine (PostgreSQL, etc.)  │             ║
║  │    sử dụng để tăng tốc query execution       │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.5 Branch Prediction — CPU đoán tương lai

Đây là một trong những kỹ thuật **quan trọng nhất** của CPU hiện đại. Câu hỏi kinh điển trên StackOverflow: _"Why is processing a sorted array faster than processing an unsorted array?"_ — có **27 triệu view** — 100% là về branch prediction.

```
╔═══════════════════════════════════════════════════════════════╗
║   BRANCH PREDICTION — CPU "ĐOÁN" TƯƠNG LAI                   ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  VẤN ĐỀ:                                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Pipeline có 14-20 stages.                    │             ║
║  │  Khi gặp `if`, CPU phải:                     │             ║
║  │  1. Đợi condition được tính xong             │             ║
║  │  2. MỚI BIẾT nhánh nào cần execute           │             ║
║  │  → Đợi = pipeline TRỐNG = lãng phí 14-20    │             ║
║  │    cycles = ~5-7 nanoseconds!                 │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  GIẢI PHÁP: ĐOÁN trước! (Branch Prediction)                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  CPU ĐOÁN nhánh nào sẽ được chọn              │             ║
║  │  → Bắt đầu execute nhánh đó NGAY, chưa cần  │             ║
║  │    biết condition                              │             ║
║  │                                                │             ║
║  │  Nếu ĐOÁN ĐÚNG → tiết kiệm 14-20 cycles!   │             ║
║  │  Nếu ĐOÁN SAI  → FLUSH pipeline → penalty   │             ║
║  │                   ~15-20 cycles!               │             ║
║  │                                                │             ║
║  │  CPU hiện đại đoán đúng: ~95-97%!            │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CÁC CHIẾN LƯỢC DỰ ĐOÁN:                                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Static Prediction (đơn giản):             │             ║
║  │     → Backward branch → PREDICT TAKEN         │             ║
║  │       (loop thường quay lại đầu)              │             ║
║  │     → Forward branch → PREDICT NOT TAKEN      │             ║
║  │       (điều kiện lỗi hiếm khi xảy ra)        │             ║
║  │                                                │             ║
║  │  2. Dynamic Prediction (thông minh):          │             ║
║  │     → 2-bit saturating counter:               │             ║
║  │                                                │             ║
║  │     ┌──────────┐   taken   ┌──────────┐      │             ║
║  │     │ Strongly │──────────►│ Weakly   │      │             ║
║  │     │ NOT taken│◄──────────│ NOT taken│      │             ║
║  │     └──────────┘ not taken └────┬─────┘      │             ║
║  │          ▲                      │ taken       │             ║
║  │          │ not taken            ▼             │             ║
║  │     ┌────┴─────┐          ┌──────────┐      │             ║
║  │     │ Weakly   │◄─────────│ Strongly │      │             ║
║  │     │ taken    │ not taken│ taken    │      │             ║
║  │     └──────────┘          └──────────┘      │             ║
║  │                                                │             ║
║  │  3. Neural Branch Prediction (AMD, Intel):    │             ║
║  │     → Dùng perceptron-based model             │             ║
║  │     → Học từ HISTORY pattern phức tạp        │             ║
║  │     → Accuracy > 97%!                         │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  VÍ DỤ KINH ĐIỂN — Sorted vs Unsorted Array:                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // Loop qua array, cộng nếu > 128            │             ║
║  │  for _, v := range data {                     │             ║
║  │      if v >= 128 {                            │             ║
║  │          sum += v                              │             ║
║  │      }                                         │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  SORTED array [0,1,...127,128,...255]:         │             ║
║  │  Branch pattern: NNNNN...NNNTTTTT...TTT       │             ║
║  │  → DỄ ĐOÁN! (~99% accuracy)                 │             ║
║  │                                                │             ║
║  │  UNSORTED array [random]:                      │             ║
║  │  Branch pattern: NTTNNTTTNNNTTNNN...          │             ║
║  │  → RANDOM! (~50% accuracy = tệ nhất)         │             ║
║  │  → Chênh lệch hiệu năng: 2-6x!              │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ Backend Relevance:                                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Database sort data trước khi filter        │             ║
║  │    → branch prediction giúp tốc độ!          │             ║
║  │  • Hot path (code chạy thường xuyên) nên     │             ║
║  │    có branch pattern ĐỀU ĐẶN                 │             ║
║  │  • Go sort.Slice trước khi filter = NHANH    │             ║
║  │    hơn filter rồi sort (trên data lớn)       │             ║
║  │  • Likely/unlikely hints trong C/Go compiler │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.6 Out-of-Order Execution — CPU không tuân lệnh bạn

Một sự thật gây sốc: **CPU hiện đại KHÔNG thực thi code theo thứ tự bạn viết!** Nó tự sắp xếp lại thứ tự để tối ưu, miễn kết quả cuối cùng GIỐNG NHƯ chạy tuần tự.

```
╔═══════════════════════════════════════════════════════════════╗
║   OUT-OF-ORDER EXECUTION (OoOE)                              ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  VẤN ĐỀ:                                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  inst1: a = LOAD [memory]  ← chờ ~100 cycles│             ║
║  │  inst2: b = a + 1          ← phụ thuộc inst1│             ║
║  │  inst3: c = 5 * 3          ← KHÔNG phụ thuộc│             ║
║  │  inst4: d = 7 - 2          ← KHÔNG phụ thuộc│             ║
║  │                                                │             ║
║  │  In-order: inst1 → (chờ 100 cycles) →        │             ║
║  │            inst2 → inst3 → inst4              │             ║
║  │  → inst3 và inst4 BỊ BLOCK bởi inst1!       │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  GIẢI PHÁP: Out-of-Order Execution                           ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  CPU phát hiện inst3 & inst4 KHÔNG phụ thuộc │             ║
║  │  inst1 → thực thi CHÚNG TRƯỚC!              │             ║
║  │                                                │             ║
║  │  Reordered: inst1 → inst3 → inst4 → (inst1  │             ║
║  │             xong) → inst2                     │             ║
║  │  → KHÔNG lãng phí cycles!                    │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CƠ CHẾ HOẠT ĐỘNG:                                           ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. INSTRUCTION WINDOW (Reorder Buffer/ROB):  │             ║
║  │     CPU nhìn trước 100-200 instructions        │             ║
║  │     → Phân tích dependency graph              │             ║
║  │     → Tìm instructions ĐỘC LẬP              │             ║
║  │                                                │             ║
║  │  2. REGISTER RENAMING:                         │             ║
║  │     → Loại bỏ "false dependencies"            │             ║
║  │     VD: inst1 dùng R1, inst3 cũng dùng R1    │             ║
║  │     → CPU đổi tên: inst3 dùng R47 (internal) │             ║
║  │     → Giờ 2 inst SONG SONG được!             │             ║
║  │                                                │             ║
║  │  3. RETIREMENT (giữ nguyên thứ tự kết quả): │             ║
║  │     → Kết quả được COMMIT theo đúng thứ tự  │             ║
║  │       chương trình gốc                        │             ║
║  │     → Đảm bảo correctness!                   │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ⚠️ HỆ QUẢ QUAN TRỌNG CHO BACKEND:                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  MEMORY ORDERING PROBLEM:                      │             ║
║  │  ┌────────────────────────────────────────┐   │             ║
║  │  │  CPU có thể reorder memory writes!     │   │             ║
║  │  │                                        │   │             ║
║  │  │  Thread 1:        Thread 2:            │   │             ║
║  │  │  data = 42        for data != 0 {}     │   │             ║
║  │  │  ready = true     if ready {           │   │             ║
║  │  │                     use(data) //42?0?  │   │             ║
║  │  │                   }                    │   │             ║
║  │  │                                        │   │             ║
║  │  │  CPU có thể REORDER: ready = true      │   │             ║
║  │  │  TRƯỚC data = 42!                      │   │             ║
║  │  │  → Thread 2 thấy ready=true nhưng      │   │             ║
║  │  │    data vẫn = 0! → BUG!               │   │             ║
║  │  └────────────────────────────────────────┘   │             ║
║  │                                                │             ║
║  │  GIẢI PHÁP:                                    │             ║
║  │  • Memory Barriers / Fences                    │             ║
║  │  • Go: sync.Mutex, sync/atomic                │             ║
║  │  • sync/atomic.Store → đảm bảo memory order  │             ║
║  │  • Channels (Go) → tự động có memory barrier │             ║
║  │                                                │             ║
║  │  ☞ Đây là lý do Go khuyến khích dùng          │             ║
║  │    channels thay vì shared memory!            │             ║
║  │  ☞ "Do not communicate by sharing memory;     │             ║
║  │     share memory by communicating."            │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.7 Multi-Core, Hyper-Threading & SIMD

```
╔═══════════════════════════════════════════════════════════════╗
║   MULTI-CORE & PARALLELISM — TẠI SAO CÓ NHIỀU CORES?        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  LỊCH SỬ: Tại sao không cứ tăng tốc 1 core?                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  1. Power Wall: Tăng clock = tăng NHIỆT ĐỘ  │             ║
║  │     → P ∝ f³ (công suất tỷ lệ LẬP PHƯƠNG   │             ║
║  │       tần số!)                                │             ║
║  │     → Tăng 2x clock = tăng 8x nhiệt!        │             ║
║  │     → ~3GHz là giới hạn thực tế (năm 2004)  │             ║
║  │                                                │             ║
║  │  2. ILP Wall (Instruction-Level Parallelism): │             ║
║  │     → Đã khai thác HẾT parallelism trong     │             ║
║  │       single-thread rồi                        │             ║
║  │     → Thêm OoOE/Pipeline không giúp nhiều    │             ║
║  │                                                │             ║
║  │  → Giải pháp: NHIỀU cores SONG SONG!         │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  MULTI-CORE ARCHITECTURE:                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌─────────┐  ┌─────────┐  ┌─────────┐      │             ║
║  │  │ Core 0  │  │ Core 1  │  │ Core 2  │ ...  │             ║
║  │  │┌──┐┌──┐│  │┌──┐┌──┐│  │┌──┐┌──┐│      │             ║
║  │  ││L1││L1││  ││L1││L1││  ││L1││L1││      │             ║
║  │  │└──┘└──┘│  │└──┘└──┘│  │└──┘└──┘│      │             ║
║  │  │ ┌────┐ │  │ ┌────┐ │  │ ┌────┐ │      │             ║
║  │  │ │ L2 │ │  │ │ L2 │ │  │ │ L2 │ │      │             ║
║  │  │ └────┘ │  │ └────┘ │  │ └────┘ │      │             ║
║  │  └───┬────┘  └───┬────┘  └───┬────┘      │             ║
║  │      └───────────┼───────────┘             │             ║
║  │                  │                          │             ║
║  │         ┌────────┴────────┐                │             ║
║  │         │  L3 Cache       │ ← SHARED!      │             ║
║  │         │  (8-32MB)       │                │             ║
║  │         └────────┬────────┘                │             ║
║  │                  │                          │             ║
║  │         ┌────────┴────────┐                │             ║
║  │         │      RAM        │                │             ║
║  │         └─────────────────┘                │             ║
║  │                                                │             ║
║  │  Mỗi core = 1 CPU ĐỘC LẬP hoàn chỉnh!     │             ║
║  │  Có riêng: Registers, ALU, L1, L2            │             ║
║  │  Chia sẻ: L3 Cache, RAM, I/O                 │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  HYPER-THREADING (Simultaneous Multi-Threading):              ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1 physical core → 2 logical threads         │             ║
║  │                                                │             ║
║  │  ┌──────────────────────────────┐             │             ║
║  │  │  Physical Core 0             │             │             ║
║  │  │  ┌───────────┬───────────┐  │             │             ║
║  │  │  │ Thread 0  │ Thread 1  │  │             ║
║  │  │  │ Registers │ Registers │  │ ← RIÊNG    │             ║
║  │  │  └─────┬─────┴─────┬─────┘  │             │             ║
║  │  │        └─────┬─────┘        │             │             ║
║  │  │  ┌───────────┴───────────┐  │             │             ║
║  │  │  │   Shared ALU, Cache   │  │ ← CHUNG    │             ║
║  │  │  └───────────────────────┘  │             │             ║
║  │  └──────────────────────────────┘             │             ║
║  │                                                │             ║
║  │  → Khi Thread 0 chờ memory (stall)            │             ║
║  │  → CPU chuyển sang Thread 1 → tận dụng ALU! │             ║
║  │  → Tăng throughput ~15-30% (không phải 2x!)  │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ GẮN VỚI GO:                                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • GOMAXPROCS = số OS threads = số cores     │             ║
║  │  • Goroutines = user-space threads (nhẹ!)    │             ║
║  │  • Go scheduler map N goroutines → M threads │             ║
║  │  • N (goroutines) >> M (OS threads)!         │             ║
║  │                                                │             ║
║  │  VD: 8 cores → 8 OS threads                  │             ║
║  │      → 10,000 goroutines chạy trên 8 threads│             ║
║  │      → Go scheduler tự chuyển khi goroutine │             ║
║  │        bị block (I/O, channel, mutex)         │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CACHE COHERENCE — Bài toán multi-core:                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Core 0 L1 Cache: x = 42                      │             ║
║  │  Core 1 L1 Cache: x = 42                      │             ║
║  │                                                │             ║
║  │  Core 0 writes: x = 100                       │             ║
║  │  → Core 0 L1: x = 100 ✓                      │             ║
║  │  → Core 1 L1: x = 42  ✗ STALE!              │             ║
║  │                                                │             ║
║  │  Giải pháp: MESI Protocol                     │             ║
║  │  → Core 0 gửi "Invalidate" message           │             ║
║  │  → Core 1 đánh dấu x = INVALID               │             ║
║  │  → Core 1 phải fetch lại x từ Core 0 / RAM  │             ║
║  │                                                │             ║
║  │  ⚠️ FALSE SHARING:                           │             ║
║  │  → 2 biến KHÁC NHAU nằm cùng cache line!    │             ║
║  │  → Core 0 write biến A → INVALIDATE cả line │             ║
║  │  → Core 1 phải reload biến B (vô ích!)      │             ║
║  │  → Performance giảm 10-50x!                   │             ║
║  │                                                │             ║
║  │  // Go example — false sharing               │             ║
║  │  type Bad struct {                             │             ║
║  │      counterA int64 // Core 0                  │             ║
║  │      counterB int64 // Core 1, cùng cache line│             ║
║  │  }                                             │             ║
║  │  type Good struct {                            │             ║
║  │      counterA int64                            │             ║
║  │      _pad     [56]byte // đẩy sang cache line │             ║
║  │      counterB int64    // khác!                │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.8 CISC vs RISC — Hai triết lý thiết kế CPU

```
╔═══════════════════════════════════════════════════════════════╗
║   CISC vs RISC — TRIẾT LÝ THIẾT KẾ CPU                      ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  CISC (Complex Instruction Set Computer):                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Đại diện: Intel x86, AMD x86-64           │             ║
║  │  • Nhiều instructions phức tạp               │             ║
║  │  • 1 instruction có thể làm NHIỀU việc      │             ║
║  │  • VD: MOVSB — copy string byte-by-byte      │             ║
║  │    (bao gồm: load, store, increment, loop)   │             ║
║  │  • Instructions có CHIỀU DÀI KHÁC NHAU       │             ║
║  │    (1 byte → 15 bytes!)                      │             ║
║  │  • → Decode PHỨC TẠP, tốn transistors        │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  RISC (Reduced Instruction Set Computer):                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Đại diện: ARM, RISC-V, MIPS               │             ║
║  │  • Ít instructions, mỗi cái ĐƠN GIẢN        │             ║
║  │  • 1 instruction = 1 việc duy nhất           │             ║
║  │  • Instructions có CHIỀU DÀI CỐ ĐỊNH (4 bytes)│            ║
║  │  • → Decode ĐƠN GIẢN, pipeline hiệu quả    │             ║
║  │  • → Ít transistors → ít điện → ít nhiệt    │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  SO SÁNH:                                                     ║
║  ┌──────────────┬───────────────┬───────────────┐             ║
║  │              │ CISC (x86)     │ RISC (ARM)     │             ║
║  ├──────────────┼───────────────┼───────────────┤             ║
║  │ Instructions │ Nhiều, phức tạp│ Ít, đơn giản  │             ║
║  │ Inst length  │ Variable       │ Fixed (4B)     │             ║
║  │ Registers    │ Ít (16)       │ Nhiều (31)    │             ║
║  │ Pipeline     │ Khó tối ưu   │ Hiệu quả      │             ║
║  │ Điện năng   │ Cao            │ Thấp           │             ║
║  │ Ứng dụng   │ Server, PC     │ Mobile, IoT    │             ║
║  └──────────────┴───────────────┴───────────────┘             ║
║                                                               ║
║  THÚ VỊ: Ranh giới đang MỜ DẦN!                             ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Intel x86 bên trong thực ra DECODE thành  │             ║
║  │    micro-ops → giống RISC!                    │             ║
║  │  • Apple M-series (ARM) → mạnh ngang x86    │             ║
║  │    cho server workloads!                      │             ║
║  │  • AWS Graviton (ARM) → dùng cho EC2         │             ║
║  │    instances, rẻ hơn 40% so với x86!         │             ║
║  │  • Go cross-compile: GOOS + GOARCH dễ dàng  │             ║
║  │    → go build cho arm64, amd64               │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.9 CPU Clock, IPC và Thước đo hiệu năng thực sự

```
╔═══════════════════════════════════════════════════════════════╗
║   CPU PERFORMANCE — ĐỪNG CHỈ NHÌN GHz!                       ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Công thức hiệu năng CPU:                                     ║
║                                                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Performance = IPC × Clock Speed              │             ║
║  │                                                │             ║
║  │  IPC = Instructions Per Cycle                  │             ║
║  │  → Bao nhiêu instructions hoàn thành TRONG    │             ║
║  │    MỖI cycle?                                  │             ║
║  │                                                │             ║
║  │  Clock Speed = Bao nhiêu cycles/giây (GHz)    │             ║
║  │                                                │             ║
║  │  VÍ DỤ:                                       │             ║
║  │  • CPU A: IPC=2, Clock=4GHz → 8 tỷ inst/s   │             ║
║  │  • CPU B: IPC=4, Clock=3GHz → 12 tỷ inst/s  │             ║
║  │  → CPU B NHANH hơn dù clock thấp hơn!       │             ║
║  │                                                │             ║
║  │  → Apple M-series: IPC CAO + clock vừa phải  │             ║
║  │    = hiệu năng cao + tiết kiệm điện!        │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  SUPERSCALAR — Nhiều instructions CÙNG LÚC:                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  CPU hiện đại = SUPERSCALAR:                  │             ║
║  │  → Có NHIỀU execution units (ALU, FPU, Load, │             ║
║  │    Store, Branch)                              │             ║
║  │  → Có thể thực thi 4-8 instructions CÙNG LÚC│             ║
║  │    trong 1 cycle!                              │             ║
║  │                                                │             ║
║  │  Cycle 1:                                      │             ║
║  │  ┌──────┬──────┬──────┬──────┐               │             ║
║  │  │ ALU  │ ALU  │ Load │ Store│               │             ║
║  │  │inst1 │inst2 │inst3 │inst4 │               │             ║
║  │  └──────┴──────┴──────┴──────┘               │             ║
║  │  → 4 instructions trong 1 cycle! IPC=4       │             ║
║  │                                                │             ║
║  │  ☞ Nhưng: IPC < 4 thực tế vì dependencies   │             ║
║  │    và hazards → IPC trung bình ~2-3          │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ Backend Engineer cần biết:                                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Benchmark = thước đo duy nhất đáng tin    │             ║
║  │  • GHz MỘT MÌNH không nói lên performance   │             ║
║  │  • Go benchmarks: go test -bench -benchmem   │             ║
║  │  • Profile trước khi optimize!                │             ║
║  │  • "Premature optimization is the root of    │             ║
║  │    all evil" — Donald Knuth                   │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.10 Tại sao CPU chỉ hiểu 0 và 1?

Đây là câu hỏi mà hầu hết developer không bao giờ suy nghĩ sâu. Nhưng nếu bạn muốn đạt level Senior ở Big Tech, bạn cần hiểu "tại sao" ở tầng sâu nhất.

**Câu trả lời ngắn:** Vì transistor — thành phần cơ bản nhất của CPU — chỉ có 2 trạng thái: BẬT (1) hoặc TẮT (0).

**Câu trả lời sâu:**

Hãy tưởng tượng transistor như một **công tắc đèn siêu nhỏ**. Nó hoạt động bằng dòng điện:

- Có dòng điện chạy qua → **BẬT** → đại diện cho số **1**
- Không có dòng điện → **TẮT** → đại diện cho số **0**

```
╔═══════════════════════════════════════════════════════════════╗
║   TRANSISTOR — VIÊN GẠCH CỦA MỌI THỨ                        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Transistor = Công tắc điện tử siêu nhỏ (~5nm hiện tại)    ║
║                                                               ║
║  Chỉ 2 trạng thái:                                          ║
║  ┌──────────────┐     ┌──────────────┐                       ║
║  │   TẮT (OFF)  │     │   BẬT (ON)   │                       ║
║  │   = 0         │     │   = 1         │                       ║
║  │   Không điện  │     │   Có điện     │                       ║
║  │   ┌───┐       │     │   ┌───┐       │                       ║
║  │   │ ○ │ đèn tắt│    │   │ ● │ đèn sáng│                    ║
║  │   └───┘       │     │   └───┘       │                       ║
║  └──────────────┘     └──────────────┘                       ║
║                                                               ║
║  Tại sao KHÔNG dùng 3, 4, 10 trạng thái?                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  → Vì 2 trạng thái = DỄ phân biệt nhất!    │             ║
║  │  → Điện áp cao/thấp rõ ràng, ít lỗi        │             ║
║  │  → 3+ trạng thái → khó phân biệt → nhiều   │             ║
║  │    lỗi (noise, interference)                  │             ║
║  │  → Trade-off: đơn giản & tin cậy > phức tạp │             ║
║  │                                                │             ║
║  │  ☞ VD: Ternary computers (3 trạng thái)      │             ║
║  │    đã được thử nghiệm (Setun, Liên Xô 1958) │             ║
║  │    nhưng THẤT BẠI vì quá phức tạp để sản    │             ║
║  │    xuất linh kiện đáng tin cậy.               │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CPU hiện đại có BAO NHIÊU transistors?                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Intel 4004 (1971):         2,300          │             ║
║  │  • Intel Pentium (1993):      3.1 triệu     │             ║
║  │  • Intel i7 (2020):           ~10 TỶ        │             ║
║  │  • Apple M2 Ultra (2023):     ~134 TỶ       │             ║
║  │                                                │             ║
║  │  → Moore's Law: Số transistor tăng GẤP ĐÔI  │             ║
║  │    mỗi ~2 năm (1965-nay, đang chậm lại)     │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

Từ transistor, người ta xây dựng lên **Logic Gates** (cổng logic) — đây là phép tính cơ bản nhất:

```
    LOGIC GATES — Từ transistor → phép tính

    AND Gate (VÀ):          OR Gate (HOẶC):
    ┌──────────────┐        ┌──────────────┐
    │ A │ B │ OUT  │        │ A │ B │ OUT  │
    ├───┼───┼──────┤        ├───┼───┼──────┤
    │ 0 │ 0 │  0   │        │ 0 │ 0 │  0   │
    │ 0 │ 1 │  0   │        │ 0 │ 1 │  1   │
    │ 1 │ 0 │  0   │        │ 1 │ 0 │  1   │
    │ 1 │ 1 │  1   │        │ 1 │ 1 │  1   │
    └──────────────┘        └──────────────┘

    NOT Gate (PHỦ ĐỊNH):    XOR Gate (LOẠI TRỪ):
    ┌──────────┐            ┌──────────────┐
    │ A │ OUT  │            │ A │ B │ OUT  │
    ├───┼──────┤            ├───┼───┼──────┤
    │ 0 │  1   │            │ 0 │ 0 │  0   │
    │ 1 │  0   │            │ 0 │ 1 │  1   │
    └──────────┘            │ 1 │ 0 │  1   │
                            │ 1 │ 1 │  0   │
                            └──────────────┘

    Từ gates → xây ADDER (bộ cộng):
    ┌─────────────────────────────────────────────┐
    │  Half Adder (cộng 2 bit):                   │
    │                                              │
    │  A ──┬──► XOR ──► Sum                       │
    │      │                                       │
    │  B ──┼──► AND ──► Carry                     │
    │      │                                       │
    │  VD: 1 + 1 = Sum=0, Carry=1 → kết quả: 10 │
    │  (trong binary: 1 + 1 = 10 = số 2)          │
    └─────────────────────────────────────────────┘

    Từ adder → xây ALU → xây CPU!

    Transistor → Gates → Adder → ALU → CPU
    (vật lý)    (logic)  (toán)  (xử lý) (máy tính)
```

**Tại sao điều này quan trọng cho backend engineer?**

Vì khi bạn viết `a + b` trong Go, đây là hành trình thực sự:

```
    a + b (trong Go code)
      │
      ▼
    Compiler → translate thành machine instruction
      │         (VD: ADD R1, R2)
      ▼
    CPU Fetch instruction từ memory
      │
      ▼
    CPU Decode: "đây là phép cộng, dùng R1 và R2"
      │
      ▼
    ALU nhận R1 và R2 → thực hiện phép cộng
      │                  (dùng hàng tỷ transistors)
      ▼
    Kết quả lưu vào R3 (register)
      │
      ▼
    Nếu cần → ghi từ R3 ra RAM

    Thời gian: < 1 nanosecond cho 1 phép cộng!
    (1 ns = 1/1,000,000,000 giây)
```

### 1.11 Speculative Execution — Khi CPU đoán sai gây ra lỗ hổng bảo mật

Phần 1.5 (Branch Prediction) và 1.6 (Out-of-Order Execution) cho thấy CPU hiện đại "đoán trước" và "thực thi trước" để tăng tốc. Nhưng khi kết hợp 2 kỹ thuật này, một hệ quả nguy hiểm đã xảy ra: **Spectre** và **Meltdown** — hai lỗ hổng bảo mật lớn nhất trong lịch sử phần cứng (công bố tháng 1/2018).

```
╔═══════════════════════════════════════════════════════════════╗
║   SPECULATIVE EXECUTION & SECURITY                           ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  SPECULATIVE EXECUTION = Branch Prediction + OoOE:           ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  CPU ĐOÁN kết quả branch → thực thi          │             ║
║  │  TRƯỚC KHI biết kết quả thật.                │             ║
║  │                                                │             ║
║  │  Nếu đúng → tiết kiệm thời gian              │             ║
║  │  Nếu sai  → ROLLBACK kết quả                │             ║
║  │             → NHƯNG: side effects             │             ║
║  │               (cache state) KHÔNG rollback!   │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  MELTDOWN (CVE-2017-5754):                                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // Pseudo-code của attack:                   │             ║
║  │  data = kernel_memory[secret_address]         │             ║
║  │  // ↑ Bình thường → SEGFAULT (cấm!)         │             ║
║  │  // NHƯNG: CPU đã speculate READ rồi!        │             ║
║  │                                                │             ║
║  │  temp = probe_array[data * 4096]              │             ║
║  │  // ↑ data được dùng làm INDEX                │             ║
║  │  // → probe_array page tương ứng VÀO CACHE  │             ║
║  │                                                │             ║
║  │  // Sau khi rollback, đo thời gian truy cập  │             ║
║  │  // mỗi page của probe_array:                │             ║
║  │  // NHANH = đã trong cache = đó là giá trị!  │             ║
║  │                                                │             ║
║  │  → Đọc được TOÀN BỘ kernel memory!          │             ║
║  │  → Ảnh hưởng: INTEL CPUs (AMD ít bị)        │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  SPECTRE (CVE-2017-5753, CVE-2017-5715):                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // Training branch predictor:                │             ║
║  │  for i := 0; i < 100; i++ {                   │             ║
║  │      if i < len(array) {  // TRUE 100 lần    │             ║
║  │          _ = array[i]     // train: TAKEN     │             ║
║  │      }                                         │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  // Attack: i = OUT_OF_BOUNDS                  │             ║
║  │  // Branch predictor vẫn ĐOÁN: TAKEN!        │             ║
║  │  // → CPU speculatively đọc array[OOB]       │             ║
║  │  // → Dùng giá trị đọc được để access cache  │             ║
║  │  // → Timing attack để đoán giá trị          │             ║
║  │                                                │             ║
║  │  → Ảnh hưởng: TẤT CẢ modern CPUs!           │             ║
║  │  → Vì đây là design flaw, không phải bug     │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ẢNH HƯỞNG TỚI BACKEND:                                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Kernel patches (KPTI/KAISER):              │             ║
║  │     → Tách kernel page table khỏi user space  │             ║
║  │     → syscall CHẬM hơn 5-30%!                │             ║
║  │     → Database, nginx, mọi I/O-heavy service │             ║
║  │       đều bị ảnh hưởng!                       │             ║
║  │                                                │             ║
║  │  2. Cloud providers (AWS, GCP, Azure):         │             ║
║  │     → Phải patch hypervisor → restart VMs     │             ║
║  │     → Performance giảm trên shared hardware   │             ║
║  │                                                │             ║
║  │  3. Retpoline (return trampoline):             │             ║
║  │     → Compiler mitigation cho Spectre v2      │             ║
║  │     → Go compiler cũng phải update!           │             ║
║  │                                                │             ║
║  │  ☞ BÀI HỌC: Performance optimization ở tầng  │             ║
║  │    hardware có thể TẠO RA lỗ hổng bảo mật.  │             ║
║  │    → Trade-off: Speed vs Security             │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.12 Interrupts & System Calls — CPU phục vụ OS

Khi bạn gọi `http.ListenAndServe()` trong Go, bên dưới tất cả các abstraction là **system calls** — yêu cầu CPU chuyển sang **kernel mode** để tương tác với hardware. Đây là cầu nối giữa software và hardware.

```
╔═══════════════════════════════════════════════════════════════╗
║   INTERRUPTS & SYSTEM CALLS                                  ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  CPU có 2 CHẾ ĐỘ HOẠT ĐỘNG:                                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌─────────────────────────────────────────┐  │             ║
║  │  │  USER MODE (Ring 3)                      │  │             ║
║  │  │  → Chạy application code (Go, Java...)  │  │             ║
║  │  │  → KHÔNG thể truy cập hardware trực tiếp│  │             ║
║  │  │  → KHÔNG thể đọc memory process khác     │  │             ║
║  │  │  → Hạn chế instructions được phép dùng  │  │             ║
║  │  └────────────────────┬────────────────────┘  │             ║
║  │                       │ syscall                │             ║
║  │                       ▼                        │             ║
║  │  ┌─────────────────────────────────────────┐  │             ║
║  │  │  KERNEL MODE (Ring 0)                    │  │             ║
║  │  │  → Chạy OS kernel code                  │  │             ║
║  │  │  → TOÀN QUYỀN truy cập hardware        │  │             ║
║  │  │  → Quản lý memory, I/O, scheduling      │  │             ║
║  │  │  → Chỉ OS kernel mới chạy ở đây       │  │             ║
║  │  └─────────────────────────────────────────┘  │             ║
║  │                                                │             ║
║  │  Tại sao cần 2 mode?                          │             ║
║  │  → ISOLATION! App lỗi không crash OS          │             ║
║  │  → SECURITY! App không thể đọc data app khác │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  SYSTEM CALL (SYSCALL) — Cầu nối App → Kernel:               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Khi Go code cần I/O:                          │             ║
║  │                                                │             ║
║  │  // Go code                                    │             ║
║  │  file, _ := os.Open("data.txt")               │             ║
║  │    │                                           │             ║
║  │    ▼                                           │             ║
║  │  // Go runtime gọi syscall                    │             ║
║  │  syscall.Open("data.txt", O_RDONLY, 0)         │             ║
║  │    │                                           │             ║
║  │    ▼                                           │             ║
║  │  // CPU chuyển từ User → Kernel mode          │             ║
║  │  // (qua SYSCALL instruction trên x86-64)     │             ║
║  │  // Bước này TỐN ~100-1000 ns!               │             ║
║  │    │                                           │             ║
║  │    ▼                                           │             ║
║  │  // Kernel: kiểm tra quyền, tìm file,        │             ║
║  │  // tạo file descriptor, trả về cho user      │             ║
║  │    │                                           │             ║
║  │    ▼                                           │             ║
║  │  // CPU chuyển Kernel → User mode             │             ║
║  │  // Trả kết quả cho Go code                   │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  INTERRUPTS — Hardware "gõ cửa" CPU:                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  CPU đang thực thi code bình thường...        │             ║
║  │                                                │             ║
║  │  BỖM! Network card: "Có packet mới!"         │             ║
║  │    │                                           │             ║
║  │    ▼                                           │             ║
║  │  1. CPU DỪNG instruction hiện tại              │             ║
║  │  2. Lưu trạng thái (registers → stack)        │             ║
║  │  3. Nhảy đến Interrupt Handler (ISR)           │             ║
║  │  4. Xử lý interrupt (đọc packet)              │             ║
║  │  5. Khôi phục trạng thái                       │             ║
║  │  6. Tiếp tục instruction cũ                   │             ║
║  │                                                │             ║
║  │  TYPES:                                         │             ║
║  │  • Hardware Interrupt: NIC, disk, keyboard     │             ║
║  │  • Software Interrupt: syscall, exception      │             ║
║  │  • Timer Interrupt: OS scheduler (~1-10ms)     │             ║
║  │    → Đây là cách OS "cướp" CPU từ process!    │             ║
║  │    → Preemptive multitasking!                  │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ GẮN VỚI GO RUNTIME:                                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  • Go scheduler dùng signal-based preemption  │             ║
║  │    (từ Go 1.14+) → gửi SIGURG signal         │             ║
║  │  • Trước Go 1.14: goroutine chỉ bị preempt   │             ║
║  │    tại function call → tight loop = BLOCK     │             ║
║  │    toàn bộ OS thread!                         │             ║
║  │                                                │             ║
║  │  // Pre-Go 1.14 problem:                      │             ║
║  │  go func() {                                   │             ║
║  │      for { /* infinite loop, no func call */ } │             ║
║  │  }()                                           │             ║
║  │  // ↑ BLOCK thread! Scheduler không preempt!  │             ║
║  │                                                │             ║
║  │  // Go 1.14+: dùng async preemption          │             ║
║  │  // → OS gửi signal → Go runtime xử lý      │             ║
║  │  // → Goroutine bị dừng → scheduler chạy     │             ║
║  │                                                │             ║
║  │  • Mỗi syscall: Go runtime có thể HANDOFF     │             ║
║  │    goroutine sang thread khác!                 │             ║
║  │  • epoll/kqueue: Go dùng để TRÁNH block      │             ║
║  │    thread cho network I/O                      │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  SYSCALL OVERHEAD — Tại sao Backend cần biết:                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Mỗi syscall tốn ~100-1000 ns:                │             ║
║  │  • Context switch: save/restore registers     │             ║
║  │  • TLB flush (có thể)                         │             ║
║  │  • Cache pollution                             │             ║
║  │                                                │             ║
║  │  Strategies để giảm syscalls:                  │             ║
║  │  • Buffered I/O: bufio.Writer thay vì         │             ║
║  │    ghi từng byte → 1 syscall cho N bytes      │             ║
║  │  • io.Copy: dùng sendfile syscall (zero-copy) │             ║
║  │  • mmap: map file vào memory, tránh          │             ║
║  │    read/write syscalls                         │             ║
║  │  • Connection pooling: tránh socket            │             ║
║  │    creation syscalls lặp lại                   │             ║
║  │                                                │             ║
║  │  // Bad: 1000 syscalls                         │             ║
║  │  for i := 0; i < 1000; i++ {                   │             ║
║  │      file.Write([]byte{data[i]}) // 1 syscall │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  // Good: ~1 syscall                           │             ║
║  │  w := bufio.NewWriter(file)                    │             ║
║  │  for i := 0; i < 1000; i++ {                   │             ║
║  │      w.WriteByte(data[i]) // buffer in memory │             ║
║  │  }                                             │             ║
║  │  w.Flush() // 1 syscall!                       │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.13 Instruction Set Architecture (ISA) — "Ngôn ngữ" của CPU

ISA là **hợp đồng** giữa phần cứng và phần mềm. Nó quy định CPU "hiểu" được những instructions nào, registers nào có sẵn, cách memory addressing hoạt động. Khi bạn chạy `GOARCH=amd64 go build`, Go compiler sinh ra instructions theo ISA của x86-64.

```
╔═══════════════════════════════════════════════════════════════╗
║   ISA — INSTRUCTION SET ARCHITECTURE                         ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ISA = "API" CỦA CPU:                                        ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Giống như REST API định nghĩa endpoints,     │             ║
║  │  ISA định nghĩa:                               │             ║
║  │                                                │             ║
║  │  1. INSTRUCTIONS: những gì CPU làm được       │             ║
║  │     → ADD, SUB, MUL, MOV, CMP, JMP, CALL...  │             ║
║  │                                                │             ║
║  │  2. REGISTERS: "biến" bên trong CPU           │             ║
║  │     → x86-64: RAX, RBX, RCX, RDX, RSP, RBP..│             ║
║  │     → ARM64:  X0-X30, SP, PC                  │             ║
║  │                                                │             ║
║  │  3. ADDRESSING MODES: cách truy cập memory    │             ║
║  │     → Direct:   MOV RAX, [0x1000]             │             ║
║  │     → Indirect: MOV RAX, [RBX]                │             ║
║  │     → Indexed:  MOV RAX, [RBX + RCX*8]       │             ║
║  │                                                │             ║
║  │  4. DATA TYPES: integer, float, vector...     │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  XEM ASSEMBLY CỦA GO CODE:                                   ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // main.go                                    │             ║
║  │  func add(a, b int) int {                     │             ║
║  │      return a + b                              │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  $ go tool compile -S main.go                 │             ║
║  │                                                │             ║
║  │  // Output (x86-64 assembly):                 │             ║
║  │  "".add STEXT nosplit size=15                  │             ║
║  │    MOVQ  "".a+8(SP), AX   // load a → AX     │             ║
║  │    ADDQ  "".b+16(SP), AX  // AX = a + b      │             ║
║  │    MOVQ  AX, "".~r0+24(SP)// store result    │             ║
║  │    RET                      // return          │             ║
║  │                                                │             ║
║  │  // Output (ARM64 assembly/Apple Silicon):    │             ║
║  │  "".add STEXT nosplit size=12                  │             ║
║  │    MOVD  "".a+8(RSP), R0  // load a → R0     │             ║
║  │    ADD   "".b+16(RSP), R0 // R0 = a + b      │             ║
║  │    MOVD  R0, "".~r0+24(RSP)// store result   │             ║
║  │    RET                                         │             ║
║  │                                                │             ║
║  │  → CÙNG Go code, KHÁC machine instructions!  │             ║
║  │  → ISA khác = binary KHÔNG tương thích!      │             ║
║  │  → Go cross-compile giải quyết chuyện này    │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CALLING CONVENTION — Cách hàm "nói chuyện":                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Khi gọi function, CPU cần biết:              │             ║
║  │  → Arguments ở đâu? Stack hay registers?      │             ║
║  │  → Return value ở đâu?                        │             ║
║  │  → Ai cleanup stack? Caller hay callee?       │             ║
║  │                                                │             ║
║  │  Go Calling Convention (trước Go 1.17):       │             ║
║  │  → TẤT CẢ arguments trên STACK              │             ║
║  │  → Đơn giản nhưng CHẬM (memory access!)     │             ║
║  │                                                │             ║
║  │  Go 1.17+ (Register-based):                   │             ║
║  │  → Arguments đầu tiên trong REGISTERS        │             ║
║  │  → Benchmark: nhanh hơn ~5% overall!         │             ║
║  │  → Giống C/C++/Rust calling convention        │             ║
║  │                                                │             ║
║  │  ☞ Đây là upgrade "FREE" — chỉ cần nâng     │             ║
║  │    Go version, code không đổi, nhanh hơn 5%! │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.14 Thực hành — Go Benchmarks chứng minh lý thuyết CPU

Lý thuyết không đủ! Dưới đây là các Go benchmarks thực tế mà bạn có thể chạy để **TẬN MẮT** thấy ảnh hưởng của CPU architecture lên performance. Mỗi benchmark tương ứng với một khái niệm đã học.

```go
// cpu_bench_test.go — Chạy: go test -bench=. -benchmem

package cpubench

import (
    "math/rand"
    "sort"
    "sync"
    "sync/atomic"
    "testing"
)

// ═══════════════════════════════════════════════════════
// BENCHMARK 1: Branch Prediction (Sorted vs Unsorted)
// Tương ứng: §1.5 Branch Prediction
// ═══════════════════════════════════════════════════════

func BenchmarkBranchPrediction_Sorted(b *testing.B) {
    data := make([]int, 100_000)
    for i := range data {
        data[i] = rand.Intn(256)
    }
    sort.Ints(data) // ← SORTED!

    b.ResetTimer()
    for n := 0; n < b.N; n++ {
        sum := 0
        for _, v := range data {
            if v >= 128 {
                sum += v
            }
        }
    }
}

func BenchmarkBranchPrediction_Unsorted(b *testing.B) {
    data := make([]int, 100_000)
    for i := range data {
        data[i] = rand.Intn(256)
    }
    // UNSORTED! → branch prediction ~50%

    b.ResetTimer()
    for n := 0; n < b.N; n++ {
        sum := 0
        for _, v := range data {
            if v >= 128 {
                sum += v
            }
        }
    }
}
// KỲ VỌNG: Sorted nhanh hơn 2-6x!

// ═══════════════════════════════════════════════════════
// BENCHMARK 2: False Sharing (Cache Coherence)
// Tương ứng: §1.7 Multi-Core — Cache Coherence
// ═══════════════════════════════════════════════════════

type CounterBad struct {
    a int64
    b int64 // ← cùng cache line với a!
}

type CounterGood struct {
    a int64
    _ [56]byte // padding → đẩy b sang cache line khác
    b int64
}

func BenchmarkFalseSharing_Bad(b *testing.B) {
    var c CounterBad
    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            atomic.AddInt64(&c.a, 1)
            atomic.AddInt64(&c.b, 1)
        }
    })
}

func BenchmarkFalseSharing_Good(b *testing.B) {
    var c CounterGood
    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            atomic.AddInt64(&c.a, 1)
            atomic.AddInt64(&c.b, 1)
        }
    })
}
// KỲ VỌNG: Good nhanh hơn 2-10x trên multi-core!

// ═══════════════════════════════════════════════════════
// BENCHMARK 3: Syscall Overhead (Buffered vs Unbuffered)
// Tương ứng: §1.12 Interrupts & System Calls
// ═══════════════════════════════════════════════════════

func BenchmarkLockContention_Mutex(b *testing.B) {
    var mu sync.Mutex
    var counter int64
    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            mu.Lock()
            counter++
            mu.Unlock()
        }
    })
}

func BenchmarkLockContention_Atomic(b *testing.B) {
    var counter int64
    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            atomic.AddInt64(&counter, 1)
        }
    })
}
// KỲ VỌNG: Atomic nhanh hơn 5-20x!
// → Mutex = syscall (futex) khi contention
// → Atomic = CPU instruction (LOCK XADD), no syscall!

// ═══════════════════════════════════════════════════════
// BENCHMARK 4: Sequential vs Random Memory Access
// Tương ứng: §1.3 Registers & Cache, §2 Memory Hierarchy
// ═══════════════════════════════════════════════════════

func BenchmarkMemAccess_Sequential(b *testing.B) {
    data := make([]int64, 1_000_000)
    b.ResetTimer()
    for n := 0; n < b.N; n++ {
        sum := int64(0)
        for i := 0; i < len(data); i++ {
            sum += data[i] // sequential → cache friendly
        }
    }
}

func BenchmarkMemAccess_Random(b *testing.B) {
    data := make([]int64, 1_000_000)
    indices := make([]int, 1_000_000)
    for i := range indices {
        indices[i] = rand.Intn(len(data))
    }
    b.ResetTimer()
    for n := 0; n < b.N; n++ {
        sum := int64(0)
        for _, idx := range indices {
            sum += data[idx] // random → cache miss!
        }
    }
}
// KỲ VỌNG: Sequential nhanh hơn 3-10x!
// → Spatial locality + CPU prefetcher
```

```
╔═══════════════════════════════════════════════════════════════╗
║   CHẠY VÀ ĐỌC KẾT QUẢ BENCHMARK                            ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  $ go test -bench=. -benchmem -cpu=1,4,8                     ║
║                                                               ║
║  Kết quả mẫu (Apple M2, 8 cores):                            ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  BenchmarkBranchPrediction_Sorted-8             ║
║  │    →     5000   231456 ns/op    0 B/op          ║
║  │  BenchmarkBranchPrediction_Unsorted-8           ║
║  │    →     1000   892341 ns/op    0 B/op          ║
║  │  → Sorted NHANH HƠN ~3.8x! Branch prediction! ║
║  │                                                  ║
║  │  BenchmarkFalseSharing_Bad-8                    ║
║  │    → 10000000    45.2 ns/op                     ║
║  │  BenchmarkFalseSharing_Good-8                   ║
║  │    → 50000000     8.3 ns/op                     ║
║  │  → Good NHANH HƠN ~5.4x! Cache coherence!      ║
║  │                                                  ║
║  │  BenchmarkLockContention_Mutex-8                ║
║  │    → 20000000    62.1 ns/op                     ║
║  │  BenchmarkLockContention_Atomic-8               ║
║  │    → 100000000   11.4 ns/op                     ║
║  │  → Atomic NHANH HƠN ~5.4x! No syscall!         ║
║  │                                                  ║
║  │  BenchmarkMemAccess_Sequential-8                ║
║  │    →     2000   612340 ns/op                    ║
║  │  BenchmarkMemAccess_Random-8                    ║
║  │    →      300  4521000 ns/op                    ║
║  │  → Sequential NHANH HƠN ~7.4x! Cache locality! ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ MỌI con số ở trên đều là KẾT QUẢ TRỰC TIẾP             ║
║    của kiến trúc CPU mà bạn đã học:                          ║
║    • Branch prediction → sorted vs unsorted                  ║
║    • Cache coherence → false sharing                         ║
║    • Syscall overhead → mutex vs atomic                      ║
║    • Spatial locality → sequential vs random                 ║
║                                                               ║
║  → Chạy thử trên máy bạn để THẤY bằng chứng!              ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.15 Latency Numbers Every Backend Engineer Should Know

Bảng dưới đây kết nối TẤT CẢ khái niệm CPU đã học vào một bức tranh thống nhất về thời gian:

```
╔═══════════════════════════════════════════════════════════════╗
║   LATENCY NUMBERS (2024) — PHẢI THUỘC LÒNG!                 ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ┌────────────────────────────────┬──────────┬──────────┐    ║
║  │ Operation                      │ Latency  │ So sánh  │    ║
║  ├────────────────────────────────┼──────────┼──────────┤    ║
║  │ CPU cycle (1/freq)             │ ~0.3 ns  │ 1 giây   │    ║
║  │ L1 cache access                │ ~1 ns    │ 3 giây   │    ║
║  │ Branch misprediction           │ ~5 ns    │ 15 giây  │    ║
║  │ L2 cache access                │ ~4 ns    │ 12 giây  │    ║
║  │ L3 cache access                │ ~10 ns   │ 30 giây  │    ║
║  │ Mutex lock/unlock              │ ~17 ns   │ 51 giây  │    ║
║  │ RAM access                     │ ~100 ns  │ 5 phút   │    ║
║  │ Syscall (Linux)                │ ~500 ns  │ 25 phút  │    ║
║  │ Context switch                 │ ~1 μs    │ 50 phút  │    ║
║  │ Goroutine switch               │ ~200 ns  │ 10 phút  │    ║
║  │ 1KB sequential SSD read        │ ~2 μs    │ 1.6 giờ  │    ║
║  │ 1MB sequential RAM read        │ ~9 μs    │ 7.5 giờ  │    ║
║  │ TCP same datacenter            │ ~500 μs  │ 17 ngày  │    ║
║  │ 1MB sequential SSD read        │ ~200 μs  │ 7 ngày   │    ║
║  │ 1MB sequential HDD read        │ ~5 ms    │ 5 tháng  │    ║
║  │ HDD random seek                │ ~10 ms   │ 10 tháng │    ║
║  │ TCP SF → NYC                   │ ~40 ms   │ 3.3 năm  │    ║
║  │ TCP SF → London                │ ~80 ms   │ 6.6 năm  │    ║
║  │ TCP SF → Sydney                │ ~150 ms  │ 12 năm   │    ║
║  └────────────────────────────────┴──────────┴──────────┘    ║
║                                                               ║
║  CỘT "So sánh" = nếu 1 CPU cycle = 1 GIÂY thì:             ║
║  → RAM access = 5 PHÚT (rất lâu so với CPU!)               ║
║  → HDD seek = 10 THÁNG!!! (vì thế cần cache!)              ║
║  → Cross-continent = 12 NĂM (vì thế cần CDN!)             ║
║                                                               ║
║  ☞ SẮP XẾP THEO NHÓM:                                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  CPU-INTERNAL (0.3 - 100 ns):                  │             ║
║  │  → Register, L1, L2, L3, RAM                  │             ║
║  │  → Tối ưu = cache locality, alignment         │             ║
║  │                                                │             ║
║  │  OS-LEVEL (200 ns - 10 μs):                    │             ║
║  │  → Syscall, context switch, goroutine switch  │             ║
║  │  → Tối ưu = buffered I/O, epoll, goroutines  │             ║
║  │                                                │             ║
║  │  STORAGE (2 μs - 10 ms):                       │             ║
║  │  → SSD read, HDD seek                         │             ║
║  │  → Tối ưu = sequential access, caching        │             ║
║  │                                                │             ║
║  │  NETWORK (500 μs - 150 ms):                    │             ║
║  │  → Datacenter, cross-region, cross-continent  │             ║
║  │  → Tối ưu = CDN, edge computing, batching     │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.16 SIMD — Một lệnh, xử lý nhiều dữ liệu cùng lúc

SIMD (Single Instruction, Multiple Data) được nhắc ở mục 1.7 nhưng xứng đáng một phần riêng. Đây là kỹ thuật giúp CPU xử lý **nhiều dữ liệu cùng lúc** bằng **một instruction duy nhất** — nền tảng của mọi tối ưu hóa multimedia, AI, database engine.

```
╔═══════════════════════════════════════════════════════════════╗
║   SIMD — SINGLE INSTRUCTION, MULTIPLE DATA                   ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Scalar (bình thường) vs SIMD:                                ║
║                                                               ║
║  SCALAR:                                                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  A[0] + B[0] → C[0]   // 1 cycle             │             ║
║  │  A[1] + B[1] → C[1]   // 1 cycle             │             ║
║  │  A[2] + B[2] → C[2]   // 1 cycle             │             ║
║  │  A[3] + B[3] → C[3]   // 1 cycle             │             ║
║  │  → 4 phép cộng = 4 cycles                    │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  SIMD:                                                        ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  ┌──────────────────┐  ┌──────────────────┐  │             ║
║  │  │A[0]│A[1]│A[2]│A[3]│ +│B[0]│B[1]│B[2]│B[3]│ │             ║
║  │  └────┬─────────────┘  └────┬─────────────┘  │             ║
║  │       └────────┬────────────┘                  │             ║
║  │                ▼                                │             ║
║  │  ┌──────────────────┐                          │             ║
║  │  │C[0]│C[1]│C[2]│C[3]│                         │             ║
║  │  └──────────────────┘                          │             ║
║  │  → 4 phép cộng = 1 cycle! (4x nhanh hơn!)   │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CÁC THẾ HỆ SIMD:                                            ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Intel/AMD:                                    │             ║
║  │  • SSE  (1999): 128-bit → 4 float32 cùng lúc│             ║
║  │  • AVX  (2011): 256-bit → 8 float32 cùng lúc│             ║
║  │  • AVX-512(2016):512-bit→ 16 float32 cùng lúc│            ║
║  │                                                │             ║
║  │  ARM:                                          │             ║
║  │  • NEON: 128-bit → dùng trong mobile         │             ║
║  │  • SVE:  scalable → cho server (AWS Graviton) │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ỨNG DỤNG THỰC TẾ:                                           ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Database:                                  │             ║
║  │     → ClickHouse: SIMD scan columns nhanh     │             ║
║  │     → PostgreSQL: SIMD cho hash joins         │             ║
║  │                                                │             ║
║  │  2. JSON Parsing:                              │             ║
║  │     → simdjson: parse JSON nhanh hơn 4x!     │             ║
║  │     → Dùng SIMD để tìm delimiters song song  │             ║
║  │                                                │             ║
║  │  3. Networking:                                │             ║
║  │     → Checksum computation (TCP/UDP)           │             ║
║  │     → Encryption (AES-NI instructions)        │             ║
║  │                                                │             ║
║  │  4. Go standard library:                       │             ║
║  │     → bytes.Equal → SIMD so sánh nhanh       │             ║
║  │     → strings.Index → SIMD tìm kiếm          │             ║
║  │     → crypto/aes → AES-NI hardware           │             ║
║  │     → math/bits → hardware POPCNT              │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  GO VÀ SIMD:                                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Go compiler TỰ ĐỘNG vectorize một số pattern:│             ║
║  │                                                │             ║
║  │  // Compiler CÓ THỂ auto-vectorize:           │             ║
║  │  for i := range a {                            │             ║
║  │      c[i] = a[i] + b[i]  // simple add loop  │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  // Kiểm tra assembly output:                 │             ║
║  │  $ GOARCH=amd64 go build -gcflags="-S" .      │             ║
║  │  // Tìm VMOVDQU, VPADDD = SSE/AVX dùng rồi! │             ║
║  │                                                │             ║
║  │  // Thư viện Go dùng SIMD rõ ràng:           │             ║
║  │  // → github.com/klauspost/compress (SIMD)    │             ║
║  │  // → github.com/minio/sha256-simd            │             ║
║  │  // → github.com/bytedance/sonic (JSON)       │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.17 Floating Point — Tại sao 0.1 + 0.2 ≠ 0.3?

Mọi backend engineer đều gặp bug liên quan đến floating point ít nhất một lần. Hiểu **IEEE 754** — cách CPU biểu diễn số thực — giải thích **tại sao** những bug này xảy ra và cách phòng tránh.

```
╔═══════════════════════════════════════════════════════════════╗
║   IEEE 754 — FLOATING POINT REPRESENTATION                   ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  VẤN ĐỀ CƠ BẢN:                                             ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  CPU chỉ có SỐ HỮU HẠN bits (<64).           │             ║
║  │  Số thực trên trục số = VÔ HẠN.              │             ║
║  │  → KHÔNG THỂ biểu diễn chính xác MỌI số!    │             ║
║  │                                                │             ║
║  │  VD trong Go:                                  │             ║
║  │  fmt.Println(0.1 + 0.2)                        │             ║
║  │  // Output: 0.30000000000000004 ← KHÔNG = 0.3!│             ║
║  │                                                │             ║
║  │  fmt.Println(0.1 + 0.2 == 0.3)                │             ║
║  │  // Output: false ← Sốc!!!                   │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CẤU TRÚC float64 (64 bits):                                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌──┬────────────┬───────────────────────────┐│             ║
║  │  │S │ Exponent   │ Mantissa (Fraction)       ││             ║
║  │  │1 │ 11 bits    │ 52 bits                   ││             ║
║  │  └──┴────────────┴───────────────────────────┘│             ║
║  │                                                │             ║
║  │  Giá trị = (-1)^S × 2^(Exp-1023) × 1.Mantissa│             ║
║  │                                                │             ║
║  │  VD: số 0.1 trong binary:                     │             ║
║  │  0.1₁₀ = 0.0001100110011001100...₂ (vô hạn!)│             ║
║  │  → Phải CẮT bớt ở 52 bits → sai số!        │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  GIÁ TRỊ ĐẶC BIỆT:                                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  +Inf:  1.0/0.0   → math.Inf(1)               │             ║
║  │  -Inf: -1.0/0.0   → math.Inf(-1)              │             ║
║  │  NaN:   0.0/0.0   → math.NaN()                │             ║
║  │                                                │             ║
║  │  ⚠️ NaN ≠ NaN!                               │             ║
║  │  math.NaN() == math.NaN()  // false!          │             ║
║  │  → Dùng math.IsNaN() để kiểm tra             │             ║
║  │                                                │             ║
║  │  ⚠️ Precision limits:                         │             ║
║  │  float32: ~7 chữ số có nghĩa                 │             ║
║  │  float64: ~15 chữ số có nghĩa                │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ QUY TẮC VÀNG CHO BACKEND:                                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. TIỀN: KHÔNG BAO GIỜ dùng float!          │             ║
║  │     → Dùng integer (cents): $10.50 = 1050     │             ║
║  │     → Hoặc dùng shopspring/decimal             │             ║
║  │                                                │             ║
║  │  2. So sánh: KHÔNG dùng == cho float!         │             ║
║  │     // Bad:                                    │             ║
║  │     if a == b { ... }                          │             ║
║  │     // Good:                                   │             ║
║  │     if math.Abs(a - b) < 1e-9 { ... }        │             ║
║  │                                                │             ║
║  │  3. Tích lũy: Cộng nhiều float NHỎ           │             ║
║  │     → sai số TÍCH LŨY theo N phép tính!      │             ║
║  │     → Dùng Kahan summation algorithm          │             ║
║  │                                                │             ║
║  │  4. JSON: float64 qua JSON có thể mất        │             ║
║  │     precision!                                 │             ║
║  │     → json.Number hoặc string encoding cho    │             ║
║  │       giá trị cần chính xác tuyệt đối        │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.18 Number Representation — Binary, Two's Complement & Endianness

Hiểu cách CPU biểu diễn số là nền tảng để hiểu tất cả những gì đã học. Khi bạn debug network protocols, parse binary files, hay optimize bitwise operations — đây là kiến thức bạn cần.

```
╔═══════════════════════════════════════════════════════════════╗
║   NUMBER REPRESENTATION TRONG CPU                            ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  UNSIGNED INTEGERS (số không dấu):                            ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  8-bit (uint8): 0 → 255                       │             ║
║  │  VD: 42 = 00101010₂                           │             ║
║  │                                                │             ║
║  │  Bit:    7  6  5  4  3  2  1  0               │             ║
║  │  Value: 128 64 32 16  8  4  2  1              │             ║
║  │  42:     0  0  1  0  1  0  1  0               │             ║
║  │       =      32    + 8    + 2 = 42            │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  SIGNED INTEGERS — Two's Complement:                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  int8: -128 → 127                             │             ║
║  │  MSB (bit cao nhất) = sign bit:               │             ║
║  │  • 0 = dương, 1 = âm                         │             ║
║  │                                                │             ║
║  │  Tại sao Two's Complement? Vì:                │             ║
║  │  • Cộng/trừ DÙNG CHUNG 1 mạch ALU!          │             ║
║  │  • Không cần mạch riêng cho trừ              │             ║
║  │  • Chỉ có 1 số 0 (không có +0 và -0)        │             ║
║  │                                                │             ║
║  │  VD: -42 = INV(42) + 1                        │             ║
║  │  = INV(00101010) + 1 = 11010101 + 1           │             ║
║  │  = 11010110₂ = -42                            │             ║
║  │                                                │             ║
║  │  ⚠️ Overflow:                                 │             ║
║  │  int8: 127 + 1 = -128! (wrap around)          │             ║
║  │  → Go: integer overflow KHÔNG panic!         │             ║
║  │  → Âm thầm wrap → bug rất khó tìm!         │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ENDIANNESS — Thứ tự bytes trong memory:                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Số 0x01020304 (int32) trong memory:          │             ║
║  │                                                │             ║
║  │  BIG ENDIAN (byte cao → thấp):               │             ║
║  │  Addr: 0x00  0x01  0x02  0x03                 │             ║
║  │  Data:  01    02    03    04                    │             ║
║  │  → "Đọc tự nhiên" giống viết trên giấy      │             ║
║  │  → Network byte order (TCP/IP dùng!)          │             ║
║  │                                                │             ║
║  │  LITTLE ENDIAN (byte thấp → cao):             │             ║
║  │  Addr: 0x00  0x01  0x02  0x03                 │             ║
║  │  Data:  04    03    02    01                    │             ║
║  │  → x86, ARM (default), RISC-V dùng!          │             ║
║  │  → Ngược trực giác nhưng giúp CPU xử lý    │             ║
║  │    nhanh hơn (byte thấp ở địa chỉ thấp)    │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ BACKEND RELEVANCE:                                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Network Protocol:                          │             ║
║  │     → TCP/IP = Big Endian                     │             ║
║  │     → CPU (x86) = Little Endian               │             ║
║  │     → Phải convert! (htonl, ntohl)            │             ║
║  │                                                │             ║
║  │  // Go:                                        │             ║
║  │  binary.BigEndian.PutUint32(buf, 0x01020304)  │             ║
║  │  // buf = [01, 02, 03, 04] → network order   │             ║
║  │                                                │             ║
║  │  binary.LittleEndian.PutUint32(buf, 0x01020304)│            ║
║  │  // buf = [04, 03, 02, 01] → host order(x86) │             ║
║  │                                                │             ║
║  │  2. Binary File Format:                        │             ║
║  │     → Protobuf, MessagePack: có endian riêng │             ║
║  │     → Phải đọc spec để biết byte order!      │             ║
║  │                                                │             ║
║  │  3. Bitwise Operations:                        │             ║
║  │     → Flags: permission = 0b111 (rwx)         │             ║
║  │     → Bitmask cho feature flags               │             ║
║  │     → Bloom filter: bit array + hash          │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  GO BITWISE PATTERNS:                                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // Feature flags với bitmask                  │             ║
║  │  const (                                       │             ║
║  │      FeatureA uint32 = 1 << iota  // 0001     │             ║
║  │      FeatureB                     // 0010     │             ║
║  │      FeatureC                     // 0100     │             ║
║  │  )                                             │             ║
║  │                                                │             ║
║  │  flags := FeatureA | FeatureC  // 0101         │             ║
║  │  hasA := flags & FeatureA != 0 // true         │             ║
║  │  hasB := flags & FeatureB != 0 // false        │             ║
║  │                                                │             ║
║  │  // Tại sao dùng bitmask?                     │             ║
║  │  // → 1 CPU instruction (AND) thay vì        │             ║
║  │  //   map lookup hoặc slice iteration!        │             ║
║  │  // → Redis dùng bitmask cho ACL permissions  │             ║
║  │  // → Linux file permissions = bitmask (755)  │             ║
║  │                                                │             ║
║  │  // Power of 2 check (cực nhanh):             │             ║
║  │  func isPow2(n uint) bool {                    │             ║
║  │      return n > 0 && n&(n-1) == 0              │             ║
║  │  }                                             │             ║
║  │  // → 1 CPU instruction! Dùng trong memory   │             ║
║  │  //   allocator để align addresses             │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 1.19 Context Switching — Cái giá CPU phải trả

Khi OS chuyển từ process/thread này sang process/thread khác, CPU phải **lưu toàn bộ trạng thái** (registers, program counter, stack pointer, TLB, cache...) và **nạp lại** trạng thái của process mới. Đây là chi phí lớn nhất trong concurrent programming.

```
╔═══════════════════════════════════════════════════════════════╗
║   CONTEXT SWITCHING — CHI TIẾT                               ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  PROCESS CONTEXT SWITCH (nặng nhất):                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Save registers (16+ general purpose)      │             ║
║  │  2. Save PC (program counter)                  │             ║
║  │  3. Save SP (stack pointer)                    │             ║
║  │  4. Save flags register                        │             ║
║  │  5. Save FPU/SIMD state (512 bytes cho AVX!)  │             ║
║  │  6. Flush TLB entries                          │             ║
║  │     → Mỗi virtual→physical mapping PHẢI       │             ║
║  │       lookup lại sau switch!                  │             ║
║  │  7. Switch page table (CR3 register trên x86) │             ║
║  │  8. Cache pollution:                           │             ║
║  │     → L1/L2 cache đầy data process CŨ       │             ║
║  │     → Process MỚI → cache miss liên tục!     │             ║
║  │                                                │             ║
║  │  CHI PHÍ: ~1-10 μs TRỰC TIẾP                 │             ║
║  │         + ~10-100 μs GIÁN TIẾP (cache warmup) │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  THREAD CONTEXT SWITCH (nhẹ hơn):                             ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  → Cùng process → KHÔNG switch page table    │             ║
║  │  → KHÔNG flush TLB (chia sẻ address space)   │             ║
║  │  → Vẫn phải save/restore registers            │             ║
║  │                                                │             ║
║  │  CHI PHÍ: ~1-5 μs                             │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  GOROUTINE SWITCH (siêu nhẹ!):                                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  → User-space switch (KHÔNG syscall!)         │             ║
║  │  → Chỉ save 3 thứ: PC, SP, và vài registers │             ║
║  │  → Cùng OS thread → KHÔNG TLB flush          │             ║
║  │  → Stack nhỏ (2KB, grow on demand)            │             ║
║  │                                                │             ║
║  │  CHI PHÍ: ~100-200 ns (10-50x nhẹ hơn!)     │             ║
║  │                                                │             ║
║  │  ☞ ĐÂY LÀ LÝ DO GO TẠO GOROUTINE!          │             ║
║  │  → Process switch: ~10 μs = 10,000 ns         │             ║
║  │  → Thread switch:  ~3 μs  = 3,000 ns          │             ║
║  │  → Goroutine:      ~200 ns = 50x nhẹ hơn!    │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  SO SÁNH TỔNG QUAN:                                           ║
║  ┌──────────────┬──────────┬────────┬──────────┐             ║
║  │              │ Process  │ Thread │ Goroutine│             ║
║  ├──────────────┼──────────┼────────┼──────────┤             ║
║  │ Switch cost  │ ~10 μs   │ ~3 μs  │ ~200 ns  │             ║
║  │ Memory/unit  │ ~1 MB+   │ ~1 MB  │ ~2 KB    │             ║
║  │ Max units    │ ~1,000   │ ~10,000│~1,000,000│             ║
║  │ Page table   │ Riêng    │ Chung  │ Chung    │             ║
║  │ TLB flush    │ Có       │ Không  │ Không    │             ║
║  │ Kernel mode  │ Có       │ Có     │ Không!   │             ║
║  │ Scheduler    │ OS       │ OS     │ Go runtime│            ║
║  └──────────────┴──────────┴────────┴──────────┘             ║
║                                                               ║
║  ☞ THỰC HÀNH — Đếm goroutines:                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // Tạo 1 triệu goroutines (thử đi!)        │             ║
║  │  for i := 0; i < 1_000_000; i++ {             │             ║
║  │      go func() {                               │             ║
║  │          time.Sleep(10 * time.Second)          │             ║
║  │      }()                                       │             ║
║  │  }                                             │             ║
║  │  // Memory: ~2GB (2KB × 1M)                   │             ║
║  │  // → KHÔNG THỂ làm với OS threads!           │             ║
║  │  //   (1MB × 1M = 1TB RAM cần thiết!)         │             ║
║  │                                                │             ║
║  │  // Monitor goroutines:                        │             ║
║  │  runtime.NumGoroutine() // → 1,000,001        │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ KHI NÀO GOROUTINE TRỞ THÀNH VẤN ĐỀ?                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Goroutine leak: tạo nhưng KHÔNG bao giờ  │             ║
║  │     kết thúc → memory grow → OOM!            │             ║
║  │     → Luôn có cancellation (context.Context)  │             ║
║  │                                                │             ║
║  │  2. Quá nhiều goroutines cùng write 1 channel │             ║
║  │     → channel contention → serialization!     │             ║
║  │     → Dùng worker pool pattern                │             ║
║  │                                                │             ║
║  │  3. Quá nhiều goroutines gọi syscall          │             ║
║  │     → Go tạo THÊM OS threads                  │             ║
║  │     → 10,000+ OS threads = OS không chịu nổi │             ║
║  │     → Limit với semaphore pattern             │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §2. Memory Hierarchy — Tháp Tốc Độ

### 2.1 Tại sao cần nhiều loại bộ nhớ?

```
╔═══════════════════════════════════════════════════════════════╗
║   MEMORY HIERARCHY — VẤN ĐỀ CỐT LÕI                        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  VẤN ĐỀ: CPU quá NHANH, RAM quá CHẬM!                      ║
║                                                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  CPU thực thi: ~0.3 ns/instruction           │             ║
║  │  RAM truy cập: ~100 ns                        │             ║
║  │                                                │             ║
║  │  → CPU phải CHỜ ~300 cycles mỗi lần đọc RAM!│             ║
║  │  → 99% thời gian CPU... NGỒI KHÔNG!          │             ║
║  │  → Giống bạn order đồ ăn nhưng phải đợi     │             ║
║  │    300 ngày mới được giao!                    │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  GIẢI PHÁP: Cache — Bộ nhớ đệm SIÊU NHANH ngay trong CPU  ║
║                                                               ║
║  Nguyên lý: LOCALITY (Tính cục bộ)                           ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  1. Temporal Locality (theo thời gian):       │             ║
║  │     → Dữ liệu VỪA dùng → SẼ dùng lại sớm  │             ║
║  │     → VD: Biến loop counter                   │             ║
║  │                                                │             ║
║  │  2. Spatial Locality (theo không gian):       │             ║
║  │     → Dữ liệu GẦN nhau → SẼ dùng cùng nhau │             ║
║  │     → VD: Duyệt array → phần tử liên tiếp   │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.2 Tháp bộ nhớ (Memory Pyramid)

```
╔═══════════════════════════════════════════════════════════════╗
║   MEMORY HIERARCHY PYRAMID                                    ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║            /\             ← Nhanh nhất, nhỏ nhất, đắt nhất ║
║           /  \                                                ║
║          / Reg\           Registers: < 1ns, ~1KB             ║
║         /──────\                                              ║
║        / L1     \         L1 Cache: ~1ns, 32-64KB            ║
║       /──────────\                                            ║
║      /  L2        \       L2 Cache: ~4ns, 256KB-1MB          ║
║     /──────────────\                                          ║
║    /   L3           \     L3 Cache: ~10ns, 8-32MB            ║
║   /──────────────────\                                        ║
║  /      RAM           \   RAM: ~100ns, 8-128GB               ║
║ /────────────────────────\                                    ║
║/       SSD / HDD          \ SSD: ~100μs / HDD: ~10ms        ║
║════════════════════════════                                   ║
║            ↑                                                  ║
║  Chậm nhất, lớn nhất, rẻ nhất                               ║
║                                                               ║
║  SO SÁNH TRỰC QUAN (nếu L1 = 1 giây):                       ║
║  ┌───────────┬──────────────┬──────────────────────┐         ║
║  │ Cấp       │ Thời gian    │ So sánh thực tế      │         ║
║  ├───────────┼──────────────┼──────────────────────┤         ║
║  │ Register  │ ~0.3ns       │ Nháy mắt             │         ║
║  │ L1 Cache  │ ~1 ns        │ Lấy sách trên bàn    │         ║
║  │ L2 Cache  │ ~4 ns        │ Lấy sách trên kệ     │         ║
║  │ L3 Cache  │ ~10 ns       │ Đi đến tủ sách       │         ║
║  │ RAM       │ ~100 ns      │ Đi ra thư viện       │         ║
║  │ SSD       │ ~100,000 ns  │ Bay sang TP khác     │         ║
║  │ HDD       │ ~10,000,000  │ Bay vòng quanh TG    │         ║
║  │ Network   │ ~ms-s        │ Gửi thư lên Sao Hỏa │         ║
║  └───────────┴──────────────┴──────────────────────┘         ║
║                                                               ║
║  ⚠️ QUAN TRỌNG cho Backend Engineer:                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Khi bạn viết code, HIỂU tháp này = hiểu   │             ║
║  │  TẠI SAO:                                     │             ║
║  │  • Array nhanh hơn Linked List               │             ║
║  │    → Array: spatial locality (data liên tiếp) │             ║
║  │    → Linked List: random access (cache miss) │             ║
║  │                                                │             ║
║  │  • Redis (in-memory) nhanh gấp 1000x MySQL  │             ║
║  │    → Redis: RAM (~100ns)                      │             ║
║  │    → MySQL: Disk (~100μs-10ms)               │             ║
║  │                                                │             ║
║  │  • Connection pooling quan trọng              │             ║
║  │    → Network round trip: ~ms                  │             ║
║  │    → Tái sử dụng connection = tiết kiệm      │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.3 Cache Line — Đơn vị truyền dữ liệu

```
╔═══════════════════════════════════════════════════════════════╗
║   CACHE LINE — HIỂU SÂU ĐỂ VIẾT CODE NHANH                 ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  CPU KHÔNG đọc từng byte từ RAM.                             ║
║  CPU đọc theo CACHE LINE = 64 bytes cùng lúc!               ║
║                                                               ║
║  RAM:                                                         ║
║  ┌────┬────┬────┬────┬────┬────┬────┬────┬────┬────┐        ║
║  │ 00 │ 01 │ 02 │ 03 │ 04 │ 05 │ 06 │ 07 │ 08 │ 09 │        ║
║  └────┴────┴────┴────┴────┴────┴────┴────┴────┴────┘        ║
║  ◄──── 64 bytes (1 cache line) ─────►                        ║
║                                                               ║
║  Khi CPU cần byte 02:                                        ║
║  → Không chỉ lấy byte 02                                    ║
║  → Lấy TOÀN BỘ 64 bytes (00-63) vào cache!                 ║
║  → Nếu tiếp theo cần byte 03 → ĐÃ CÓ SẴN!               ║
║  → Đây là spatial locality!                                  ║
║                                                               ║
║  VÍ DỤ THỰC TẾ — Array vs Linked List:                      ║
║                                                               ║
║  Array (data LIÊN TIẾP trong memory):                        ║
║  ┌────┬────┬────┬────┬────┬────┬────┬────┐                   ║
║  │ a0 │ a1 │ a2 │ a3 │ a4 │ a5 │ a6 │ a7 │                   ║
║  └────┴────┴────┴────┴────┴────┴────┴────┘                   ║
║  ◄──── 1 cache line load = 8 phần tử! ─────►                ║
║  → Duyệt 8 phần tử chỉ TỐN 1 lần đọc RAM!                ║
║                                                               ║
║  Linked List (data RẢI RÁC trong memory):                    ║
║  ┌────┐     ┌────┐         ┌────┐   ┌────┐                  ║
║  │ n0 │────►│ n1 │────────►│ n2 │──►│ n3 │                  ║
║  └────┘     └────┘         └────┘   └────┘                  ║
║  addr:100   addr:5000      addr:200 addr:8000                ║
║  → Mỗi node ở ĐỊA CHỈ KHÁC NHAU!                          ║
║  → Mỗi lần truy cập = 1 lần MISS cache!                    ║
║  → 4 node = 4 lần đọc RAM = chậm gấp 4x!                  ║
║                                                               ║
║  ⚠️ ĐÂY LÀ LÝ DO Go dùng SLICE (mảng) thay vì            ║
║  linked list trong hầu hết trường hợp!                       ║
║  → Data-Oriented Design: tổ chức data cho HARDWARE!         ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.4 Cache Associativity — CPU tìm data trong cache như thế nào?

Khi CPU cần truy cập data, nó phải tìm xem data đó **có trong cache hay không**. Cách tổ chức cache quyết định tốc độ tìm kiếm và tỷ lệ cache miss. Đây là kiến thức then chốt để hiểu tại sao struct alignment và padding ảnh hưởng performance.

```
╔═══════════════════════════════════════════════════════════════╗
║   CACHE ASSOCIATIVITY — TỔ CHỨC NỘI BỘ CACHE                ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ĐỊA CHỈ MEMORY ĐƯỢC CHIA THÀNH 3 PHẦN:                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Memory Address (64-bit):                      │             ║
║  │  ┌──────────┬────────┬──────────┐              │             ║
║  │  │   TAG    │  SET   │  OFFSET  │              │             ║
║  │  │ (nhận   │(chọn   │(byte nào │              │             ║
║  │  │  dạng)  │ nhóm)  │trong line)│              │             ║
║  │  └──────────┴────────┴──────────┘              │             ║
║  │                                                │             ║
║  │  OFFSET: 6 bits (2⁶ = 64 bytes/cache line)   │             ║
║  │  SET: chọn 1 trong N nhóm                     │             ║
║  │  TAG: để phân biệt giữa các địa chỉ         │             ║
║  │       cùng set                                 │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  3 LOẠI CACHE ASSOCIATIVITY:                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ① DIRECT MAPPED (1-way):                      │             ║
║  │  ┌───────────────────────────┐                 │             ║
║  │  │ Set 0: [Line]             │                 │             ║
║  │  │ Set 1: [Line]             │                 │             ║
║  │  │ Set 2: [Line]             │                 │             ║
║  │  │ ...                        │                 │             ║
║  │  └───────────────────────────┘                 │             ║
║  │  → Mỗi set CHỈ 1 line                         │             ║
║  │  → Nhanh nhất tìm kiếm (O(1))                │             ║
║  │  → NHƯNG: conflict miss cao!                  │             ║
║  │  → 2 addr cùng set → "đá" nhau liên tục     │             ║
║  │                                                │             ║
║  │  ② SET-ASSOCIATIVE (N-way, PHỔ BIẾN NHẤT):   │             ║
║  │  ┌───────────────────────────┐                 │             ║
║  │  │ Set 0: [Line][Line][Line] │  ← 3-way       │             ║
║  │  │ Set 1: [Line][Line][Line] │                 │             ║
║  │  │ Set 2: [Line][Line][Line] │                 │             ║
║  │  │ ...                        │                 │             ║
║  │  └───────────────────────────┘                 │             ║
║  │  → Mỗi set có N lines (thường 4-16 way)      │             ║
║  │  → L1: thường 8-way                           │             ║
║  │  → L2: thường 4-8-way                         │             ║
║  │  → L3: thường 12-16-way                       │             ║
║  │  → Cân bằng giữa speed và miss rate          │             ║
║  │                                                │             ║
║  │  ③ FULLY ASSOCIATIVE:                          │             ║
║  │  → Data có thể ở BẤT KỲ line nào            │             ║
║  │  → Ít conflict miss nhất                      │             ║
║  │  → NHƯNG: chậm tìm kiếm (phải so sánh ALL)  │             ║
║  │  → Chỉ dùng cho TLB (cache nhỏ)             │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CACHE EVICTION POLICIES — Khi cache ĐẦY:                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Khi 1 set đầy (N lines đã dùng hết):        │             ║
║  │  → Phải ĐẨY 1 line ra để nhường chỗ!       │             ║
║  │                                                │             ║
║  │  1. LRU (Least Recently Used):                 │             ║
║  │     → Đẩy line lâu nhất chưa dùng            │             ║
║  │     → Phổ biến nhất cho L1/L2                 │             ║
║  │     → Giống Redis eviction policy!            │             ║
║  │                                                │             ║
║  │  2. Pseudo-LRU:                                │             ║
║  │     → Xấp xỉ LRU bằng ít bit hơn            │             ║
║  │     → Dùng cho L3 (quá nhiều ways cho LRU)   │             ║
║  │                                                │             ║
║  │  3. Random:                                    │             ║
║  │     → Đẩy ngẫu nhiên                         │             ║
║  │     → Đơn giản, hiệu quả bất ngờ            │             ║
║  │                                                │             ║
║  │  ☞ Song song với Redis:                       │             ║
║  │  → allkeys-lru = giống CPU cache LRU          │             ║
║  │  → volatile-ttl = giống cache line aging      │             ║
║  │  → CPU cache = hardware Redis!                │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  3 LOẠI CACHE MISS:                                           ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Compulsory (Cold) Miss:                    │             ║
║  │     → Lần đầu truy cập → chắc chắn miss     │             ║
║  │     → KHÔNG thể tránh                         │             ║
║  │     → Giải pháp: prefetching                  │             ║
║  │                                                │             ║
║  │  2. Capacity Miss:                             │             ║
║  │     → Cache QUÁ NHỎ cho working set           │             ║
║  │     → Giải pháp: giảm working set size        │             ║
║  │     → VD: tiling/blocking algorithms          │             ║
║  │                                                │             ║
║  │  3. Conflict Miss:                             │             ║
║  │     → 2+ địa chỉ map cùng set → "đá" nhau  │             ║
║  │     → Giải pháp: tăng associativity           │             ║
║  │     → Hoặc padding để đổi set mapping        │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.5 TLB — Translation Lookaside Buffer

Khi CPU truy cập memory, nó dùng **virtual address** (không phải physical address). Mỗi lần truy cập đều cần **dịch** virtual → physical address. TLB là cache chuyên dụng cho việc dịch này — và TLB miss có thể tốn **hàng trăm cycles**.

```
╔═══════════════════════════════════════════════════════════════╗
║   TLB — TRANSLATION LOOKASIDE BUFFER                         ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  VẤN ĐỀ:                                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Application thấy: Virtual Address (VA)        │             ║
║  │  RAM thực sự dùng: Physical Address (PA)       │             ║
║  │                                                │             ║
║  │  VA → PA mapping nằm trong PAGE TABLE          │             ║
║  │  Page Table nằm trong... RAM!                  │             ║
║  │                                                │             ║
║  │  Mỗi memory access cần:                        │             ║
║  │  1. Đọc Page Table từ RAM (100ns!)             │             ║
║  │  2. Lấy Physical Address                       │             ║
║  │  3. Đọc data thực từ RAM (100ns!)              │             ║
║  │  → TỔNG: 200ns cho 1 lần đọc?! KHÔNG CHẤP    │             ║
║  │    NHẬN ĐƯỢC!                                  │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  GIẢI PHÁP: TLB = Cache cho Page Table:                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌──────────┐    ┌──────────┐    ┌─────────┐ │             ║
║  │  │ Virtual  │───►│   TLB    │───►│Physical │ │             ║
║  │  │ Address  │    │ (cache)  │    │ Address │ │             ║
║  │  └──────────┘    └──────────┘    └─────────┘ │             ║
║  │                    │ miss                      │             ║
║  │                    ▼                           │             ║
║  │              ┌──────────┐                      │             ║
║  │              │Page Table│ ← trong RAM          │             ║
║  │              │ (chậm!)  │                      │             ║
║  │              └──────────┘                      │             ║
║  │                                                │             ║
║  │  TLB specs (Intel Skylake):                    │             ║
║  │  • L1 DTLB: 64 entries, 4-way (4KB pages)    │             ║
║  │  • L1 ITLB: 128 entries, 8-way               │             ║
║  │  • L2 STLB: 1536 entries, 12-way              │             ║
║  │                                                │             ║
║  │  TLB hit: ~1 cycle                             │             ║
║  │  TLB miss: ~10-100 cycles (page table walk!)  │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  PAGE SIZE VÀ TLB COVERAGE:                                   ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Standard page: 4KB                            │             ║
║  │  64 TLB entries × 4KB = 256KB coverage         │             ║
║  │  → Chỉ 256KB memory không bị TLB miss!       │             ║
║  │  → Working set > 256KB = TLB thrashing!       │             ║
║  │                                                │             ║
║  │  HUGE PAGES: 2MB hoặc 1GB                     │             ║
║  │  64 entries × 2MB = 128MB coverage!            │             ║
║  │  → 500x coverage hơn 4KB pages!              │             ║
║  │                                                │             ║
║  │  ☞ Backend Relevance:                          │             ║
║  │  • Database buffers (PostgreSQL shared_buffers)│             ║
║  │    → Dùng huge pages = ít TLB miss hơn!      │             ║
║  │  • JVM: -XX:+UseTransparentHugePages          │             ║
║  │  • Redis: redis.conf → hugepages enable       │             ║
║  │                                                │             ║
║  │  // Linux: kiểm tra TLB miss                  │             ║
║  │  $ perf stat -e dTLB-load-misses ./myapp      │             ║
║  │                                                │             ║
║  │  // Enable huge pages                          │             ║
║  │  $ echo 1024 > /proc/sys/vm/nr_hugepages      │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ GẮN VỚI GO:                                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Go heap allocations → nhiều pages            │             ║
║  │  → Struct lớn escape to heap → nhiều TLB     │             ║
║  │    entries cần → TLB pressure!                │             ║
║  │                                                │             ║
║  │  Tối ưu:                                       │             ║
║  │  • Stack allocation (nhỏ, không escape)       │             ║
║  │    → ít pages = ít TLB pressure               │             ║
║  │  • Object pooling (sync.Pool)                  │             ║
║  │    → tái dùng memory = ít allocation mới     │             ║
║  │  • Slice thay vì map cho small datasets       │             ║
║  │    → contiguous memory = TLB friendly         │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.6 Hardware Prefetching — CPU đọc trước tương lai

CPU không chỉ lưu data đã đọc vào cache. Nó còn **đoán trước** data nào sẽ cần tiếp theo và **tải trước** vào cache. Đây là lý do sequential access nhanh hơn random access hàng chục lần.

```
╔═══════════════════════════════════════════════════════════════╗
║   HARDWARE PREFETCHING                                       ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  CÁC LOẠI PREFETCHER:                                        ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Next-Line Prefetcher:                      │             ║
║  │     → Đọc line N → tự động fetch line N+1    │             ║
║  │     → Đơn giản, hiệu quả cho sequential scan │             ║
║  │                                                │             ║
║  │  2. Stride Prefetcher:                         │             ║
║  │     → Nhận ra pattern: addr, addr+S, addr+2S  │             ║
║  │     → Tự động fetch addr+3S, addr+4S...       │             ║
║  │     → Hiệu quả cho array-of-structs          │             ║
║  │                                                │             ║
║  │  3. Stream Prefetcher:                         │             ║
║  │     → Track nhiều streams cùng lúc            │             ║
║  │     → VD: duyệt 2 arrays song song           │             ║
║  │     → Intel có ~4-8 stream detectors          │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  TẠI SAO SEQUENTIAL NHANH HƠN RANDOM:                        ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  SEQUENTIAL ACCESS:                            │             ║
║  │  ┌─────────────────────────────────────────┐  │             ║
║  │  │ Read line 0 → Prefetch line 1,2,3       │  │             ║
║  │  │ Read line 1 → ALREADY IN CACHE! (0ns)   │  │             ║
║  │  │ Read line 2 → ALREADY IN CACHE! (0ns)   │  │             ║
║  │  │ Read line 3 → ALREADY IN CACHE! (0ns)   │  │             ║
║  │  │ → Effective latency: ~1ns avg            │  │             ║
║  │  └─────────────────────────────────────────┘  │             ║
║  │                                                │             ║
║  │  RANDOM ACCESS:                                │             ║
║  │  ┌─────────────────────────────────────────┐  │             ║
║  │  │ Read addr 5000 → prefetch 5001? Vô dụng│  │             ║
║  │  │ Read addr 200  → MISS! 100ns            │  │             ║
║  │  │ Read addr 9999 → MISS! 100ns            │  │             ║
║  │  │ Read addr 42   → MISS! 100ns            │  │             ║
║  │  │ → Effective latency: ~100ns avg          │  │             ║
║  │  └─────────────────────────────────────────┘  │             ║
║  │                                                │             ║
║  │  → Sequential / Random = 100x gap!            │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ BACKEND IMPLICATIONS:                                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Database B-Tree vs Hash Index:             │             ║
║  │     → B-Tree: range scan = SEQUENTIAL (nhanh!)│             ║
║  │     → Hash: point lookup = RANDOM              │             ║
║  │     → Đây là lý do B-Tree phổ biến hơn!     │             ║
║  │                                                │             ║
║  │  2. Column-store vs Row-store:                 │             ║
║  │     → Column (ClickHouse): 1 column liên tiếp│             ║
║  │       → Prefetcher HIỆU QUẢ → nhanh!        │             ║
║  │     → Row (MySQL): columns rải rác            │             ║
║  │       → Đọc 1 column = skip data → chậm     │             ║
║  │                                                │             ║
║  │  3. Go slice iteration:                        │             ║
║  │     → for range slice = sequential → nhanh   │             ║
║  │     → for range map = random → chậm hơn     │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.7 Virtual Memory — Ảo hóa bộ nhớ

Virtual Memory là abstraction cho phép mỗi process **tưởng** nó có toàn bộ RAM. OS + CPU (MMU) phối hợp để dịch virtual address → physical address, cung cấp isolation và cho phép dùng nhiều RAM hơn thực tế.

```
╔═══════════════════════════════════════════════════════════════╗
║   VIRTUAL MEMORY — ẢO HÓA BỘ NHỚ                           ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  TẠI SAO CẦN VIRTUAL MEMORY?                                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  KHÔNG CÓ Virtual Memory:                      │             ║
║  │  ┌─────────────────────────────────┐           │             ║
║  │  │  Process A: addr 0-1000         │           │             ║
║  │  │  Process B: addr 1001-2000      │           │             ║
║  │  │  Process C: addr 2001-3000      │           │             ║
║  │  └─────────────────────────────────┘           │             ║
║  │  VẤN ĐỀ:                                       │             ║
║  │  • Process A có THỂ đọc memory Process B!     │             ║
║  │  • Không thể mở rộng memory nếu hết         │             ║
║  │  • Crash 1 process → ảnh hưởng tất cả       │             ║
║  │                                                │             ║
║  │  CÓ Virtual Memory:                            │             ║
║  │  ┌─────────────────────────────────┐           │             ║
║  │  │  Process A: addr 0-MAX (ẢO)    │           │             ║
║  │  │  Process B: addr 0-MAX (ẢO)    │           │             ║
║  │  │  Process C: addr 0-MAX (ẢO)    │           │             ║
║  │  │  ↓ (OS dịch qua Page Table)    │           │             ║
║  │  │  Physical RAM: tự do phân bổ   │           │             ║
║  │  └─────────────────────────────────┘           │             ║
║  │  → Mỗi process TƯỞNG mình có toàn bộ RAM!   │             ║
║  │  → KHÔNG thể đọc memory process khác         │             ║
║  │  → Isolation hoàn toàn!                       │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  PAGE TABLE — Bản đồ Virtual → Physical:                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Virtual Page     Physical Frame               │             ║
║  │  ┌────────┐      ┌────────┐                    │             ║
║  │  │ VP 0   │─────►│ PF 5   │ (trong RAM)        │             ║
║  │  │ VP 1   │─────►│ PF 2   │ (trong RAM)        │             ║
║  │  │ VP 2   │─────►│ DISK   │ (swapped out!)     │             ║
║  │  │ VP 3   │─────►│ PF 9   │ (trong RAM)        │             ║
║  │  │ VP 4   │─────►│ NULL   │ (chưa allocate)    │             ║
║  │  └────────┘      └────────┘                    │             ║
║  │                                                │             ║
║  │  4-Level Page Table (x86-64):                  │             ║
║  │  PML4 → PDPT → PD → PT → Physical Frame      │             ║
║  │  (9 bit)(9 bit)(9 bit)(9 bit)(12 bit offset)  │             ║
║  │  = 48 bits = 256 TB virtual address space!    │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  PAGE FAULT — Khi page KHÔNG ở RAM:                           ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  CPU truy cập VP 2 → Page Table: "DISK!"     │             ║
║  │    │                                           │             ║
║  │    ▼                                           │             ║
║  │  MMU tạo PAGE FAULT exception                  │             ║
║  │    │                                           │             ║
║  │    ▼                                           │             ║
║  │  OS handler:                                    │             ║
║  │  1. Tìm free physical frame                    │             ║
║  │  2. Nếu không có → evict page khác (swap)     │             ║
║  │  3. Đọc page từ disk vào RAM (~ms!)           │             ║
║  │  4. Update Page Table entry                    │             ║
║  │  5. Retry instruction                          │             ║
║  │                                                │             ║
║  │  CHI PHÍ: ~1-10 ms (so với 100ns RAM access!) │             ║
║  │  → 10,000-100,000x CHẬM hơn!                 │             ║
║  │                                                │             ║
║  │  ☞ Đây là lý do database cần:                 │             ║
║  │  • Buffer pool size lớn (giữ data trong RAM)  │             ║
║  │  • vm.swappiness = 0 (tắt swap cho DB server) │             ║
║  │  • Enough RAM > working set                    │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ GẮN VỚI GO:                                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Go runtime quản lý memory qua OS syscalls:   │             ║
║  │  • mmap: request virtual pages từ OS           │             ║
║  │  • madvise: hint cho OS về usage pattern      │             ║
║  │  • Go heap = nhiều spans = nhiều pages        │             ║
║  │                                                │             ║
║  │  GOGC (Garbage Collection):                    │             ║
║  │  • GOGC=100: GC khi heap gấp đôi             │             ║
║  │  • Heap lớn = nhiều pages = TLB pressure      │             ║
║  │  • GOMEMLIMIT: giới hạn max memory            │             ║
║  │                                                │             ║
║  │  // Kiểm tra memory usage                      │             ║
║  │  var m runtime.MemStats                        │             ║
║  │  runtime.ReadMemStats(&m)                      │             ║
║  │  fmt.Printf("Alloc:   %d MB\n", m.Alloc/1024/1024)│       ║
║  │  fmt.Printf("HeapSys: %d MB\n", m.HeapSys/1024/1024)│     ║
║  │  fmt.Printf("NumGC:   %d\n", m.NumGC)         │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.8 Cache-Friendly Programming — Viết code cho hardware

Hiểu memory hierarchy mà không biết áp dụng = lãng phí. Section này tổng hợp các pattern giúp code của bạn **"hợp tác" với cache** thay vì chống lại nó.

```
╔═══════════════════════════════════════════════════════════════╗
║   CACHE-FRIENDLY PROGRAMMING PATTERNS                        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  PATTERN 1: Struct of Arrays vs Array of Structs              ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // ❌ AoS (Array of Structs) — cache wasteful│             ║
║  │  type User struct {                            │             ║
║  │      Name  string  // 16 bytes                │             ║
║  │      Age   int     // 8 bytes                 │             ║
║  │      Email string  // 16 bytes                │             ║
║  │      Score float64 // 8 bytes                 │             ║
║  │  }                                             │             ║
║  │  users := make([]User, 1_000_000)              │             ║
║  │                                                │             ║
║  │  // Tính tổng score → chỉ cần 8/48 bytes!   │             ║
║  │  for _, u := range users {                     │             ║
║  │      total += u.Score  // load 48B, dùng 8B! │             ║
║  │  }                                             │             ║
║  │  // → 83% bandwidth wasted!                    │             ║
║  │                                                │             ║
║  │  // ✅ SoA (Struct of Arrays) — cache perfect │             ║
║  │  type Users struct {                           │             ║
║  │      Names  []string                           │             ║
║  │      Ages   []int                              │             ║
║  │      Emails []string                           │             ║
║  │      Scores []float64  // liên tiếp!          │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  for _, s := range users.Scores {              │             ║
║  │      total += s  // load 64B = 8 scores!      │             ║
║  │  }                                             │             ║
║  │  // → 100% bandwidth tận dụng!                │             ║
║  │                                                │             ║
║  │  ☞ Databases dùng SoA = Column Store!         │             ║
║  │  → ClickHouse, Parquet, Arrow đều column-based│             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  PATTERN 2: Loop Tiling / Blocking:                           ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // ❌ Naive matrix multiply — cache hostile  │             ║
║  │  for i := 0; i < N; i++ {                      │             ║
║  │      for j := 0; j < N; j++ {                  │             ║
║  │          for k := 0; k < N; k++ {              │             ║
║  │              C[i][j] += A[i][k] * B[k][j]     │             ║
║  │              // B[k][j]: k thay đổi → stride  │             ║
║  │              // = N × sizeof(float64) bytes!  │             ║
║  │              // = cache miss mỗi iteration!   │             ║
║  │          }                                      │             ║
║  │      }                                          │             ║
║  │  }                                              │             ║
║  │                                                │             ║
║  │  // ✅ Tiled — cache friendly                  │             ║
║  │  BS := 64 // block size = cache line friendly │             ║
║  │  for ii := 0; ii < N; ii += BS {               │             ║
║  │    for jj := 0; jj < N; jj += BS {             │             ║
║  │      for kk := 0; kk < N; kk += BS {           │             ║
║  │        for i := ii; i < min(ii+BS, N); i++ {   │             ║
║  │          for j := jj; j < min(jj+BS, N); j++ { │             ║
║  │            for k := kk; k < min(kk+BS, N); k++ {│            ║
║  │              C[i][j] += A[i][k] * B[k][j]     │             ║
║  │            }                                    │             ║
║  │          }                                      │             ║
║  │        }                                        │             ║
║  │      }                                          │             ║
║  │    }                                            │             ║
║  │  }                                              │             ║
║  │  // → Xử lý từng block vừa vặn cache!        │             ║
║  │  // → 3-10x nhanh hơn cho large matrices!     │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  PATTERN 3: Hot/Cold Split:                                   ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // ❌ Tất cả fields cùng struct               │             ║
║  │  type Session struct {                         │             ║
║  │      ID        uint64   // hot (dùng nhiều)   │             ║
║  │      UserID    uint64   // hot                 │             ║
║  │      Token     string   // hot                 │             ║
║  │      CreatedAt time.Time // cold (ít dùng)    │             ║
║  │      UserAgent string    // cold               │             ║
║  │      IP        string    // cold               │             ║
║  │      Metadata  map[...]  // cold               │             ║
║  │  }                                             │             ║
║  │  // Hot path load cả cold data → cache waste! │             ║
║  │                                                │             ║
║  │  // ✅ Tách hot/cold                           │             ║
║  │  type SessionHot struct {                      │             ║
║  │      ID     uint64                             │             ║
║  │      UserID uint64                             │             ║
║  │      Token  string                             │             ║
║  │      Cold   *SessionCold // pointer only      │             ║
║  │  }                                             │             ║
║  │  type SessionCold struct {                     │             ║
║  │      CreatedAt time.Time                       │             ║
║  │      UserAgent string                          │             ║
║  │      IP        string                          │             ║
║  │      Metadata  map[string]string               │             ║
║  │  }                                             │             ║
║  │  // Hot path: chỉ load 40 bytes thay vì 200+ │             ║
║  │  // → 5x ít cache pollution!                  │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  PATTERN 4: Struct Field Ordering:                            ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // ❌ Padding waste                           │             ║
║  │  type Bad struct {                             │             ║
║  │      a bool    // 1B + 7B padding              │             ║
║  │      b int64   // 8B                           │             ║
║  │      c bool    // 1B + 7B padding              │             ║
║  │      d int64   // 8B                           │             ║
║  │  }                                             │             ║
║  │  // sizeof = 32 bytes (50% wasted!)            │             ║
║  │                                                │             ║
║  │  // ✅ Optimized ordering                      │             ║
║  │  type Good struct {                            │             ║
║  │      b int64   // 8B                           │             ║
║  │      d int64   // 8B                           │             ║
║  │      a bool    // 1B                           │             ║
║  │      c bool    // 1B + 6B padding              │             ║
║  │  }                                             │             ║
║  │  // sizeof = 24 bytes (25% smaller!)           │             ║
║  │                                                │             ║
║  │  // Kiểm tra: go vet -fieldalignment ./...    │             ║
║  │  // Hoặc: github.com/dominikh/go-tools        │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.9 Go Memory Benchmarks — Chứng minh Memory Hierarchy

```go
// memory_bench_test.go — Chạy: go test -bench=. -benchmem

package membench

import (
    "math/rand"
    "testing"
    "unsafe"
)

// ═══════════════════════════════════════════════════════
// BENCHMARK 1: Array of Structs vs Struct of Arrays
// ═══════════════════════════════════════════════════════

type UserAoS struct {
    Name  [32]byte
    Age   int64
    Email [32]byte
    Score float64
}

func BenchmarkSumScore_AoS(b *testing.B) {
    data := make([]UserAoS, 1_000_000)
    for i := range data {
        data[i].Score = float64(i)
    }
    b.ResetTimer()
    for n := 0; n < b.N; n++ {
        sum := 0.0
        for i := range data {
            sum += data[i].Score
        }
    }
}

// SoA approach
type UsersSoA struct {
    Scores []float64
    Ages   []int64
    Names  [][32]byte
    Emails [][32]byte
}

func BenchmarkSumScore_SoA(b *testing.B) {
    data := UsersSoA{Scores: make([]float64, 1_000_000)}
    for i := range data.Scores {
        data.Scores[i] = float64(i)
    }
    b.ResetTimer()
    for n := 0; n < b.N; n++ {
        sum := 0.0
        for _, s := range data.Scores {
            sum += s
        }
    }
}
// KỲ VỌNG: SoA nhanh hơn 3-8x!

// ═══════════════════════════════════════════════════════
// BENCHMARK 2: Row-major vs Column-major traversal
// ═══════════════════════════════════════════════════════

const MatSize = 1024

func BenchmarkMatrix_RowMajor(b *testing.B) {
    matrix := [MatSize][MatSize]int64{}
    b.ResetTimer()
    for n := 0; n < b.N; n++ {
        sum := int64(0)
        for i := 0; i < MatSize; i++ {
            for j := 0; j < MatSize; j++ {
                sum += matrix[i][j] // sequential!
            }
        }
    }
}

func BenchmarkMatrix_ColMajor(b *testing.B) {
    matrix := [MatSize][MatSize]int64{}
    b.ResetTimer()
    for n := 0; n < b.N; n++ {
        sum := int64(0)
        for j := 0; j < MatSize; j++ {
            for i := 0; i < MatSize; i++ {
                sum += matrix[i][j] // stride = 1024×8!
            }
        }
    }
}
// KỲ VỌNG: RowMajor nhanh hơn 5-20x!

// ═══════════════════════════════════════════════════════
// BENCHMARK 3: Struct padding impact
// ═══════════════════════════════════════════════════════

type PaddedBad struct {
    a bool
    b int64
    c bool
    d int64
}

type PaddedGood struct {
    b int64
    d int64
    a bool
    c bool
}

func BenchmarkStruct_BadPadding(b *testing.B) {
    data := make([]PaddedBad, 1_000_000)
    b.ResetTimer()
    for n := 0; n < b.N; n++ {
        sum := int64(0)
        for i := range data {
            sum += data[i].b + data[i].d
        }
    }
}

func BenchmarkStruct_GoodPadding(b *testing.B) {
    data := make([]PaddedGood, 1_000_000)
    b.ResetTimer()
    for n := 0; n < b.N; n++ {
        sum := int64(0)
        for i := range data {
            sum += data[i].b + data[i].d
        }
    }
}
// KỲ VỌNG: Good nhanh hơn ~20-30% và dùng ít memory!

// ═══════════════════════════════════════════════════════
// BENCHMARK 4: Map vs Slice lookup (small dataset)
// ═══════════════════════════════════════════════════════

func BenchmarkLookup_Map(b *testing.B) {
    m := make(map[int]int, 100)
    for i := 0; i < 100; i++ {
        m[i] = i * 2
    }
    b.ResetTimer()
    for n := 0; n < b.N; n++ {
        key := rand.Intn(100)
        _ = m[key]
    }
}

func BenchmarkLookup_Slice(b *testing.B) {
    s := make([]int, 100)
    for i := 0; i < 100; i++ {
        s[i] = i * 2
    }
    b.ResetTimer()
    for n := 0; n < b.N; n++ {
        key := rand.Intn(100)
        _ = s[key]
    }
}
// KỲ VỌNG: Slice nhanh hơn 5-10x cho small datasets!
// → Map: hash + pointer chase = cache unfriendly
// → Slice: direct index = cache friendly

func init() {
    // Show struct sizes
    _ = unsafe.Sizeof(PaddedBad{})   // 32 bytes
    _ = unsafe.Sizeof(PaddedGood{})  // 24 bytes
    _ = unsafe.Sizeof(UserAoS{})     // 88 bytes per user
}
```

```
╔═══════════════════════════════════════════════════════════════╗
║   CHẠY VÀ ĐỌC KẾT QUẢ BENCHMARK                            ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  $ go test -bench=. -benchmem                                 ║
║                                                               ║
║  Kết quả mẫu (Apple M2):                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  BenchmarkSumScore_AoS-8                        ║
║  │    →    200   5234567 ns/op                     ║
║  │  BenchmarkSumScore_SoA-8                        ║
║  │    →   1000    982345 ns/op                     ║
║  │  → SoA NHANH HƠN ~5.3x!                        ║
║  │    (vì chỉ load scores, không load names/email) ║
║  │                                                  ║
║  │  BenchmarkMatrix_RowMajor-8                     ║
║  │    →   1000   1023456 ns/op                     ║
║  │  BenchmarkMatrix_ColMajor-8                     ║
║  │    →    100   8234567 ns/op                     ║
║  │  → RowMajor NHANH HƠN ~8x!                     ║
║  │    (sequential vs stride access)                 ║
║  │                                                  ║
║  │  BenchmarkStruct_BadPadding-8                   ║
║  │    →    500   2134567 ns/op                     ║
║  │  BenchmarkStruct_GoodPadding-8                  ║
║  │    →    600   1734567 ns/op                     ║
║  │  → Good: ~23% nhanh hơn + 25% ít memory!       ║
║  │                                                  ║
║  │  BenchmarkLookup_Map-8                          ║
║  │    → 10000000   52.1 ns/op                      ║
║  │  BenchmarkLookup_Slice-8                        ║
║  │    → 100000000   6.2 ns/op                      ║
║  │  → Slice NHANH HƠN ~8.4x cho small lookup!     ║
║  │                                                  ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ TỔNG KẾT:                                                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Pattern                │ Speedup            │             ║
║  │  AoS → SoA             │ 3-8x               │             ║
║  │  ColMajor → RowMajor   │ 5-20x              │             ║
║  │  Bad padding → Good    │ 20-30%             │             ║
║  │  Map → Slice (small)   │ 5-10x              │             ║
║  │                                                │             ║
║  │  → TẤT CẢ đều là kết quả trực tiếp         │             ║
║  │    của MEMORY HIERARCHY!                       │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.10 Cache Write Policies — Ghi data vào cache như thế nào?

Khi CPU **ghi** (write) data, có 2 câu hỏi quan trọng: (1) data được ghi vào đâu? (2) khi nào data đến RAM thật? Chính sách write quyết định **consistency vs performance** — trade-off giống hệt database WAL.

```
╔═══════════════════════════════════════════════════════════════╗
║   CACHE WRITE POLICIES                                       ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ① WRITE-THROUGH:                                             ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  CPU write data:                               │             ║
║  │  ┌─────────┐                                   │             ║
║  │  │  Cache   │ ← ghi VÀO                       │             ║
║  │  └────┬────┘                                   │             ║
║  │       │ ĐỒNG THỜI                              │             ║
║  │       ▼                                        │             ║
║  │  ┌─────────┐                                   │             ║
║  │  │   RAM   │ ← cũng ghi VÀO                   │             ║
║  │  └─────────┘                                   │             ║
║  │                                                │             ║
║  │  ✅ Ưu: Cache & RAM LUÔN đồng bộ              │             ║
║  │  ❌ Nhược: MỖI lần write = write RAM (CHẬM!) │             ║
║  │  → Dùng cho: L1 instruction cache             │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ② WRITE-BACK (phổ biến hơn):                                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  CPU write data:                               │             ║
║  │  ┌─────────┐                                   │             ║
║  │  │  Cache   │ ← ghi VÀO + đánh dấu "dirty"   │             ║
║  │  └────┬────┘                                   │             ║
║  │       │ CHỈ KHI bị evict                       │             ║
║  │       ▼                                        │             ║
║  │  ┌─────────┐                                   │             ║
║  │  │   RAM   │ ← MỚI ghi vào RAM                │             ║
║  │  └─────────┘                                   │             ║
║  │                                                │             ║
║  │  ✅ Ưu: Write NHANH (chỉ vào cache)          │             ║
║  │  ✅ Ưu: Gom nhiều writes → 1 lần flush RAM   │             ║
║  │  ❌ Nhược: Cache & RAM có thể KHÁC nhau       │             ║
║  │  → Dùng cho: L1 data cache, L2, L3            │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ③ WRITE-ALLOCATE vs NO-WRITE-ALLOCATE:                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Khi write MISS (data chưa có trong cache):   │             ║
║  │                                                │             ║
║  │  Write-Allocate:                               │             ║
║  │  → Fetch data từ RAM vào cache TRƯỚC          │             ║
║  │  → Rồi mới write vào cache                    │             ║
║  │  → Tốt nếu sẽ đọc lại data này sớm         │             ║
║  │                                                │             ║
║  │  No-Write-Allocate:                            │             ║
║  │  → Write thẳng xuống RAM                       │             ║
║  │  → KHÔNG mang data vào cache                   │             ║
║  │  → Tốt nếu data write-only (streaming)       │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ SONG SONG VỚI DATABASE:                                   ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  CPU Cache Write-Back ≈ Database Buffer Pool! │             ║
║  │                                                │             ║
║  │  ┌──────────────┬─────────────────────┐        │             ║
║  │  │ CPU Cache    │ Database             │        │             ║
║  │  ├──────────────┼─────────────────────┤        │             ║
║  │  │ Cache line   │ Buffer page          │        │             ║
║  │  │ Dirty bit    │ Dirty page flag      │        │             ║
║  │  │ Eviction     │ Checkpoint/Flush     │        │             ║
║  │  │ Write-back   │ WAL (Write-Ahead Log)│        │             ║
║  │  │ LRU policy   │ Buffer eviction LRU  │        │             ║
║  │  │ Cache miss   │ Buffer pool miss     │        │             ║
║  │  │ → fetch RAM  │ → read from disk     │        │             ║
║  │  └──────────────┴─────────────────────┘        │             ║
║  │                                                │             ║
║  │  → PostgreSQL WAL = write-back + journal!     │             ║
║  │  → Redis AOF = write-through strategy!        │             ║
║  │  → Cùng trade-off: speed vs durability        │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.11 NUMA — Non-Uniform Memory Access

Trên server **nhiều CPU socket** (phổ biến trong production), không phải mọi RAM đều có tốc độ truy cập giống nhau. RAM gần CPU socket hiện tại nhanh hơn RAM xa. Đây là NUMA — và hiểu nó là bắt buộc khi tuning database/cache trên bare-metal servers.

```
╔═══════════════════════════════════════════════════════════════╗
║   NUMA — NON-UNIFORM MEMORY ACCESS                           ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  UMA (cũ) vs NUMA (hiện đại):                                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  UMA (Uniform Memory Access):                  │             ║
║  │  ┌────────┐  ┌────────┐                        │             ║
║  │  │ CPU 0  │  │ CPU 1  │                        │             ║
║  │  └───┬────┘  └────┬───┘                        │             ║
║  │      └──────┬─────┘                             │             ║
║  │             │ (shared bus)                      │             ║
║  │      ┌──────┴──────┐                            │             ║
║  │      │     RAM     │  ← TẤT CẢ cùng tốc độ   │             ║
║  │      └─────────────┘                            │             ║
║  │  ❌ Bus nghẽn khi nhiều CPUs truy cập!        │             ║
║  │                                                │             ║
║  │  NUMA (Non-Uniform Memory Access):             │             ║
║  │  ┌──────────────┐    ┌──────────────┐          │             ║
║  │  │   Node 0     │    │   Node 1     │          │             ║
║  │  │ ┌────────┐   │    │ ┌────────┐   │          │             ║
║  │  │ │ CPU 0  │   │    │ │ CPU 1  │   │          │             ║
║  │  │ └────────┘   │    │ └────────┘   │          │             ║
║  │  │ ┌────────┐   │    │ ┌────────┐   │          │             ║
║  │  │ │ RAM 0  │   │◄──►│ │ RAM 1  │   │          │             ║
║  │  │ │ (local)│   │ QPI │ │ (local)│   │          │             ║
║  │  │ └────────┘   │    │ └────────┘   │          │             ║
║  │  └──────────────┘    └──────────────┘          │             ║
║  │                                                │             ║
║  │  CPU 0 → RAM 0: ~80ns  (LOCAL — nhanh!)       │             ║
║  │  CPU 0 → RAM 1: ~130ns (REMOTE — chậm 60%!)  │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  TẠI SAO BACKEND PHẢI QUAN TÂM:                              ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Database Servers:                          │             ║
║  │     → PostgreSQL shared_buffers trên NUMA     │             ║
║  │     → Nếu buffer nằm ở remote node:          │             ║
║  │       mỗi page access chậm thêm 50ns!        │             ║
║  │     → Triệu queries/giây × 50ns = VẤN ĐỀ!  │             ║
║  │                                                │             ║
║  │  2. Redis:                                     │             ║
║  │     → Single-threaded → pin vào 1 NUMA node  │             ║
║  │     → numactl --cpunodebind=0 redis-server    │             ║
║  │                                                │             ║
║  │  3. Kafka:                                     │             ║
║  │     → Page cache intensive                     │             ║
║  │     → NUMA-aware allocation = ít latency      │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  LINUX NUMA COMMANDS:                                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  # Xem topology                                │             ║
║  │  $ numactl --hardware                         │             ║
║  │  available: 2 nodes (0-1)                      │             ║
║  │  node 0 cpus: 0 1 2 3 4 5                     │             ║
║  │  node 0 size: 32768 MB                         │             ║
║  │  node 1 cpus: 6 7 8 9 10 11                   │             ║
║  │  node 1 size: 32768 MB                         │             ║
║  │                                                │             ║
║  │  # Xem NUMA misses                             │             ║
║  │  $ numastat                                    │             ║
║  │  → numa_miss cao = performance problem!       │             ║
║  │                                                │             ║
║  │  # Pin process vào node 0                      │             ║
║  │  $ numactl --cpunodebind=0 --membind=0 ./app  │             ║
║  │                                                │             ║
║  │  # Interleave memory (spread đều)             │             ║
║  │  $ numactl --interleave=all ./app              │             ║
║  │  → Tốt cho workloads random access           │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ GẮN VỚI GO:                                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Go runtime KHÔNG có NUMA-awareness!          │             ║
║  │  → Goroutines có thể chạy trên ANY node      │             ║
║  │  → GC threads quét ALL memory → cross-node!  │             ║
║  │                                                │             ║
║  │  Workarounds:                                  │             ║
║  │  • Chạy nhiều Go instances, mỗi cái pin vào │             ║
║  │    1 NUMA node (giống Redis cluster)           │             ║
║  │  • GOMAXPROCS = cores trên 1 node              │             ║
║  │  • numactl --cpunodebind=0 --membind=0 ./app  │             ║
║  │                                                │             ║
║  │  VD: Server 2 sockets × 12 cores:             │             ║
║  │  → KHÔNG: 1 Go app, GOMAXPROCS=24             │             ║
║  │  → CÓ: 2 Go apps, GOMAXPROCS=12, mỗi cái   │             ║
║  │    pin vào 1 NUMA node + load balancer phía   │             ║
║  │    trước                                       │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.12 Memory Alignment — Tại sao struct padding tồn tại?

CPU đọc memory theo **aligned boundaries** — nghĩa là int64 phải nằm ở địa chỉ chia hết cho 8. Nếu data bị misaligned, CPU phải đọc **2 lần** thay vì 1 lần. Đây là lý do Go compiler tự động thêm padding vào structs.

```
╔═══════════════════════════════════════════════════════════════╗
║   MEMORY ALIGNMENT — TẠI SAO CẦN PADDING?                   ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  QUY TẮC ALIGNMENT:                                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Mỗi kiểu data yêu cầu alignment riêng:     │             ║
║  │                                                │             ║
║  │  ┌──────────┬──────────┬────────────┐          │             ║
║  │  │ Kiểu     │ Size     │ Alignment  │          │             ║
║  │  ├──────────┼──────────┼────────────┤          │             ║
║  │  │ bool     │ 1 byte   │ 1 byte     │          │             ║
║  │  │ int8     │ 1 byte   │ 1 byte     │          │             ║
║  │  │ int16    │ 2 bytes  │ 2 bytes    │          │             ║
║  │  │ int32    │ 4 bytes  │ 4 bytes    │          │             ║
║  │  │ int64    │ 8 bytes  │ 8 bytes    │          │             ║
║  │  │ float64  │ 8 bytes  │ 8 bytes    │          │             ║
║  │  │ string   │ 16 bytes │ 8 bytes    │          │             ║
║  │  │ slice    │ 24 bytes │ 8 bytes    │          │             ║
║  │  │ pointer  │ 8 bytes  │ 8 bytes    │          │             ║
║  │  └──────────┴──────────┴────────────┘          │             ║
║  │                                                │             ║
║  │  Quy tắc: Địa chỉ phải chia hết cho alignment│             ║
║  │  VD: int64 ở địa chỉ 0, 8, 16... (✅)       │             ║
║  │      int64 ở địa chỉ 5 (❌ misaligned!)     │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  MISALIGNED ACCESS — Chuyện gì xảy ra?                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌ word 0──────────┐┌ word 1──────────┐        │             ║
║  │  │ 0 1 2 3 4 5 6 7 ││ 8 9 10 11 ...  │        │             ║
║  │  └─────────────────┘└─────────────────┘        │             ║
║  │                                                │             ║
║  │  ALIGNED: int64 ở addr 0                      │             ║
║  │  → CPU đọc word 0 = 1 memory access ✅       │             ║
║  │                                                │             ║
║  │  MISALIGNED: int64 ở addr 5                   │             ║
║  │  → CPU đọc word 0 (lấy byte 5-7)             │             ║
║  │  → CPU đọc word 1 (lấy byte 8-12)            │             ║
║  │  → Ghép lại = 2 memory access! ❌             │             ║
║  │  → 2x chậm hơn!                              │             ║
║  │                                                │             ║
║  │  ⚠️ Trên ARM: misaligned = CRASH (SIGBUS)!   │             ║
║  │  x86 cho phép nhưng CHẬM hơn.                 │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  STRUCT PADDING TRONG GO:                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  type Example struct {                         │             ║
║  │      a bool    // offset 0, size 1             │             ║
║  │      // [7 bytes PADDING] ← compiler thêm!   │             ║
║  │      b int64   // offset 8, size 8 (align 8)  │             ║
║  │      c bool    // offset 16, size 1            │             ║
║  │      // [3 bytes PADDING]                      │             ║
║  │      d int32   // offset 20, size 4 (align 4) │             ║
║  │      e bool    // offset 24, size 1            │             ║
║  │      // [7 bytes PADDING] ← struct align = 8 │             ║
║  │  }                                             │             ║
║  │  // Total: 32 bytes (13 bytes padding = 40%!) │             ║
║  │                                                │             ║
║  │  // Kiểm tra:                                 │             ║
║  │  unsafe.Sizeof(Example{})    // 32             │             ║
║  │  unsafe.Alignof(Example{})   // 8              │             ║
║  │  unsafe.Offsetof(Example{}.b) // 8             │             ║
║  │  unsafe.Offsetof(Example{}.c) // 16            │             ║
║  │  unsafe.Offsetof(Example{}.d) // 20            │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  TỐI ƯU STRUCT ORDERING:                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  CÔNG THỨC: Sắp xếp fields GIẢM DẦN theo    │             ║
║  │  alignment requirement!                        │             ║
║  │                                                │             ║
║  │  // ❌ Bad: 32 bytes                           │             ║
║  │  type Bad struct {                             │             ║
║  │      a bool     // align 1                     │             ║
║  │      b int64    // align 8                     │             ║
║  │      c bool     // align 1                     │             ║
║  │      d int32    // align 4                     │             ║
║  │      e bool     // align 1                     │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  // ✅ Good: 16 bytes (50% nhỏ hơn!)         │             ║
║  │  type Good struct {                            │             ║
║  │      b int64    // align 8, offset 0           │             ║
║  │      d int32    // align 4, offset 8           │             ║
║  │      a bool     // align 1, offset 12          │             ║
║  │      c bool     // align 1, offset 13          │             ║
║  │      e bool     // align 1, offset 14          │             ║
║  │      // [1 byte padding] → total 16 bytes     │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  TIẾT KIỆM: 32 bytes → 16 bytes = 50%!       │             ║
║  │  • 1M structs: 32MB → 16MB                    │             ║
║  │  • Ít cache lines cần load = NHANH hơn!      │             ║
║  │                                                │             ║
║  │  // Tools kiểm tra:                            │             ║
║  │  $ go vet -fieldalignment ./...                │             ║
║  │  $ go install golang.org/x/tools/go/analysis/\│             ║
║  │    passes/fieldalignment/cmd/fieldalignment    │             ║
║  │  $ fieldalignment -fix ./...                   │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ⚠️ ATOMIC VÀ ALIGNMENT:                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  sync/atomic yêu cầu int64 PHẢI aligned 8!   │             ║
║  │                                                │             ║
║  │  // ❌ BUG trên 32-bit architectures:         │             ║
║  │  type Counter struct {                         │             ║
║  │      name string                               │             ║
║  │      val  int64 // offset 16 ✅ trên amd64   │             ║
║  │      //                 nhưng có thể ❌ trên  │             ║
║  │      //                 32-bit nếu name thay  │             ║
║  │      //                 đổi alignment          │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  // ✅ AN TOÀN: đặt int64 ĐẦU struct!       │             ║
║  │  type Counter struct {                         │             ║
║  │      val  int64  // offset 0 → LUÔN aligned! │             ║
║  │      name string                               │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  // Hoặc dùng atomic.Int64 (Go 1.19+):       │             ║
║  │  var counter atomic.Int64                      │             ║
║  │  counter.Add(1) // tự xử lý alignment!       │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.13 Memory-Mapped I/O (mmap) — Khi RAM gặp Disk

mmap cho phép ứng dụng truy cập file trên disk **như thể nó nằm trong RAM**. OS tự động quản lý page fault và caching. Đây là kỹ thuật nền tảng của Kafka, BoltDB, SQLite, và hầu hết database engines.

```
╔═══════════════════════════════════════════════════════════════╗
║   MEMORY-MAPPED I/O (mmap)                                   ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  TRADITIONAL I/O vs mmap:                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  TRADITIONAL (read/write syscalls):            │             ║
║  │  ┌──────────┐    ┌──────────┐    ┌─────────┐ │             ║
║  │  │ App buf  │←──│ Kernel   │←──│  Disk   │ │             ║
║  │  │ (user)   │ ② │ buffer   │ ① │         │ │             ║
║  │  └──────────┘    └──────────┘    └─────────┘ │             ║
║  │  → 2 lần copy! (disk→kernel→user)           │             ║
║  │  → Mỗi read/write = 1 syscall (đắt!)        │             ║
║  │                                                │             ║
║  │  MMAP (zero-copy concept):                     │             ║
║  │  ┌──────────┐                    ┌─────────┐  │             ║
║  │  │ App sees │────────────────────│  Disk   │  │             ║
║  │  │ virtual  │  (page table map)  │         │  │             ║
║  │  │ memory   │                    └─────────┘  │             ║
║  │  └──────────┘                                  │             ║
║  │  → App đọc "memory" → OS tự load page       │             ║
║  │  → KHÔNG cần read() syscall!                  │             ║
║  │  → Tận dụng page cache của OS                 │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CÁC MODE CỦA MMAP:                                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  MAP_PRIVATE:                                  │             ║
║  │  → Copy-on-Write                               │             ║
║  │  → Thay đổi KHÔNG ảnh hưởng file gốc        │             ║
║  │  → Dùng cho: đọc shared libraries (.so)       │             ║
║  │                                                │             ║
║  │  MAP_SHARED:                                   │             ║
║  │  → Thay đổi ĐƯỢC ghi lại file                │             ║
║  │  → Nhiều process thấy CÙNG data               │             ║
║  │  → Dùng cho: database files, IPC              │             ║
║  │                                                │             ║
║  │  MAP_ANONYMOUS:                                │             ║
║  │  → KHÔNG gắn file                              │             ║
║  │  → Chỉ allocate memory                        │             ║
║  │  → Go runtime dùng cái này cho heap!          │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ AI DÙNG MMAP?                                              ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Kafka:                                     │             ║
║  │     → Log segments = mmap files               │             ║
║  │     → OS page cache = "free" caching          │             ║
║  │     → sendfile() = zero-copy network I/O      │             ║
║  │     → Lý do Kafka nhanh bất thường!          │             ║
║  │                                                │             ║
║  │  2. BoltDB / bbolt (Go):                       │             ║
║  │     → Entire database = 1 mmap file            │             ║
║  │     → Read = pointer dereference (siêu nhanh!)│             ║
║  │     → etcd dùng bbolt!                         │             ║
║  │                                                │             ║
║  │  3. SQLite:                                    │             ║
║  │     → mmap mode cho read performance          │             ║
║  │     → PRAGMA mmap_size = N;                    │             ║
║  │                                                │             ║
║  │  4. MongoDB (WiredTiger):                      │             ║
║  │     → mmap cho block cache                     │             ║
║  │                                                │             ║
║  │  5. RocksDB / LevelDB:                         │             ║
║  │     → SST files có thể mmap                   │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ GO VÀ MMAP:                                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // Cách dùng mmap trong Go:                   │             ║
║  │  import "syscall"                              │             ║
║  │                                                │             ║
║  │  f, _ := os.Open("data.bin")                   │             ║
║  │  info, _ := f.Stat()                           │             ║
║  │  size := int(info.Size())                      │             ║
║  │                                                │             ║
║  │  data, _ := syscall.Mmap(                      │             ║
║  │      int(f.Fd()),                              │             ║
║  │      0,        // offset                       │             ║
║  │      size,     // length                       │             ║
║  │      syscall.PROT_READ,                        │             ║
║  │      syscall.MAP_PRIVATE,                      │             ║
║  │  )                                             │             ║
║  │  // data là []byte → đọc như slice bình thường│             ║
║  │  // OS tự quản lý page fault + caching!       │             ║
║  │                                                │             ║
║  │  defer syscall.Munmap(data)                    │             ║
║  │                                                │             ║
║  │  ⚠️ CẢNH BÁO:                                │             ║
║  │  • SIGBUS nếu file bị truncate khi đang mmap │             ║
║  │  • GC KHÔNG biết về mmap memory               │             ║
║  │  • Khó control I/O timing (OS quyết định)    │             ║
║  │  → Dùng thư viện: github.com/edsrzf/mmap-go  │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.14 Memory Barriers — Khi CPU đọc/ghi không theo thứ tự

Modern CPUs **sắp xếp lại** thứ tự đọc/ghi memory để tối ưu hiệu năng. Điều này an toàn cho single-thread, nhưng trong concurrent programming, nó gây ra bugs cực kỳ khó debug. Memory barriers (fences) buộc CPU phải tuân thủ thứ tự.

```
╔═══════════════════════════════════════════════════════════════╗
║   MEMORY BARRIERS (MEMORY FENCES)                            ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  VẤN ĐỀ: CPU REORDERING                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Code bạn viết:                                │             ║
║  │  x = 42         // ① store x                  │             ║
║  │  ready = true   // ② store ready               │             ║
║  │                                                │             ║
║  │  CPU CÓ THỂ thực thi:                         │             ║
║  │  ready = true   // ② TRƯỚC!                   │             ║
║  │  x = 42         // ① SAU!                     │             ║
║  │                                                │             ║
║  │  Tại sao? Vì:                                  │             ║
║  │  • Store buffer: writes chưa đến cache ngay   │             ║
║  │  • OoOE: CPU sắp lại cho hiệu năng           │             ║
║  │  • Compiler: cũng có thể reorder!             │             ║
║  │                                                │             ║
║  │  Hậu quả: Goroutine khác thấy ready=true      │             ║
║  │  nhưng x CHƯA = 42! → BUG!                    │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CÁC LOẠI MEMORY BARRIER:                                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Store Barrier (sfence):                    │             ║
║  │     → Tất cả stores TRƯỚC barrier phải       │             ║
║  │       hoàn thành TRƯỚC stores SAU barrier      │             ║
║  │                                                │             ║
║  │  2. Load Barrier (lfence):                     │             ║
║  │     → Tất cả loads TRƯỚC barrier phải        │             ║
║  │       hoàn thành TRƯỚC loads SAU barrier        │             ║
║  │                                                │             ║
║  │  3. Full Barrier (mfence):                     │             ║
║  │     → Tất cả loads VÀ stores TRƯỚC barrier   │             ║
║  │       phải hoàn thành TRƯỚC bất kỳ thao tác  │             ║
║  │       SAU barrier                               │             ║
║  │                                                │             ║
║  │  x86: TSO (Total Store Order)                  │             ║
║  │  → "Mạnh" nhất, ít reorder nhất              │             ║
║  │  → Store-load reorder VẪN xảy ra!            │             ║
║  │                                                │             ║
║  │  ARM: Weak ordering                            │             ║
║  │  → Reorder MỌI THỨ trừ khi có barrier        │             ║
║  │  → Nhiều bugs CHỈ xuất hiện trên ARM!        │             ║
║  │  → Apple M1/M2 = ARM = CẨN THẬN!            │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ GO VÀ MEMORY ORDERING:                                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Go Memory Model đảm bảo "happens-before":   │             ║
║  │                                                │             ║
║  │  // ❌ DATA RACE — KHÔNG CÓ happens-before!  │             ║
║  │  var x int                                     │             ║
║  │  var ready bool                                │             ║
║  │                                                │             ║
║  │  go func() {                                   │             ║
║  │      x = 42                                    │             ║
║  │      ready = true // CPU có thể reorder!      │             ║
║  │  }()                                           │             ║
║  │                                                │             ║
║  │  for !ready {} // busy wait                    │             ║
║  │  fmt.Println(x) // có thể in 0! 💀           │             ║
║  │                                                │             ║
║  │  // ✅ ĐÚNG — dùng channel (có barrier):      │             ║
║  │  ch := make(chan struct{})                      │             ║
║  │  go func() {                                   │             ║
║  │      x = 42                                    │             ║
║  │      ch <- struct{}{} // barrier: store x       │             ║
║  │  }()                  //   happens-before       │             ║
║  │  <-ch                 //   receive              │             ║
║  │  fmt.Println(x) // CHẮC CHẮN 42 ✅            │             ║
║  │                                                │             ║
║  │  // ✅ ĐÚNG — dùng sync/atomic:               │             ║
║  │  var x int64                                   │             ║
║  │  var ready atomic.Bool                         │             ║
║  │                                                │             ║
║  │  go func() {                                   │             ║
║  │      atomic.StoreInt64(&x, 42)                 │             ║
║  │      ready.Store(true)  // memory barrier!     │             ║
║  │  }()                                           │             ║
║  │                                                │             ║
║  │  for !ready.Load() {}                          │             ║
║  │  fmt.Println(atomic.LoadInt64(&x)) // 42 ✅   │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  HAPPENS-BEFORE TRONG GO:                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Các thao tác TẠO happens-before:              │             ║
║  │                                                │             ║
║  │  1. Channel send → channel receive             │             ║
║  │  2. sync.Mutex.Unlock → Mutex.Lock             │             ║
║  │  3. sync.WaitGroup.Done → WaitGroup.Wait       │             ║
║  │  4. sync.Once.Do(f) → f hoàn thành            │             ║
║  │  5. atomic operations (implicit barriers)      │             ║
║  │  6. go f() → f bắt đầu chạy                  │             ║
║  │                                                │             ║
║  │  ⚠️ KHÔNG tạo happens-before:                 │             ║
║  │  • Đọc/ghi biến thường từ nhiều goroutines   │             ║
║  │  • time.Sleep (KHÔNG phải synchronization!)    │             ║
║  │  • runtime.Gosched()                           │             ║
║  │                                                │             ║
║  │  // Luôn chạy với race detector:               │             ║
║  │  $ go test -race ./...                         │             ║
║  │  $ go run -race main.go                        │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.15 Cache Coherence — MESI Protocol

Trên CPU multi-core, mỗi core có L1/L2 cache RIÊNG. Khi core A ghi vào cache line mà core B cũng đang giữ, phải có cơ chế đồng bộ. **MESI protocol** là giao thức phổ biến nhất để giải quyết bài toán này — và hiểu nó giúp bạn hiểu tại sao **concurrent writes chậm kinh khủng**.

```
╔═══════════════════════════════════════════════════════════════╗
║   CACHE COHERENCE — MESI PROTOCOL                            ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  VẤN ĐỀ: CACHE KHÔNG NHẤT QUÁN                              ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Core 0 cache: x = 42                         │             ║
║  │  Core 1 cache: x = 42                         │             ║
║  │  RAM:          x = 42                          │             ║
║  │                                                │             ║
║  │  Core 0 ghi: x = 100                          │             ║
║  │  Core 0 cache: x = 100 ← đã đổi!            │             ║
║  │  Core 1 cache: x = 42  ← VẪN CŨ! ❌         │             ║
║  │  RAM:          x = 42  ← VẪN CŨ!             │             ║
║  │                                                │             ║
║  │  Core 1 đọc x → lấy 42? hay 100?            │             ║
║  │  → PHẢI CÓ PROTOCOL ĐỂ ĐỒNG BỘ!            │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  4 TRẠNG THÁI MESI:                                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌──────────┬──────────────────────────────┐   │             ║
║  │  │ State    │ Ý nghĩa                       │   │             ║
║  │  ├──────────┼──────────────────────────────┤   │             ║
║  │  │ Modified │ CHỈ core này có, ĐÃ SỬA     │   │             ║
║  │  │ (M)      │ RAM chưa cập nhật (dirty)     │   │             ║
║  │  │          │ → Phải flush trước khi share  │   │             ║
║  │  ├──────────┼──────────────────────────────┤   │             ║
║  │  │ Exclusive│ CHỈ core này có, CHƯA SỬA    │   │             ║
║  │  │ (E)      │ RAM đã cập nhật (clean)       │   │             ║
║  │  │          │ → Có thể chuyển sang M ngay   │   │             ║
║  │  ├──────────┼──────────────────────────────┤   │             ║
║  │  │ Shared   │ NHIỀU cores cùng có copy      │   │             ║
║  │  │ (S)      │ Tất cả giống RAM (clean)      │   │             ║
║  │  │          │ → Muốn write phải invalidate  │   │             ║
║  │  ├──────────┼──────────────────────────────┤   │             ║
║  │  │ Invalid  │ Cache line KHÔNG HỢP LỆ       │   │             ║
║  │  │ (I)      │ Phải fetch lại từ RAM/cache   │   │             ║
║  │  └──────────┴──────────────────────────────┘   │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  STATE MACHINE FLOW:                                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  I ──(local read)──► E ──(local write)──► M   │             ║
║  │  │                   │                    │    │             ║
║  │  │                   │(remote read)       │    │             ║
║  │  │                   ▼                    │    │             ║
║  │  │                   S ◄──(remote read)───┘    │             ║
║  │  │                   │                         │             ║
║  │  │(remote write)     │(remote write)           │             ║
║  │  │                   ▼                         │             ║
║  │  ◄───────────────── I                          │             ║
║  │                                                │             ║
║  │  Khi Core A WRITE một cache line:              │             ║
║  │  1. Broadcast "Invalidate" cho ALL cores       │             ║
║  │  2. Các cores khác đánh dấu line = Invalid   │             ║
║  │  3. Core A chuyển line sang Modified            │             ║
║  │  4. Lần sau core B đọc → phải fetch từ A!    │             ║
║  │                                                │             ║
║  │  CHI PHÍ:                                       │             ║
║  │  • Invalidate message qua bus: ~40-100 cycles! │             ║
║  │  • Core B re-fetch: thêm ~40 cycles!          │             ║
║  │  • TỔNG: 1 write ảnh hưởng tới TẤT CẢ cores │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ SONG SONG VỚI DATABASE REPLICATION:                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌──────────────────┬────────────────────┐     │             ║
║  │  │ MESI Protocol    │ DB Replication     │     │             ║
║  │  ├──────────────────┼────────────────────┤     │             ║
║  │  │ Invalidate msg   │ Invalidation query │     │             ║
║  │  │ Modified state   │ Primary/Leader      │     │             ║
║  │  │ Shared state     │ Read replica        │     │             ║
║  │  │ Write penalty    │ Replication lag      │     │             ║
║  │  │ Bus snooping     │ Change Data Capture │     │             ║
║  │  │ Write-back       │ Async replication   │     │             ║
║  │  │ Write-through    │ Sync replication    │     │             ║
║  │  └──────────────────┴────────────────────┘     │             ║
║  │                                                │             ║
║  │  → Cùng trade-off: consistency vs latency!    │             ║
║  │  → MESI = hardware-level distributed system!  │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.16 False Sharing — Kẻ giết hiệu năng thầm lặng

False sharing xảy ra khi 2 goroutines/threads ghi vào 2 biến KHÁC NHAU nhưng nằm trên CÙNG cache line. Mỗi lần write, MESI invalidate cache line → core kia phải re-fetch. Kết quả: chậm **10-50x** dù code trông hoàn toàn đúng.

```
╔═══════════════════════════════════════════════════════════════╗
║   FALSE SHARING — PERFORMANCE KILLER                         ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  VẤN ĐỀ:                                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  type Counters struct {                        │             ║
║  │      a int64  // offset 0                      │             ║
║  │      b int64  // offset 8                      │             ║
║  │  }                                             │             ║
║  │  // Cả 2 nằm trên CÙNG 1 cache line (64B)!  │             ║
║  │                                                │             ║
║  │  Cache Line (64 bytes):                        │             ║
║  │  ┌──────────────────────────────────────┐      │             ║
║  │  │ a (8B) │ b (8B) │ ... padding ...   │      │             ║
║  │  └──────────────────────────────────────┘      │             ║
║  │                                                │             ║
║  │  Goroutine 1: tăng a liên tục                 │             ║
║  │  Goroutine 2: tăng b liên tục                 │             ║
║  │                                                │             ║
║  │  DÙ a VÀ b LÀ BIẾN KHÁC NHAU:                │             ║
║  │  → G1 write a → invalidate CÙNG line!        │             ║
║  │  → G2 phải re-fetch toàn bộ line             │             ║
║  │  → G2 write b → invalidate CÙNG line!        │             ║
║  │  → G1 phải re-fetch toàn bộ line             │             ║
║  │  → PING-PONG liên tục! 💀                    │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  GIẢI PHÁP: PADDING                                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // ❌ False sharing:                          │             ║
║  │  type BadCounters struct {                     │             ║
║  │      a int64  // cùng cache line               │             ║
║  │      b int64  // cùng cache line               │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  // ✅ Padded — mỗi biến 1 cache line riêng: │             ║
║  │  type CacheLinePad [64]byte // = 1 cache line │             ║
║  │                                                │             ║
║  │  type GoodCounters struct {                    │             ║
║  │      a    int64                                │             ║
║  │      _pad [64 - 8]byte // đẩy b sang line mới│             ║
║  │      b    int64                                │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  Cache Line 0:                                 │             ║
║  │  ┌──────────────────────────────────────┐      │             ║
║  │  │ a (8B) │ padding (56B)              │      │             ║
║  │  └──────────────────────────────────────┘      │             ║
║  │  Cache Line 1:                                 │             ║
║  │  ┌──────────────────────────────────────┐      │             ║
║  │  │ b (8B) │ ...                         │      │             ║
║  │  └──────────────────────────────────────┘      │             ║
║  │  → KHÔNG còn ping-pong!                       │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ REAL-WORLD EXAMPLES:                                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Go runtime: P struct có padding!          │             ║
║  │     → runtime/proc.go: pad [64]byte           │             ║
║  │                                                │             ║
║  │  2. sync.Pool: internal struct padded          │             ║
║  │     → Tránh false sharing giữa P's pools     │             ║
║  │                                                │             ║
║  │  3. Java: @Contended annotation               │             ║
║  │     → Tự thêm padding cho fields              │             ║
║  │                                                │             ║
║  │  4. Prometheus client_golang:                  │             ║
║  │     → Counter structs có cache line padding   │             ║
║  │                                                │             ║
║  │  5. ClickHouse:                                │             ║
║  │     → Per-thread counters padded để tránh     │             ║
║  │       false sharing                            │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

```go
// false_sharing_bench_test.go — Chạy: go test -bench=. -count=3

package falsesharing

import (
    "sync/atomic"
    "testing"
)

// ═══════════════════════════════════════════════════════
// FALSE SHARING BENCHMARK
// ═══════════════════════════════════════════════════════

type NoPad struct {
    a int64
    b int64
}

type WithPad struct {
    a    int64
    _pad [64 - 8]byte // cache line padding
    b    int64
}

func BenchmarkFalseSharing_NoPad(b *testing.B) {
    var c NoPad
    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            atomic.AddInt64(&c.a, 1)
        }
    })
    // Goroutine khác cũng write c.b cùng lúc
    go func() {
        for i := 0; i < b.N; i++ {
            atomic.AddInt64(&c.b, 1)
        }
    }()
}

func BenchmarkFalseSharing_WithPad(b *testing.B) {
    var c WithPad
    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            atomic.AddInt64(&c.a, 1)
        }
    })
    go func() {
        for i := 0; i < b.N; i++ {
            atomic.AddInt64(&c.b, 1)
        }
    }()
}

// KỲ VỌNG: WithPad nhanh hơn 3-10x trên multi-core!
// False sharing = hiệu năng tệ DÙ code đúng!
```

### 2.17 Copy-on-Write — Sao chép khi cần

Copy-on-Write (CoW) là kỹ thuật trì hoãn việc copy memory đến khi thực sự cần. Thay vì copy ngay, hai bên **chia sẻ cùng pages** và chỉ tạo bản copy khi 1 bên **WRITE**. Đây là nền tảng của `fork()`, Redis BGSAVE, và Go slice behavior.

```
╔═══════════════════════════════════════════════════════════════╗
║   COPY-ON-WRITE (CoW)                                        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  CƠ CHẾ:                                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  TRƯỚC fork():                                 │             ║
║  │  ┌──────────┐                                  │             ║
║  │  │ Process A│                                  │             ║
║  │  │ Page 0   │──►┌──────────┐                   │             ║
║  │  │ Page 1   │──►│Physical  │                   │             ║
║  │  │ Page 2   │──►│  RAM     │                   │             ║
║  │  └──────────┘   └──────────┘                   │             ║
║  │                                                │             ║
║  │  SAU fork() (chưa write):                      │             ║
║  │  ┌──────────┐                                  │             ║
║  │  │ Process A│   ┌──────────┐                   │             ║
║  │  │ Page 0   │──►│Physical  │◄── Page 0 (B)     │             ║
║  │  │ Page 1   │──►│  RAM     │◄── Page 1 (B)     │             ║
║  │  │ Page 2   │──►│(SHARED!) │◄── Page 2 (B)     │             ║
║  │  └──────────┘   └──────────┘   ┌──────────┐   │             ║
║  │                                │ Process B│   │             ║
║  │                                └──────────┘   │             ║
║  │  → 0 bytes copied! Chỉ copy page table!      │             ║
║  │  → Tất cả pages đánh dấu READ-ONLY          │             ║
║  │                                                │             ║
║  │  SAU write (Process B writes Page 1):          │             ║
║  │  ┌──────────┐   ┌──────────┐                   │             ║
║  │  │ Process A│   │Physical  │                   │             ║
║  │  │ Page 0   │──►│  RAM     │◄── Page 0 (B)     │             ║
║  │  │ Page 1   │──►│ (shared) │    Page 1'(B) ──►│             ║
║  │  │ Page 2   │──►│          │◄── Page 2 (B)     │             ║
║  │  └──────────┘   └──────────┘   ┌──────────┐   │             ║
║  │                    ↑           │ NEW copy │   │             ║
║  │                    │           │ of Page 1│   │             ║
║  │  PAGE FAULT! ──────┘           └──────────┘   │             ║
║  │  → Chỉ copy 1 page (4KB), KHÔNG toàn bộ!    │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ BACKEND APPLICATIONS:                                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Redis BGSAVE:                              │             ║
║  │     → fork() để tạo snapshot                  │             ║
║  │     → Child process đọc data (CoW shared)     │             ║
║  │     → Parent tiếp tục serve writes            │             ║
║  │     → Chỉ pages bị modify mới copy           │             ║
║  │     → 10GB Redis, 5% writes = ~500MB extra    │             ║
║  │                                                │             ║
║  │     ⚠️ Vấn đề: huge writes during BGSAVE     │             ║
║  │     → Nếu 100% pages bị modify                │             ║
║  │     → 10GB × 2 = 20GB RAM needed!             │             ║
║  │     → OOM killer! 💀                          │             ║
║  │                                                │             ║
║  │  2. PostgreSQL:                                │             ║
║  │     → fork() child cho VACUUM, pg_dump        │             ║
║  │     → Shared buffers = CoW efficient          │             ║
║  │                                                │             ║
║  │  3. Container/Docker:                          │             ║
║  │     → OverlayFS = file-level CoW              │             ║
║  │     → Base image shared, writes go to layer   │             ║
║  │     → 100 containers, 1 base image = ~ 1 copy│             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ GO SLICE VÀ CoW GOTCHA:                                   ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Go SLICES KHÔNG CÓ CoW tự động!             │             ║
║  │  Nhưng slicing tạo "shared backing array":    │             ║
║  │                                                │             ║
║  │  a := []int{1, 2, 3, 4, 5}                    │             ║
║  │  b := a[1:3] // b = [2, 3]                    │             ║
║  │                                                │             ║
║  │  // a và b SHARE backing array!               │             ║
║  │  b[0] = 99                                     │             ║
║  │  fmt.Println(a) // [1, 99, 3, 4, 5] → ĐỔI!  │             ║
║  │                                                │             ║
║  │  // ✅ Copy an toàn:                           │             ║
║  │  b := make([]int, 2)                           │             ║
║  │  copy(b, a[1:3])                               │             ║
║  │  b[0] = 99                                     │             ║
║  │  fmt.Println(a) // [1, 2, 3, 4, 5] → KHÔNG đổi│            ║
║  │                                                │             ║
║  │  // append gotcha:                             │             ║
║  │  a := make([]int, 3, 5) // len=3, cap=5       │             ║
║  │  b := append(a, 4)      // cap đủ → SHARE!   │             ║
║  │  c := append(a, 5)      // cap đủ → ĐÈ b!   │             ║
║  │  fmt.Println(b[3])      // 5! (bị c đè)      │             ║
║  │                                                │             ║
║  │  // ✅ Force copy: append vào [:len:len]       │             ║
║  │  b := append(a[:len(a):len(a)], 4) // cap=len │             ║
║  │  // → Buộc allocate backing array mới         │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.18 DMA — Direct Memory Access

DMA cho phép thiết bị (NIC, disk controller, GPU) đọc/ghi RAM **MÀ KHÔNG CẦN CPU**. CPU chỉ cần thiết lập DMA transfer rồi làm việc khác. Đây là nền tảng của zero-copy networking và high-throughput I/O.

```
╔═══════════════════════════════════════════════════════════════╗
║   DMA — DIRECT MEMORY ACCESS                                ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  KHÔNG CÓ DMA (PIO — Programmed I/O):                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌─────┐    ┌─────┐    ┌──────┐               │             ║
║  │  │Disk │→①→│ CPU │→②→│  RAM │               │             ║
║  │  └─────┘    └─────┘    └──────┘               │             ║
║  │                                                │             ║
║  │  → CPU đọc từng byte từ disk controller       │             ║
║  │  → CPU ghi từng byte vào RAM                   │             ║
║  │  → CPU bận 100% suốt quá trình I/O!          │             ║
║  │  → KHÔNG thể làm gì khác!                    │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CÓ DMA:                                                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌─────┐              ┌──────┐                │             ║
║  │  │Disk │──────DMA─────│  RAM │                │             ║
║  │  └─────┘              └──────┘                │             ║
║  │      ↑                    ↑                    │             ║
║  │  ①CPU setup           ②CPU gets                │             ║
║  │   DMA transfer        interrupt                │             ║
║  │                        "done!"                  │             ║
║  │                                                │             ║
║  │  → CPU chỉ setup + nhận interrupt            │             ║
║  │  → DMA controller tự copy data                │             ║
║  │  → CPU free để làm việc khác!                │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ZERO-COPY NETWORKING:                                        ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  TRUYỀN THỐNG (4 copies, 4 context switches): │             ║
║  │  Disk →(DMA)→ Kernel buf →(CPU)→ User buf    │             ║
║  │  →(CPU)→ Socket buf →(DMA)→ NIC               │             ║
║  │                                                │             ║
║  │  SENDFILE (2 copies, 0 context switches):      │             ║
║  │  Disk →(DMA)→ Kernel buf →(DMA)→ NIC          │             ║
║  │  → CPU KHÔNG CHẠM DATA!                       │             ║
║  │  → Kafka dùng sendfile() cho consumers!       │             ║
║  │                                                │             ║
║  │  SPLICE (Linux):                               │             ║
║  │  → Pipe-based zero-copy, linh hoạt hơn       │             ║
║  │  → Go net package dùng splice internally!     │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ AI DÙNG DMA/ZERO-COPY:                                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Kafka:                                     │             ║
║  │     → sendfile() = zero-copy từ disk → NIC   │             ║
║  │     → Lý do #1 Kafka consume nhanh bất thường│             ║
║  │                                                │             ║
║  │  2. Nginx:                                     │             ║
║  │     → sendfile on; trong config               │             ║
║  │     → Static files không qua userspace        │             ║
║  │                                                │             ║
║  │  3. DPDK / io_uring:                           │             ║
║  │     → Kernel bypass networking                 │             ║
║  │     → User-space DMA                           │             ║
║  │     → Dùng cho: trading systems, CDN, LB      │             ║
║  │                                                │             ║
║  │  4. RDMA (Remote DMA):                         │             ║
║  │     → DMA qua network! RAM → RAM trực tiếp   │             ║
║  │     → Dùng cho: HPC, distributed databases    │             ║
║  │     → ScyllaDB, FoundationDB support RDMA     │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ GO VÀ ZERO-COPY:                                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // Go tự dùng splice cho TCP → TCP:          │             ║
║  │  // net.TCPConn.ReadFrom tự detect splice!    │             ║
║  │  src, _ := net.Dial("tcp", "source:8080")      │             ║
║  │  dst, _ := net.Dial("tcp", "dest:9090")        │             ║
║  │  io.Copy(dst, src) // → splice nếu có thể!   │             ║
║  │                                                │             ║
║  │  // net.Buffers: vectored I/O (writev)        │             ║
║  │  bufs := net.Buffers{                          │             ║
║  │      []byte("header"),                         │             ║
║  │      []byte("payload"),                        │             ║
║  │      []byte("trailer"),                        │             ║
║  │  }                                             │             ║
║  │  bufs.WriteTo(conn) // 1 syscall, 0 copy!     │             ║
║  │                                                │             ║
║  │  // sendfile cho static files:                 │             ║
║  │  http.ServeFile(w, r, "big_file.zip")          │             ║
║  │  // → Go HTTP server tự dùng sendfile!        │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 2.19 Go Memory Allocator — Cách Go quản lý bộ nhớ

Go có memory allocator riêng, lấy cảm hứng từ TCMalloc (Google). Hiểu cơ chế này giúp bạn viết code ít allocation, hiểu GC pressure, và tối ưu performance cho production.

```
╔═══════════════════════════════════════════════════════════════╗
║   GO MEMORY ALLOCATOR                                        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  KIẾN TRÚC 3 LỚP:                                           ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Goroutine 1    Goroutine 2    Goroutine N    │             ║
║  │       │              │              │          │             ║
║  │       ▼              ▼              ▼          │             ║
║  │  ┌─────────┐   ┌─────────┐   ┌─────────┐     │             ║
║  │  │ mcache  │   │ mcache  │   │ mcache  │     │             ║
║  │  │ (per-P) │   │ (per-P) │   │ (per-P) │     │             ║
║  │  └────┬────┘   └────┬────┘   └────┬────┘     │             ║
║  │       │              │              │          │             ║
║  │       └──────────────┼──────────────┘          │             ║
║  │                      ▼                         │             ║
║  │              ┌──────────────┐                  │             ║
║  │              │   mcentral   │ (per size class) │             ║
║  │              │ (shared pool)│                  │             ║
║  │              └──────┬───────┘                  │             ║
║  │                     ▼                          │             ║
║  │              ┌──────────────┐                  │             ║
║  │              │    mheap     │ (global)          │             ║
║  │              │ (OS memory)  │                  │             ║
║  │              └──────────────┘                  │             ║
║  │                     ▼                          │             ║
║  │              ┌──────────────┐                  │             ║
║  │              │   OS (mmap)  │                  │             ║
║  │              └──────────────┘                  │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  TỪNG LỚP CHI TIẾT:                                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ① mcache (per-P, KHÔNG CẦN LOCK!):           │             ║
║  │     → Mỗi P (processor) có 1 mcache riêng    │             ║
║  │     → Chứa free objects theo size class       │             ║
║  │     → Allocation < 32KB: lấy từ mcache       │             ║
║  │     → KHÔNG CẦN LOCK = cực nhanh!            │             ║
║  │     → Giống CPU L1 cache (private, fast)      │             ║
║  │                                                │             ║
║  │  ② mcentral (per size class, CẦN LOCK):       │             ║
║  │     → Pool chung cho tất cả P's mcache        │             ║
║  │     → Khi mcache hết → lấy span từ mcentral  │             ║
║  │     → Cần mutex lock (nhưng ít contention)    │             ║
║  │     → Giống CPU L2 cache (shared, slower)     │             ║
║  │                                                │             ║
║  │  ③ mheap (global, CẦN LOCK):                  │             ║
║  │     → Quản lý tất cả memory từ OS            │             ║
║  │     → Allocate/free spans (group of pages)    │             ║
║  │     → Khi mcentral hết → request từ mheap    │             ║
║  │     → Giống RAM (global, slowest)             │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  SIZE CLASSES:                                                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Go chia objects thành 68 size classes:        │             ║
║  │                                                │             ║
║  │  ┌──────────┬────────────┬────────────┐        │             ║
║  │  │ Class    │ Size range │ Ví dụ       │        │             ║
║  │  ├──────────┼────────────┼────────────┤        │             ║
║  │  │ Tiny     │ < 16B      │ small ints │        │             ║
║  │  │ Small    │ 16B-32KB   │ structs    │        │             ║
║  │  │ Large    │ > 32KB     │ big slices │        │             ║
║  │  └──────────┴────────────┴────────────┘        │             ║
║  │                                                │             ║
║  │  Tiny allocator:                               │             ║
║  │  → Objects < 16 bytes, no pointers             │             ║
║  │  → Gom nhiều tiny objects vào 1 block          │             ║
║  │  → string "ab" + string "cd" → cùng block!   │             ║
║  │                                                │             ║
║  │  Small (≤ 32KB):                              │             ║
║  │  → Tìm size class phù hợp                     │             ║
║  │  → Lấy từ mcache → mcentral → mheap          │             ║
║  │  → VD: cần 33 bytes → class 48 bytes          │             ║
║  │  → Internal fragmentation: ~30%               │             ║
║  │                                                │             ║
║  │  Large (> 32KB):                               │             ║
║  │  → Allocate trực tiếp từ mheap               │             ║
║  │  → Page-aligned (8KB pages)                    │             ║
║  │  → Tốn hơn vì cần global lock                │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  STACK vs HEAP — ESCAPE ANALYSIS:                             ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Go compiler quyết định: stack hay heap?      │             ║
║  │                                                │             ║
║  │  // Stack (nhanh, tự free):                    │             ║
║  │  func sum(a, b int) int {                      │             ║
║  │      result := a + b  // stack!                │             ║
║  │      return result                             │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  // Heap (chậm, cần GC):                       │             ║
║  │  func newUser() *User {                        │             ║
║  │      u := User{Name: "Jun"} // escapes to heap│             ║
║  │      return &u               // pointer thoát!│             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  // Kiểm tra escape analysis:                  │             ║
║  │  $ go build -gcflags="-m" ./...                │             ║
║  │  → "moved to heap: u" ← bị escape!           │             ║
║  │  → "does not escape" ← tốt!                  │             ║
║  │                                                │             ║
║  │  CÁC TRƯỜNG HỢP ESCAPE:                      │             ║
║  │  • Return pointer → ESCAPE                    │             ║
║  │  • Gán vào interface{} → ESCAPE               │             ║
║  │  • Closure capture pointer → ESCAPE            │             ║
║  │  • Quá lớn cho stack → ESCAPE                 │             ║
║  │  • Slice append grow → ESCAPE                  │             ║
║  │  • Gửi qua channel → ESCAPE                   │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ sync.Pool — Object Reuse:                                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // sync.Pool = "mcache cho ứng dụng"         │             ║
║  │  var bufPool = sync.Pool{                      │             ║
║  │      New: func() interface{} {                 │             ║
║  │          return new(bytes.Buffer)               │             ║
║  │      },                                        │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  func processRequest() {                       │             ║
║  │      buf := bufPool.Get().(*bytes.Buffer)      │             ║
║  │      buf.Reset()                               │             ║
║  │      defer bufPool.Put(buf) // trả lại pool   │             ║
║  │                                                │             ║
║  │      // dùng buf...                            │             ║
║  │      buf.WriteString("hello")                  │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  ☞ Khi nào dùng sync.Pool:                    │             ║
║  │  • Tạo object đắt (bytes.Buffer)              │             ║
║  │  • Tần suất alloc/free cao                    │             ║
║  │  • Object có thể reset & reuse                │             ║
║  │                                                │             ║
║  │  ☞ Ai dùng:                                    │             ║
║  │  • encoding/json: decoder pool                 │             ║
║  │  • net/http: response writer buffers           │             ║
║  │  • fmt: printer objects                        │             ║
║  │  • zap logger: encoder pool                    │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ GC TUNING:                                                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  GOGC (default 100):                           │             ║
║  │  → GC chạy khi heap tăng 100% so với live    │             ║
║  │  → GOGC=50: GC thường xuyên hơn, ít memory   │             ║
║  │  → GOGC=200: GC ít hơn, nhiều memory         │             ║
║  │  → GOGC=off: TẮT GC (cho benchmark)          │             ║
║  │                                                │             ║
║  │  GOMEMLIMIT (Go 1.19+):                       │             ║
║  │  → Giới hạn tổng memory usage                 │             ║
║  │  → GOMEMLIMIT=1GiB → GC cố giữ dưới 1GB    │             ║
║  │  → Container-friendly (cgroup limits)          │             ║
║  │  → Kết hợp: GOGC=off + GOMEMLIMIT=1GiB       │             ║
║  │    = "GC chỉ chạy khi gần hết memory"        │             ║
║  │                                                │             ║
║  │  // Debug GC:                                   │             ║
║  │  $ GODEBUG=gctrace=1 ./app                     │             ║
║  │  → gc 1 @0.012s 2%: 0.018+1.2+0.009 ms       │             ║
║  │  → Hiện: STW time, heap size, % CPU for GC   │             ║
║  │                                                │             ║
║  │  // Profiling memory:                           │             ║
║  │  $ go tool pprof -alloc_space app mem.prof     │             ║
║  │  $ go tool pprof -inuse_space app mem.prof     │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §3. RAM — Bộ Nhớ Chính

### 3.1 RAM hoạt động ra sao?

```
╔═══════════════════════════════════════════════════════════════╗
║   RAM — RANDOM ACCESS MEMORY                                 ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  RAM = Bộ nhớ CHÍNH của máy tính.                            ║
║                                                               ║
║  Đặc điểm:                                                   ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • VOLATILE (bay hơi): Tắt điện = MẤT HẾT! │             ║
║  │  • RANDOM ACCESS: Truy cập bất kỳ vị trí    │             ║
║  │    nào với CÙNG tốc độ (~100ns)              │             ║
║  │  • Dung lượng: 8GB - 128GB (phổ biến)       │             ║
║  │  • Tổ chức: Mảng KHỔNG LỒ các bytes         │             ║
║  │    Mỗi byte có 1 ĐỊA CHỈ duy nhất          │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  TẠI SAO gọi là "Random Access"?                             ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  → Vì đọc byte ở vị trí 0 hay vị trí       │             ║
║  │    1,000,000 đều MẤT CÙNG THỜI GIAN!       │             ║
║  │  → Khác với HDD: đọc ở xa phải DI CHUYỂN   │             ║
║  │    đầu đọc (seek time)                        │             ║
║  │  → Khác với Tape: phải TUA đến vị trí cần  │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  RAM như một bảng khổng lồ:                                   ║
║  ┌──────────┬──────────────────────┐                         ║
║  │ Địa chỉ  │ Giá trị (1 byte)     │                         ║
║  ├──────────┼──────────────────────┤                         ║
║  │ 0x0000   │ 01001101             │                         ║
║  │ 0x0001   │ 11010010             │                         ║
║  │ 0x0002   │ 00000000             │                         ║
║  │ ...      │ ...                  │                         ║
║  │ 0xFFFF   │ 10101010             │                         ║
║  └──────────┴──────────────────────┘                         ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.2 Stack vs Heap — Hai vùng nhớ quan trọng nhất

Khi chương trình chạy, hệ điều hành chia RAM thành nhiều vùng khác nhau. Hai vùng quan trọng nhất mà mọi backend engineer PHẢI hiểu là **Stack** và **Heap**.

```
╔═══════════════════════════════════════════════════════════════╗
║   STACK vs HEAP — HAI VÙNG NHỚ QUAN TRỌNG NHẤT              ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Khi chương trình chạy, RAM được chia:                       ║
║                                                               ║
║  ┌─────────────────────────────────────┐  ← Địa chỉ CAO    ║
║  │            STACK                     │                     ║
║  │  (Tăng trưởng XUỐNG ↓)              │                     ║
║  │  ┌─────────────────────┐            │                     ║
║  │  │ main() frame        │            │                     ║
║  │  │ ├── x = 42          │            │                     ║
║  │  │ └── y = 100         │            │                     ║
║  │  ├─────────────────────┤            │                     ║
║  │  │ doWork() frame      │            │                     ║
║  │  │ ├── a = 10          │            │                     ║
║  │  │ └── b = 20          │            │                     ║
║  │  └─────────────────────┘            │                     ║
║  │         ↓ (grows down)               │                     ║
║  │                                      │                     ║
║  │         ↑ (grows up)                 │                     ║
║  │  ┌──────────────────────────┐       │                     ║
║  │  │       HEAP                │       │                     ║
║  │  │  (Tăng trưởng LÊN ↑)    │       │                     ║
║  │  │                          │       │                     ║
║  │  │  [Object A] [Object B]   │       │                     ║
║  │  │  [     Object C        ] │       │                     ║
║  │  │  [  D  ] [free] [ E ]    │       │                     ║
║  │  └──────────────────────────┘       │                     ║
║  │                                      │                     ║
║  │  ┌──────────────────────────┐       │                     ║
║  │  │  Data Segment             │       │                     ║
║  │  │  (global/static vars)     │       │                     ║
║  │  ├──────────────────────────┤       │                     ║
║  │  │  Code Segment (Text)      │       │                     ║
║  │  │  (machine instructions)   │       │                     ║
║  │  └──────────────────────────┘       │                     ║
║  └─────────────────────────────────────┘  ← Địa chỉ THẤP   ║
║                                                               ║
║  SO SÁNH STACK vs HEAP:                                       ║
║  ┌──────────┬───────────────────┬───────────────────┐        ║
║  │          │ STACK              │ HEAP               │        ║
║  ├──────────┼───────────────────┼───────────────────┤        ║
║  │ Tốc độ  │ CỰC NHANH         │ Chậm hơn          │        ║
║  │ Cấp phát│ Tự động (LIFO)    │ Thủ công/GC       │        ║
║  │ Kích    │ Nhỏ (2KB-8MB)    │ Lớn (GBs)         │        ║
║  │ thước   │                   │                    │        ║
║  │ Quản lý │ Compiler/OS       │ Developer/GC       │        ║
║  │ Lưu gì  │ Local vars,       │ Dynamic data,      │        ║
║  │         │ params, returns   │ shared data        │        ║
║  │ Lifetime│ Function scope    │ Đến khi free/GC   │        ║
║  │ Thread  │ Mỗi thread RIÊNG │ Chia sẻ giữa      │        ║
║  │ safety  │                   │ các threads        │        ║
║  └──────────┴───────────────────┴───────────────────┘        ║
║                                                               ║
║  TẠI SAO Stack nhanh hơn Heap?                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Stack: Chỉ cần di chuyển STACK POINTER!     │             ║
║  │  → Push: SP -= size (1 instruction!)         │             ║
║  │  → Pop: SP += size (1 instruction!)          │             ║
║  │  → KHÔNG cần tìm kiếm vùng trống!           │             ║
║  │                                                │             ║
║  │  Heap: Phải TÌM vùng trống đủ lớn!           │             ║
║  │  → malloc(): scan free list                   │             ║
║  │  → Có thể bị FRAGMENTATION (bộ nhớ lỗ chỗ) │             ║
║  │  → Cần GC (Garbage Collector) để dọn dẹp    │             ║
║  │  → GC = thêm overhead (Stop-The-World)       │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  TRONG GO:                                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  → Compiler QUYẾT ĐỊNH biến ở Stack hay Heap│             ║
║  │  → Qua ESCAPE ANALYSIS!                      │             ║
║  │  → Nếu biến "escape" ra khỏi function       │             ║
║  │    → Heap (VD: return &x)                    │             ║
║  │  → Nếu biến chỉ dùng trong function          │             ║
║  │    → Stack (nhanh hơn!)                       │             ║
║  │  → go build -gcflags="-m" → xem kết quả     │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.3 Memory Alignment & Padding

```
╔═══════════════════════════════════════════════════════════════╗
║   MEMORY ALIGNMENT — TẠI SAO CẦN?                           ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  CPU đọc memory theo KHỐI (thường 4 hoặc 8 bytes).          ║
║  Nếu data KHÔNG nằm đúng ranh giới → chậm hơn!             ║
║                                                               ║
║  VÍ DỤ — Struct trong Go:                                    ║
║                                                               ║
║  ❌ Thứ tự TỆ (wasted 5 bytes padding):                     ║
║  type Bad struct {                                            ║
║      a bool   // 1 byte                                      ║
║      b int64  // 8 bytes                                      ║
║      c bool   // 1 byte                                      ║
║  }                                                            ║
║  Memory layout:                                               ║
║  ┌─┬───────┬────────┬─┬───────┐                              ║
║  │a│padding│   b    │c│padding│ = 24 bytes!                  ║
║  │1│  7    │   8    │1│  7    │                               ║
║  └─┴───────┴────────┴─┴───────┘                              ║
║                                                               ║
║  ✅ Thứ tự TỐT (chỉ 0 bytes wasted):                        ║
║  type Good struct {                                           ║
║      b int64  // 8 bytes                                      ║
║      a bool   // 1 byte                                       ║
║      c bool   // 1 byte                                       ║
║  }                                                            ║
║  Memory layout:                                               ║
║  ┌────────┬─┬─┬──────┐                                       ║
║  │   b    │a│c│  pad │ = 16 bytes!                           ║
║  │   8    │1│1│  6   │                                        ║
║  └────────┴─┴─┴──────┘                                       ║
║                                                               ║
║  → Tiết kiệm 8 bytes/struct!                                ║
║  → 1 triệu objects = 8MB tiết kiệm!                        ║
║  → Nhiều data fit trong cache line hơn!                      ║
║                                                               ║
║  QUY TẮC: Sắp xếp field từ LỚN → NHỎ!                     ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.4 DRAM — Bên Trong Chip RAM

DRAM (Dynamic RAM) lưu mỗi bit bằng **1 capacitor + 1 transistor**. Capacitor xả điện dần → phải **refresh** liên tục (mỗi 64ms). Đây là lý do gọi là "Dynamic" — và cũng là lý do RAM chậm hơn SRAM (cache).

```
╔═══════════════════════════════════════════════════════════════╗
║   DRAM — DYNAMIC RANDOM ACCESS MEMORY                        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  CẤU TRÚC 1 BIT DRAM:                                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Word Line (hàng)                              │             ║
║  │  ────────┬────────                             │             ║
║  │          │ Gate                                 │             ║
║  │     ┌────┴────┐                                │             ║
║  │     │Transistor│                               │             ║
║  │     └────┬────┘                                │             ║
║  │          │                                     │             ║
║  │     ┌────┴────┐                                │             ║
║  │     │Capacitor│ ← Lưu 1 bit (charge/no charge)│             ║
║  │     │  ≈10fF  │                                │             ║
║  │     └─────────┘                                │             ║
║  │          │                                     │             ║
║  │  ────────┴────────                             │             ║
║  │  Bit Line (cột)                                │             ║
║  │                                                │             ║
║  │  SRAM (cache) vs DRAM:                         │             ║
║  │  ┌──────────┬─────────────┬──────────────┐     │             ║
║  │  │          │ SRAM         │ DRAM          │     │             ║
║  │  ├──────────┼─────────────┼──────────────┤     │             ║
║  │  │Transistors│ 6 per bit   │ 1 per bit     │     │             ║
║  │  │ per bit  │             │               │     │             ║
║  │  │Speed     │ ~1-2ns       │ ~50-100ns     │     │             ║
║  │  │Refresh   │ KHÔNG cần   │ Mỗi 64ms     │     │             ║
║  │  │Cost/bit  │ Đắt (10x)  │ Rẻ           │     │             ║
║  │  │Dùng cho │ L1/L2/L3    │ Main memory   │     │             ║
║  │  └──────────┴─────────────┴──────────────┘     │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CẤU TRÚC CHIP DRAM:                                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  DRAM Chip = Ma trận 2D (rows × columns):    │             ║
║  │                                                │             ║
║  │       Col 0  Col 1  Col 2  ...  Col N         │             ║
║  │  Row 0  [C]    [C]    [C]   ...  [C]          │             ║
║  │  Row 1  [C]    [C]    [C]   ...  [C]          │             ║
║  │  Row 2  [C]    [C]    [C]   ...  [C]          │             ║
║  │  ...                                           │             ║
║  │  Row M  [C]    [C]    [C]   ...  [C]          │             ║
║  │                                                │             ║
║  │  Đọc 1 byte:                                  │             ║
║  │  ① RAS (Row Address Strobe): chọn row         │             ║
║  │  ② Cả row được copy vào Row Buffer            │             ║
║  │  ③ CAS (Column Address Strobe): chọn column   │             ║
║  │  ④ Data output                                 │             ║
║  │                                                │             ║
║  │  ⚡ ROW BUFFER HIT:                           │             ║
║  │  → Nếu row đã trong buffer → CỰC NHANH!    │             ║
║  │  → Chỉ cần CAS (~15ns)                       │             ║
║  │  → Sequential access = row buffer hits!       │             ║
║  │                                                │             ║
║  │  💀 ROW BUFFER MISS:                           │             ║
║  │  → Phải load row mới → RAS + CAS (~50ns)     │             ║
║  │  → Random access = row buffer misses!          │             ║
║  │  → Lý do sequential nhanh hơn random!        │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  BANK INTERLEAVING:                                           ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1 DIMM chứa nhiều BANKS (thường 8-16):      │             ║
║  │                                                │             ║
║  │  ┌──────┐ ┌──────┐ ┌──────┐ ┌──────┐         │             ║
║  │  │Bank 0│ │Bank 1│ │Bank 2│ │Bank 3│         │             ║
║  │  │[████]│ │[    ]│ │[    ]│ │[    ]│         │             ║
║  │  │active│ │idle  │ │idle  │ │idle  │         │             ║
║  │  └──────┘ └──────┘ └──────┘ └──────┘         │             ║
║  │                                                │             ║
║  │  → Trong khi Bank 0 đang xử lý RAS...       │             ║
║  │  → Bank 1 có thể bắt đầu ngay!             │             ║
║  │  → Pipeline giữa các banks = tăng throughput! │             ║
║  │  → Giống CPU pipelining nhưng ở RAM level     │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ REFRESH VÀ PERFORMANCE:                                   ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Mỗi 64ms, TẤT CẢ rows phải refresh!        │             ║
║  │  → 8K rows × 64ms = 1 row mỗi ~7.8μs        │             ║
║  │  → Trong lúc refresh: bank KHÔNG truy cập    │             ║
║  │    được! (blocked)                             │             ║
║  │  → Refresh overhead: ~5-10% bandwidth loss    │             ║
║  │                                                │             ║
║  │  Với DDR5:                                     │             ║
║  │  → Same-bank refresh: chỉ block 1 bank        │             ║
║  │  → Các banks khác vẫn hoạt động             │             ║
║  │  → Giảm refresh overhead đáng kể             │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.5 DDR Generations — Từ DDR3 đến DDR5

Mỗi thế hệ DDR tăng gấp đôi bandwidth bằng cách tăng **prefetch** và **clock rate**. Hiểu điều này giúp bạn tính toán memory bandwidth cho capacity planning của database/cache servers.

```
╔═══════════════════════════════════════════════════════════════╗
║   DDR GENERATIONS                                             ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  SO SÁNH CÁC THẾ HỆ:                                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌──────┬────────┬──────────┬────────┬──────┐ │             ║
║  │  │      │Clock   │Bandwidth │Voltage │Prefetch│             ║
║  │  │      │(MT/s)  │(GB/s)    │        │       │ │             ║
║  │  ├──────┼────────┼──────────┼────────┼──────┤ │             ║
║  │  │DDR3  │800-2133│6.4-17    │1.5V    │8n    │ │             ║
║  │  │DDR4  │2133-   │17-25.6   │1.2V    │8n    │ │             ║
║  │  │      │3200    │          │        │      │ │             ║
║  │  │DDR5  │4800-   │38.4-     │1.1V    │16n   │ │             ║
║  │  │      │8400    │67.2      │        │      │ │             ║
║  │  └──────┴────────┴──────────┴────────┴──────┘ │             ║
║  │                                                │             ║
║  │  BANDWIDTH CALCULATION:                        │             ║
║  │  BW = Clock(MT/s) × 8 bytes (bus width)       │             ║
║  │  VD: DDR4-3200 = 3200 × 8 = 25,600 MB/s      │             ║
║  │      = 25.6 GB/s PER CHANNEL                   │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  DDR5 CẢI TIẾN QUAN TRỌNG:                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. 2 Sub-channels per DIMM:                   │             ║
║  │     DDR4: 1 channel × 64-bit                   │             ║
║  │     DDR5: 2 channels × 32-bit                  │             ║
║  │     → Cùng bandwidth, nhưng latency tốt hơn  │             ║
║  │     → Interleave giữa 2 sub-channels          │             ║
║  │                                                │             ║
║  │  2. On-die ECC:                                │             ║
║  │     → ECC tích hợp trong chip (không phải    │             ║
║  │       ECC DIMM)                                │             ║
║  │     → Sửa lỗi single-bit trong chip          │             ║
║  │                                                │             ║
║  │  3. Same-bank refresh:                         │             ║
║  │     → Refresh 1 bank, các bank khác vẫn chạy │             ║
║  │     → Giảm refresh penalty                    │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ CHỌN RAM CHO SERVER:                                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Database server (PostgreSQL, MySQL):           │             ║
║  │  → Nhiều RAM = lớn buffer pool = ít disk I/O │             ║
║  │  → ECC bắt buộc! (data integrity)            │             ║
║  │  → Đủ channels để không bottleneck           │             ║
║  │                                                │             ║
║  │  Cache server (Redis, Memcached):              │             ║
║  │  → RAM = entire dataset → cần nhiều nhất!    │             ║
║  │  → Bandwidth quan trọng cho scan operations   │             ║
║  │                                                │             ║
║  │  Application server (Go, Node.js):             │             ║
║  │  → Ít RAM hơn (chỉ cần cho heap + stack)     │             ║
║  │  → 4-16GB thường đủ                          │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.6 ECC RAM — Khi 1 Bit Sai Có Thể Phá Hủy Database

Cosmic rays, điện từ trường, và aging silicon có thể làm **flip** 1 bit trong RAM. Không có ECC, database của bạn có thể **corrupt data** mà không ai biết. Đây là lý do tại sao mọi production server đều cần ECC.

```
╔═══════════════════════════════════════════════════════════════╗
║   ECC RAM — ERROR-CORRECTING CODE                            ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  VẤN ĐỀ: BIT FLIP                                           ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Trước: 01001101 (giá trị 77)                 │             ║
║  │  Sau:   01001111 (giá trị 79) ← bit 1 flipped│             ║
║  │                                                │             ║
║  │  Nguyên nhân:                                  │             ║
║  │  • Cosmic rays (tia vũ trụ)                   │             ║
║  │  • Alpha particles từ chip packaging          │             ║
║  │  • Điện từ interference                       │             ║
║  │  • Silicon aging                               │             ║
║  │                                                │             ║
║  │  Tần suất: ~1 bit flip / GB / 6-12 giờ       │             ║
║  │  Server 128GB → ~10-20 bit flips/ngày!        │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ECC CƠ CHẾ:                                                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Non-ECC: 64 data bits                         │             ║
║  │  ┌────────────────────────────────────────┐    │             ║
║  │  │ 64 bits data                            │    │             ║
║  │  └────────────────────────────────────────┘    │             ║
║  │                                                │             ║
║  │  ECC: 64 data bits + 8 ECC bits = 72 bits     │             ║
║  │  ┌────────────────────────────────────┬──────┐ │             ║
║  │  │ 64 bits data                       │8 ECC │ │             ║
║  │  └────────────────────────────────────┴──────┘ │             ║
║  │                                                │             ║
║  │  Khả năng:                                    │             ║
║  │  • SECDED: Single Error Correct, Double       │             ║
║  │    Error Detect                                │             ║
║  │  • Sửa lỗi 1-bit tự động (transparent)      │             ║
║  │  • Phát hiện lỗi 2-bit → halt/log            │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ TẠI SAO BACKEND CẦN ECC:                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Database:                                  │             ║
║  │     → Bit flip trong B-Tree index              │             ║
║  │     → Con trỏ sai → đọc wrong data!          │             ║
║  │     → Hoặc crash toàn database!               │             ║
║  │                                                │             ║
║  │  2. Redis:                                     │             ║
║  │     → Tất cả data trong RAM                   │             ║
║  │     → 1 bit flip = corrupted value            │             ║
║  │     → Không có cách detect nếu không ECC!    │             ║
║  │                                                │             ║
║  │  3. ZFS/Btrfs:                                 │             ║
║  │     → Checksums TRONG filesystem               │             ║
║  │     → Nhưng RAM corruption trước khi write    │             ║
║  │     → = corrupted checksum! (worse!)           │             ║
║  │                                                │             ║
║  │  ☞ Linus Torvalds: "ECC should be default     │             ║
║  │     for ALL systems."                          │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.7 Memory Channels & Bandwidth — Khi RAM Thành Bottleneck

Dù RAM nhanh, nhưng nếu server chỉ có **1 memory channel**, tất cả CPU cores đều phải xếp hàng chờ. Đây là bottleneck phổ biến trên cloud instances rẻ.

```
╔═══════════════════════════════════════════════════════════════╗
║   MEMORY CHANNELS & BANDWIDTH                                ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  SINGLE vs DUAL vs QUAD CHANNEL:                             ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Single Channel:                               │             ║
║  │  ┌─────┐     ┌──────┐                         │             ║
║  │  │ CPU │═════│ DIMM │  = 25.6 GB/s            │             ║
║  │  └─────┘     └──────┘                         │             ║
║  │                                                │             ║
║  │  Dual Channel:                                 │             ║
║  │  ┌─────┐     ┌──────┐                         │             ║
║  │  │ CPU │═══╦═│DIMM 0│  = 51.2 GB/s (2x!)     │             ║
║  │  └─────┘   ╚═│DIMM 1│                         │             ║
║  │              └──────┘                         │             ║
║  │                                                │             ║
║  │  Quad Channel (server):                        │             ║
║  │  ┌─────┐     ┌──────┐                         │             ║
║  │  │ CPU │═╦═══│DIMM 0│                         │             ║
║  │  └─────┘ ╠═══│DIMM 1│  = 102.4 GB/s (4x!)    │             ║
║  │          ╠═══│DIMM 2│                         │             ║
║  │          ╚═══│DIMM 3│                         │             ║
║  │              └──────┘                         │             ║
║  │                                                │             ║
║  │  Hexa/Octa Channel (high-end server):          │             ║
║  │  → 6-8 channels = 150-200 GB/s               │             ║
║  │  → AMD EPYC: 8 channels                       │             ║
║  │  → Intel Xeon Sapphire Rapids: 8 channels     │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ BANDWIDTH BOTTLENECK CALCULATION:                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Scenario: PostgreSQL full table scan          │             ║
║  │  • Table: 10GB, 100M rows                      │             ║
║  │  • Sequential scan → bandwidth-bound          │             ║
║  │                                                │             ║
║  │  Single channel DDR4-3200: 25.6 GB/s           │             ║
║  │  → 10GB / 25.6 = 0.39 giây                   │             ║
║  │                                                │             ║
║  │  Dual channel: 51.2 GB/s                       │             ║
║  │  → 10GB / 51.2 = 0.20 giây                   │             ║
║  │                                                │             ║
║  │  Nhưng! CPU cũng phải xử lý từng row:        │             ║
║  │  → Thực tế thường CPU-bound trước khi        │             ║
║  │    hết bandwidth                               │             ║
║  │  → NGOẠI TRỪ: SIMD scanning, columnar data   │             ║
║  │                                                │             ║
║  │  Khi nào bandwidth thực sự bottleneck:         │             ║
║  │  • Large memcpy operations                     │             ║
║  │  • Redis KEYS/SCAN trên dataset lớn           │             ║
║  │  • Analytics queries (columnar scan)           │             ║
║  │  • Machine learning inference                  │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ CLOUD INSTANCES & MEMORY:                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ⚠️ Cloud VMs CHIA SẺ memory bandwidth!      │             ║
║  │                                                │             ║
║  │  ┌────────────┬──────────┬──────────────┐      │             ║
║  │  │ Instance   │ BW (GB/s)│ Use case      │      │             ║
║  │  ├────────────┼──────────┼──────────────┤      │             ║
║  │  │ t3.micro   │ ~3-5     │ Dev/test      │      │             ║
║  │  │ m5.xlarge  │ ~15-20   │ App server    │      │             ║
║  │  │ r5.2xlarge │ ~25-30   │ Database      │      │             ║
║  │  │ x1.16xlarge│ ~80-100  │ In-memory DB  │      │             ║
║  │  └────────────┴──────────┴──────────────┘      │             ║
║  │                                                │             ║
║  │  → t3.micro cho DB = DISASTER (shared BW!)    │             ║
║  │  → r-series (memory optimized) cho databases  │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.8 Process Memory Layout — Bản Đồ Bộ Nhớ Một Process

Khi OS load 1 chương trình, nó tạo virtual address space riêng với nhiều **segments** rõ ràng. Hiểu layout này giúp bạn debug memory issues, hiểu segfault, và tối ưu Go applications.

```
╔═══════════════════════════════════════════════════════════════╗
║   PROCESS MEMORY LAYOUT (Linux x86-64)                       ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  ┌───────────────────────────────────┐ 0xFFFFFFFFFFFF (128TB)║
║  │         KERNEL SPACE              │                        ║
║  │ (user không truy cập được!)      │                        ║
║  ├───────────────────────────────────┤ 0x7FFFFFFFFFFF        ║
║  │                                   │                        ║
║  │  ┌─────────────────────────────┐  │                        ║
║  │  │          STACK              │  │                        ║
║  │  │   ↓ grows downward ↓       │  │                        ║
║  │  │   • Local variables         │  │                        ║
║  │  │   • Function parameters     │  │                        ║
║  │  │   • Return addresses        │  │                        ║
║  │  │   • Saved registers         │  │                        ║
║  │  │   Default limit: 8MB        │  │                        ║
║  │  └─────────────────────────────┘  │                        ║
║  │  ┌─────────┐                      │                        ║
║  │  │ Guard   │ ← SIGSEGV nếu chạm│                        ║
║  │  │ Page    │   (stack overflow)   │                        ║
║  │  └─────────┘                      │                        ║
║  │           ...FREE SPACE...        │                        ║
║  │                                   │                        ║
║  │  ┌─────────────────────────────┐  │                        ║
║  │  │   Memory-mapped files       │  │                        ║
║  │  │   • Shared libraries (.so)  │  │                        ║
║  │  │   • mmap() allocations      │  │                        ║
║  │  │   • Anonymous mappings      │  │                        ║
║  │  └─────────────────────────────┘  │                        ║
║  │                                   │                        ║
║  │  ┌─────────────────────────────┐  │                        ║
║  │  │          HEAP               │  │                        ║
║  │  │   ↑ grows upward ↑         │  │                        ║
║  │  │   • malloc/new/make         │  │                        ║
║  │  │   • Dynamic allocations     │  │                        ║
║  │  │   • Managed by allocator    │  │                        ║
║  │  └─────────────────────────────┘  │                        ║
║  │                                   │                        ║
║  │  ┌─────────────────────────────┐  │                        ║
║  │  │  BSS Segment               │  │                        ║
║  │  │  (uninitialized globals)    │  │                        ║
║  │  │  var x int // zero-valued   │  │                        ║
║  │  ├─────────────────────────────┤  │                        ║
║  │  │  Data Segment               │  │                        ║
║  │  │  (initialized globals)      │  │                        ║
║  │  │  var y = 42                 │  │                        ║
║  │  ├─────────────────────────────┤  │                        ║
║  │  │  Text Segment (code)        │  │                        ║
║  │  │  Read-only + Execute        │  │                        ║
║  │  │  Machine instructions       │  │                        ║
║  │  └─────────────────────────────┘  │                        ║
║  └───────────────────────────────────┘ 0x000000400000         ║
║                                                               ║
║  KIỂM TRA TRÊN LINUX:                                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  $ cat /proc/<pid>/maps                        │             ║
║  │  00400000-0048a000 r-xp ... /app (text)        │             ║
║  │  0048a000-004b2000 rw-p ... /app (data)        │             ║
║  │  01234000-01345000 rw-p ... [heap]             │             ║
║  │  7f1234000000-... r-xp ... libc.so             │             ║
║  │  7ffd12340000-... rw-p ... [stack]             │             ║
║  │                                                │             ║
║  │  $ cat /proc/<pid>/status                      │             ║
║  │  VmSize:  1234 kB  (total virtual)             │             ║
║  │  VmRSS:    567 kB  (physical RAM used)         │             ║
║  │  VmStk:     12 kB  (stack size)                │             ║
║  │  VmData:   890 kB  (heap + data)               │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.9 Goroutine Stacks — Tại Sao Go Tạo Triệu Goroutines Được?

Go goroutines bắt đầu với stack chỉ **2KB** (so với thread stack 1-8MB). Stack tự động **grow** khi cần và **shrink** khi GC. Đây là cơ chế cho phép Go chạy hàng triệu goroutines trên máy với vài GB RAM.

```
╔═══════════════════════════════════════════════════════════════╗
║   GOROUTINE STACKS — CONTIGUOUS STACK MODEL                  ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  OS THREAD vs GOROUTINE STACK:                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  OS Thread (C/Java/Rust):                      │             ║
║  │  ┌─────────────────────────────┐               │             ║
║  │  │          1-8 MB             │ ← Fixed!      │             ║
║  │  │   (allocated at creation)   │               │             ║
║  │  │   Phần lớn LÃNG PHÍ!      │               │             ║
║  │  └─────────────────────────────┘               │             ║
║  │  → 1000 threads × 8MB = 8GB stack alone!      │             ║
║  │                                                │             ║
║  │  Goroutine:                                    │             ║
║  │  ┌──┐ ← Start: 2KB!                           │             ║
║  │  │2K│                                          │             ║
║  │  └──┘                                          │             ║
║  │  → 1,000,000 goroutines × 2KB = 2GB          │             ║
║  │  → Thực tế ít hơn vì nhiều goroutines idle   │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  STACK GROWTH MECHANISM:                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ① Compiler chèn STACK CHECK ở đầu function: │             ║
║  │                                                │             ║
║  │  func doWork() {                               │             ║
║  │      // COMPILER INSERTS:                      │             ║
║  │      // if SP < stackguard → morestack()      │             ║
║  │      ...                                       │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  ② Nếu stack hết: GROW!                       │             ║
║  │                                                │             ║
║  │  OLD stack (2KB):     NEW stack (4KB):         │             ║
║  │  ┌──────────┐         ┌──────────────────┐     │             ║
║  │  │ frame A  │  COPY   │ frame A (copied) │     │             ║
║  │  │ frame B  │ ──────► │ frame B (copied) │     │             ║
║  │  │ ██FULL██ │         │ (free space)     │     │             ║
║  │  └──────────┘         │                  │     │             ║
║  │  (freed!)             └──────────────────┘     │             ║
║  │                                                │             ║
║  │  ③ Stack sizes: 2KB → 4KB → 8KB → ... → 1GB │             ║
║  │     Luôn NHÂN ĐÔI khi grow!                  │             ║
║  │                                                │             ║
║  │  ④ Pointer adjustment:                         │             ║
║  │     Khi copy, TẤT CẢ pointers trỏ vào       │             ║
║  │     stack cũ phải được UPDATE sang stack mới! │             ║
║  │     → Lý do Go không cho phép pointer         │             ║
║  │       arithmetic!                               │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  STACK SHRINK (khi GC chạy):                                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Nếu stack dùng < 1/4 capacity:              │             ║
║  │  → GC thu nhỏ stack xuống 1/2                 │             ║
║  │  → Trả memory lại cho OS                      │             ║
║  │                                                │             ║
║  │  VD: goroutine xử lý HTTP request:           │             ║
║  │  1. Bắt đầu: 2KB                             │             ║
║  │  2. Parse request: grow → 8KB                 │             ║
║  │  3. Query DB: grow → 16KB                     │             ║
║  │  4. Response done, waiting → GC shrink → 4KB│             ║
║  │  5. Next request: grow lại nếu cần           │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ⚠️ STACK OVERFLOW TRONG GO:                                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Go stack có thể grow đến 1GB (default)!     │             ║
║  │  → runtime: goroutine stack exceeds 1GB       │             ║
║  │  → Thường do infinite recursion!              │             ║
║  │                                                │             ║
║  │  // Thay đổi limit:                           │             ║
║  │  debug.SetMaxStack(2 * 1024 * 1024 * 1024)    │             ║
║  │  // 2GB max stack                              │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.10 Heap Fragmentation — Khi RAM Có Nhưng Không Dùng Được

Heap fragmentation xảy ra khi có **đủ tổng RAM** nhưng không có khối liên tục đủ lớn để cấp phát. Giống như bãi đỗ xe có 10 chỗ trống nhưng tất cả rải rác — xe tải cần 3 chỗ liền KHÔNG đỗ được.

```
╔═══════════════════════════════════════════════════════════════╗
║   HEAP FRAGMENTATION                                         ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  2 LOẠI FRAGMENTATION:                                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ① EXTERNAL Fragmentation:                    │             ║
║  │  ┌──┬────┬──┬────┬──┬────┬──┬────┐            │             ║
║  │  │A │free│B │free│C │free│D │free│            │             ║
║  │  │4K│ 2K │4K│ 2K │4K│ 2K │4K│ 2K │            │             ║
║  │  └──┴────┴──┴────┴──┴────┴──┴────┘            │             ║
║  │  Total free: 8KB                               │             ║
║  │  Nhưng cần allocate 5KB → KHÔNG THỂ!         │             ║
║  │  (không có khối 5KB liên tiếp)                │             ║
║  │                                                │             ║
║  │  ② INTERNAL Fragmentation:                    │             ║
║  │  Cần 33 bytes → allocator cho size class 48B  │             ║
║  │  ┌──────────────────────────────┐              │             ║
║  │  │ 33 bytes used │ 15 bytes wasted│              │             ║
║  │  └──────────────────────────────┘              │             ║
║  │  → 31% wasted per object!                     │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  GO CHỐNG FRAGMENTATION:                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Size classes (68 classes):                 │             ║
║  │     → Objects cùng size = cùng span           │             ║
║  │     → Không bị external fragmentation         │             ║
║  │     → Trả giá: internal (max ~12%)            │             ║
║  │                                                │             ║
║  │  2. Span-based allocation:                     │             ║
║  │     ┌──────────────────────────────┐           │             ║
║  │     │ Span (8KB page, class=48B)   │           │             ║
║  │     │ [obj][obj][obj][obj][obj]...  │           │             ║
║  │     │ Tất cả 48 bytes, no external │           │             ║
║  │     │ fragmentation!               │           │             ║
║  │     └──────────────────────────────┘           │             ║
║  │                                                │             ║
║  │  3. GC compaction (KHÔNG CÓ trong Go!):       │             ║
║  │     → Go GC là NON-MOVING                     │             ║
║  │     → Objects KHÔNG di chuyển sau allocate    │             ║
║  │     → Đơn giản hơn nhưng fragmentation vẫn  │             ║
║  │       có thể xảy ra theo thời gian            │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ BACKEND IMPACTS:                                           ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. Long-running Go services:                  │             ║
║  │     → Heap grows over time (fragmentation)    │             ║
║  │     → RSS tăng dù live objects ít            │             ║
║  │     → debug.FreeOSMemory() ép trả memory    │             ║
║  │                                                │             ║
║  │  2. Redis:                                     │             ║
║  │     → jemalloc fragmentation ratio            │             ║
║  │     → INFO memory: mem_fragmentation_ratio    │             ║
║  │     → > 1.5 = VẤN ĐỀ!                       │             ║
║  │     → MEMORY PURGE để giảm                   │             ║
║  │                                                │             ║
║  │  3. Container OOM:                             │             ║
║  │     → RSS > cgroup limit → OOM killed!        │             ║
║  │     → DÙ Go live heap nhỏ hơn limit!        │             ║
║  │     → GOMEMLIMIT giải quyết vấn đề này      │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.11 Go Memory Profiling — Debug Memory Issues

Memory profiling là kỹ năng QUAN TRỌNG cho production. Khi service bị OOM, bạn cần biết CÁI GÌ đang chiếm memory và TẠI SAO nó tăng.

```
╔═══════════════════════════════════════════════════════════════╗
║   GO MEMORY PROFILING                                        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  runtime.MemStats — SNAPSHOT BỘ NHỚ:                        ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  var m runtime.MemStats                        │             ║
║  │  runtime.ReadMemStats(&m)                      │             ║
║  │                                                │             ║
║  │  ┌────────────────┬──────────────────────────┐ │             ║
║  │  │ Field          │ Ý nghĩa                  │ │             ║
║  │  ├────────────────┼──────────────────────────┤ │             ║
║  │  │ Alloc          │ Heap bytes đang dùng    │ │             ║
║  │  │ TotalAlloc     │ Tổng bytes ever alloc'd │ │             ║
║  │  │ Sys            │ Bytes lấy từ OS         │ │             ║
║  │  │ HeapAlloc      │ = Alloc (live objects)    │ │             ║
║  │  │ HeapSys        │ Heap bytes từ OS        │ │             ║
║  │  │ HeapIdle       │ Spans chưa dùng         │ │             ║
║  │  │ HeapInuse      │ Spans đang dùng         │ │             ║
║  │  │ HeapReleased   │ Đã trả lại OS          │ │             ║
║  │  │ StackInuse     │ Stack memory đang dùng  │ │             ║
║  │  │ NumGC          │ Số lần GC chạy          │ │             ║
║  │  │ GCCPUFraction  │ % CPU cho GC             │ │             ║
║  │  │ NumGoroutine   │ Goroutines đang sống    │ │             ║
║  │  └────────────────┴──────────────────────────┘ │             ║
║  │                                                │             ║
║  │  KEY METRICS TO MONITOR:                       │             ║
║  │  • HeapAlloc tăng liên tục → memory leak!    │             ║
║  │  • GCCPUFraction > 25% → quá nhiều GC       │             ║
║  │  • HeapSys >> HeapAlloc → fragmentation!      │             ║
║  │  • StackInuse lớn → quá nhiều goroutines     │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  pprof — PROFILING TOOL:                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // Thêm vào HTTP server:                     │             ║
║  │  import _ "net/http/pprof"                     │             ║
║  │  go http.ListenAndServe(":6060", nil)          │             ║
║  │                                                │             ║
║  │  // Xem heap profile:                          │             ║
║  │  $ go tool pprof http://localhost:6060/         │             ║
║  │    debug/pprof/heap                            │             ║
║  │                                                │             ║
║  │  // 4 loại memory profile:                     │             ║
║  │  -inuse_space  → bytes đang dùng (default)   │             ║
║  │  -inuse_objects→ objects đang sống            │             ║
║  │  -alloc_space  → total bytes ever allocated   │             ║
║  │  -alloc_objects→ total objects ever created    │             ║
║  │                                                │             ║
║  │  // Memory leak detection:                     │             ║
║  │  $ go tool pprof -base before.prof after.prof  │             ║
║  │  → So sánh 2 heap snapshots!                  │             ║
║  │  → Cái gì TĂNG = potential leak!              │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  BENCHMEM — ĐO ALLOCATION:                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  $ go test -bench=. -benchmem                  │             ║
║  │  BenchmarkA-8  1000000  150 ns/op  64 B/op    │             ║
║  │                                     1 allocs/op│             ║
║  │                                                │             ║
║  │  → 64 B/op: mỗi operation alloc 64 bytes     │             ║
║  │  → 1 allocs/op: 1 heap allocation              │             ║
║  │  → Mục tiêu: 0 allocs/op!                    │             ║
║  │                                                │             ║
║  │  // Trong benchmark code:                      │             ║
║  │  func BenchmarkX(b *testing.B) {               │             ║
║  │      b.ReportAllocs() // bật alloc tracking   │             ║
║  │      for i := 0; i < b.N; i++ {               │             ║
║  │          // code to benchmark                   │             ║
║  │      }                                         │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 3.12 Zero-Allocation Patterns — Viết Go Ít Tốn RAM

Mỗi heap allocation = thêm công cho GC = thêm latency. Senior Go engineers viết code **zero-allocation** cho hot paths. Đây là patterns production checklist.

```
╔═══════════════════════════════════════════════════════════════╗
║   ZERO-ALLOCATION PATTERNS IN GO                             ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  PATTERN 1: Pre-allocate slices/maps                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // ❌ Multiple allocations:                   │             ║
║  │  var results []string                          │             ║
║  │  for _, item := range items {                  │             ║
║  │      results = append(results, item.Name)      │             ║
║  │  }                                             │             ║
║  │  // append grows: 0→1→2→4→8→16→32...         │             ║
║  │  // = O(log n) allocations!                    │             ║
║  │                                                │             ║
║  │  // ✅ Single allocation:                      │             ║
║  │  results := make([]string, 0, len(items))      │             ║
║  │  for _, item := range items {                  │             ║
║  │      results = append(results, item.Name)      │             ║
║  │  }                                             │             ║
║  │  // 1 allocation, đúng size!                  │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  PATTERN 2: strings.Builder thay vì + concatenation          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // ❌ N allocations:                          │             ║
║  │  s := ""                                       │             ║
║  │  for _, part := range parts {                  │             ║
║  │      s += part // MỖI lần = new string!       │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  // ✅ 1-2 allocations:                        │             ║
║  │  var b strings.Builder                         │             ║
║  │  b.Grow(estimatedSize)   // pre-allocate       │             ║
║  │  for _, part := range parts {                  │             ║
║  │      b.WriteString(part) // no alloc!          │             ║
║  │  }                                             │             ║
║  │  result := b.String()                          │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  PATTERN 3: Tránh interface{} boxing                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // ❌ Boxing allocates:                       │             ║
║  │  func log(msg interface{}) { ... }             │             ║
║  │  log(42)   // box int → heap!                 │             ║
║  │  log("hi") // box string → heap!              │             ║
║  │                                                │             ║
║  │  // ✅ Generics (Go 1.18+) — no boxing:       │             ║
║  │  func log[T any](msg T) { ... }               │             ║
║  │  log(42)   // no allocation!                   │             ║
║  │  log("hi") // no allocation!                   │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  PATTERN 4: sync.Pool cho temporary objects                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // ❌ Allocate mỗi request:                  │             ║
║  │  func handleRequest(w http.ResponseWriter,     │             ║
║  │      r *http.Request) {                        │             ║
║  │      buf := make([]byte, 4096)  // alloc!     │             ║
║  │      // dùng buf...                            │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  // ✅ Reuse từ pool:                          │             ║
║  │  var bufPool = sync.Pool{                      │             ║
║  │      New: func() any {                         │             ║
║  │          b := make([]byte, 4096)               │             ║
║  │          return &b                             │             ║
║  │      },                                        │             ║
║  │  }                                             │             ║
║  │  func handleRequest(w http.ResponseWriter,     │             ║
║  │      r *http.Request) {                        │             ║
║  │      bp := bufPool.Get().(*[]byte)             │             ║
║  │      buf := *bp                                │             ║
║  │      defer bufPool.Put(bp)                     │             ║
║  │      // dùng buf...                            │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  PATTERN 5: Tránh closures capture variables                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // ❌ Closure captures → heap escape:        │             ║
║  │  func process(items []Item) {                  │             ║
║  │      for i, item := range items {              │             ║
║  │          go func() {                           │             ║
║  │              fmt.Println(item) // captures     │             ║
║  │          }()    // item escapes to heap!       │             ║
║  │      }                                         │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  // ✅ Pass as parameter:                      │             ║
║  │  func process(items []Item) {                  │             ║
║  │      for i, item := range items {              │             ║
║  │          go func(it Item) {                    │             ║
║  │              fmt.Println(it) // stack copy!    │             ║
║  │          }(item)                               │             ║
║  │      }                                         │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CHECKLIST CHO HOT PATH:                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  □ go build -gcflags="-m" → kiểm tra escape  │             ║
║  │  □ go test -bench=. -benchmem → 0 allocs/op  │             ║
║  │  □ Pre-allocate slices/maps với size hint     │             ║
║  │  □ sync.Pool cho temporary large objects      │             ║
║  │  □ strings.Builder thay vì string + concat    │             ║
║  │  □ Generics thay vì interface{} khi có thể   │             ║
║  │  □ Pass by value cho small structs (≤ 64B)   │             ║
║  │  □ Tránh fmt.Sprintf trên hot path           │             ║
║  │    (dùng strconv.Append* thay thế)            │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §4. Disk & Storage — Lưu Trữ Vĩnh Viễn

### 4.1 HDD vs SSD — Hai thế giới khác biệt

```
╔═══════════════════════════════════════════════════════════════╗
║   HDD vs SSD — HIỂU ĐỂ THIẾT KẾ HỆ THỐNG                   ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  HDD (Hard Disk Drive) — CƠ HỌC:                            ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Cấu tạo: Đĩa kim loại QUAY + đầu đọc     │             ║
║  │                                                │             ║
║  │       ┌─────────────────┐                     │             ║
║  │       │    ╭─────╮      │ ← Đĩa quay        │             ║
║  │       │   ╭┤     ├╮     │   5400-7200 RPM    │             ║
║  │       │   │╰─────╯│     │                     │             ║
║  │       │   ╰───┬───╯     │                     │             ║
║  │       │  ═════╪══       │ ← Đầu đọc          │             ║
║  │       └───────┼─────────┘                     │             ║
║  │               │                                │             ║
║  │  Để đọc data:                                  │             ║
║  │  1. Seek: Di chuyển đầu đọc (~5-10ms)        │             ║
║  │  2. Rotate: Chờ đĩa quay đúng vị trí (~4ms) │             ║
║  │  3. Transfer: Đọc data (~0.05ms/sector)       │             ║
║  │  → Total: ~10ms cho RANDOM read!              │             ║
║  │  → Sequential read: nhanh hơn nhiều (no seek)│             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  SSD (Solid State Drive) — ĐIỆN TỬ:                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Cấu tạo: Flash memory chips (NO moving parts)│            ║
║  │                                                │             ║
║  │  ┌─────┬─────┬─────┬─────┐                   │             ║
║  │  │Cell │Cell │Cell │Cell │ ← NAND Flash      │             ║
║  │  │     │     │     │     │   cells            │             ║
║  │  ├─────┼─────┼─────┼─────┤                   │             ║
║  │  │Cell │Cell │Cell │Cell │                    │             ║
║  │  └─────┴─────┴─────┴─────┘                   │             ║
║  │                                                │             ║
║  │  Random read: ~0.1ms (nhanh gấp 100x HDD!)  │             ║
║  │  Không có seek/rotate → tốc độ ỔN ĐỊNH      │             ║
║  │  NHƯNG: write phức tạp hơn (wear leveling)  │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  SO SÁNH:                                                     ║
║  ┌──────────┬──────────────┬──────────────┐                  ║
║  │          │ HDD           │ SSD           │                  ║
║  ├──────────┼──────────────┼──────────────┤                  ║
║  │ Random   │ ~10ms         │ ~0.1ms        │                  ║
║  │ Seq Read │ ~100MB/s      │ ~3500MB/s     │                  ║
║  │ Giá      │ Rẻ ($20/TB)  │ Đắt ($80/TB) │                  ║
║  │ Tuổi thọ│ Cơ học hỏng  │ Write limit   │                  ║
║  │ Nhiệt   │ Ít            │ Nhiều hơn     │                  ║
║  └──────────┴──────────────┴──────────────┘                  ║
║                                                               ║
║  ⚠️ Backend Engineer cần biết:                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Database trên SSD: random read OK         │             ║
║  │  • Database trên HDD: PHẢI optimize cho      │             ║
║  │    sequential I/O (LSM-Tree, Write-Ahead Log)│             ║
║  │  • Kafka nhanh trên HDD nhờ SEQUENTIAL write │             ║
║  │  • PostgreSQL B-Tree index: random read heavy│             ║
║  │    → SSD giúp NHIỀU!                         │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 4.2 Sequential vs Random Access — Bài học then chốt

Đây là một trong những kiến thức **quan trọng nhất** cho backend engineer khi thiết kế hệ thống. Gần như MỌI quyết định về storage đều xoay quanh sự khác biệt này.

```
    Sequential Access (tuần tự):
    ┌────┬────┬────┬────┬────┬────┬────┬────┐
    │ D1 │ D2 │ D3 │ D4 │ D5 │ D6 │ D7 │ D8 │
    └────┴────┴────┴────┴────┴────┴────┴────┘
     →    →    →    →    →    →    →    →
    Đọc LIÊN TIẾP → nhanh (HDD: no seek, SSD: prefetch)

    Random Access (ngẫu nhiên):
    ┌────┬────┬────┬────┬────┬────┬────┬────┐
    │ D1 │    │    │ D4 │    │ D6 │    │    │
    └────┴────┴────┴────┴────┴────┴────┴────┘
     ↑              ↑         ↑
    Nhảy lung tung → chậm (HDD: phải seek mỗi lần)

    Ứng dụng thực tế:
    ┌─────────────────────────────────────────────────┐
    │  • Kafka: Sequential write → nhanh trên cả HDD │
    │  • LSM-Tree (RocksDB, Cassandra):               │
    │    Write = sequential (memtable → SSTable)     │
    │    Read = có thể random (cần bloom filter)     │
    │  • B-Tree (PostgreSQL, MySQL):                   │
    │    Cả read+write đều có random component       │
    │    → cần SSD để performance tốt                │
    │  • Write-Ahead Log (WAL):                       │
    │    Append-only = sequential → nhanh & safe     │
    └─────────────────────────────────────────────────┘
```

### 4.3 SSD Internals — NAND Flash Bên Trong

SSD không đơn giản là "RAM không bay hơi". Bên trong có kiến trúc phức tạp với **pages, blocks, erase cycles**, và **write amplification** — hiểu những điều này giải thích tại sao SSD có write limit và tại sao random writes chậm.

```
╔═══════════════════════════════════════════════════════════════╗
║   SSD INTERNALS — NAND FLASH                                ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  CẤU TRÚC PHÂN CẤP:                                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  SSD                                           │             ║
║  │  └── Package (chip)                            │             ║
║  │      └── Die                                   │             ║
║  │          └── Plane                             │             ║
║  │              └── Block (128-512 pages)         │             ║
║  │                  └── Page (4-16 KB)            │             ║
║  │                      └── Cells                 │             ║
║  │                                                │             ║
║  │  ĐƠN VỊ THAO TÁC:                            │             ║
║  │  • READ:  theo PAGE (4-16KB)     ~25μs        │             ║
║  │  • WRITE: theo PAGE (4-16KB)     ~250μs       │             ║
║  │  • ERASE: theo BLOCK (256KB-4MB) ~2ms         │             ║
║  │                                                │             ║
║  │  ⚠️ KHÔNG THỂ ghi đè page trực tiếp!        │             ║
║  │  → Phải ERASE toàn bộ block trước!           │             ║
║  │  → Đây là gốc rễ mọi phức tạp SSD!          │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  NAND CELL TYPES:                                             ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌──────┬──────┬──────┬──────────┬──────────┐ │             ║
║  │  │ Type │Bits/ │Endur.│Speed     │Cost      │ │             ║
║  │  │      │cell  │(P/E) │          │          │ │             ║
║  │  ├──────┼──────┼──────┼──────────┼──────────┤ │             ║
║  │  │ SLC  │  1   │100K  │Fastest   │$$$$      │ │             ║
║  │  │ MLC  │  2   │10K   │Fast      │$$$       │ │             ║
║  │  │ TLC  │  3   │3K    │Medium    │$$        │ │             ║
║  │  │ QLC  │  4   │1K    │Slow      │$         │ │             ║
║  │  └──────┴──────┴──────┴──────────┴──────────┘ │             ║
║  │                                                │             ║
║  │  → Server SSD: thường MLC/TLC enterprise     │             ║
║  │  → Consumer SSD: TLC/QLC (rẻ, ít bền)       │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  WRITE AMPLIFICATION (WA):                                   ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Bạn muốn ghi 4KB:                           │             ║
║  │                                                │             ║
║  │  Block (256KB):                                │             ║
║  │  ┌────┬────┬────┬────┬────┬────┐              │             ║
║  │  │ P0 │ P1 │ P2 │ P3 │ P4 │... │              │             ║
║  │  │old │old │WANT│old │old │    │              │             ║
║  │  │    │    │WRITE    │    │    │              │             ║
║  │  └────┴────┴────┴────┴────┴────┘              │             ║
║  │                                                │             ║
║  │  Phải:                                         │             ║
║  │  1. Đọc TOÀN BỘ block (256KB) vào buffer    │             ║
║  │  2. Modify page P2 trong buffer                │             ║
║  │  3. ERASE toàn block                           │             ║
║  │  4. Ghi lại TOÀN BỘ 256KB                    │             ║
║  │                                                │             ║
║  │  → Ghi 4KB nhưng thực tế ghi 256KB!          │             ║
║  │  → WA = 256/4 = 64x!                          │             ║
║  │  → SSD controller dùng GC + over-provisioning │             ║
║  │    để giảm WA xuống ~2-5x                     │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  TRIM & GARBAGE COLLECTION:                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  TRIM: OS thông báo SSD "pages này đã xóa"  │             ║
║  │  → SSD biết pages nào free để GC hiệu quả   │             ║
║  │  → Không có TRIM: SSD phải đoán → chậm dần!│             ║
║  │                                                │             ║
║  │  ⚠️ Linux: fstrim hoặc mount -o discard       │             ║
║  │  → QUAN TRỌNG cho database servers!            │             ║
║  │  → Không TRIM = SSD chậm dần theo thời gian  │             ║
║  │                                                │             ║
║  │  Over-provisioning:                            │             ║
║  │  → Enterprise SSD: 28% dung lượng dự phòng  │             ║
║  │  → Consumer SSD: 7%                            │             ║
║  │  → Nhiều OP hơn = ít WA + tuổi thọ cao hơn  │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 4.4 I/O Schedulers — Ai Quyết Định Đọc/Ghi Trước?

Khi nhiều processes đồng thời đọc/ghi disk, **I/O scheduler** quyết định thứ tự requests. Chọn sai scheduler = database performance tệ hại.

```
╔═══════════════════════════════════════════════════════════════╗
║   I/O SCHEDULERS                                             ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  TẠI SAO CẦN SCHEDULER:                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Process A: đọc sector 1000                    │             ║
║  │  Process B: đọc sector 5                       │             ║
║  │  Process C: đọc sector 999                     │             ║
║  │                                                │             ║
║  │  Thứ tự FIFO: 1000 → 5 → 999                 │             ║
║  │  → HDD seek: xa→gần→xa = chậm!              │             ║
║  │                                                │             ║
║  │  Thứ tự ELEVATOR: 5 → 999 → 1000             │             ║
║  │  → Di chuyển 1 hướng = ít seek!              │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  LINUX I/O SCHEDULERS:                                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌───────────┬───────────────┬──────────────┐ │             ║
║  │  │ Scheduler │ Tốt cho       │ Không tốt    │ │             ║
║  │  ├───────────┼───────────────┼──────────────┤ │             ║
║  │  │ none/noop │ NVMe SSD      │ HDD          │ │             ║
║  │  │           │ (no reorder)  │              │ │             ║
║  │  │ mq-dead-  │ DB trên SSD  │ Desktop      │ │             ║
║  │  │ line      │ (low latency) │              │ │             ║
║  │  │ bfq       │ Desktop/      │ High-IOPS   │ │             ║
║  │  │           │ mixed load    │ servers      │ │             ║
║  │  │ kyber     │ Fast devices  │ HDD          │ │             ║
║  │  │           │ (auto-tune)   │              │ │             ║
║  │  └───────────┴───────────────┴──────────────┘ │             ║
║  │                                                │             ║
║  │  Kiểm tra/thay đổi:                          │             ║
║  │  $ cat /sys/block/sda/queue/scheduler          │             ║
║  │  [mq-deadline] kyber bfq none                  │             ║
║  │                                                │             ║
║  │  $ echo "none" > /sys/block/nvme0n1/queue/     │             ║
║  │    scheduler                                   │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ DATABASE RECOMMENDATIONS:                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  PostgreSQL + NVMe SSD:                        │             ║
║  │  → none hoặc mq-deadline                      │             ║
║  │  → KHÔNG bfq (overhead cho fast devices)      │             ║
║  │                                                │             ║
║  │  MySQL/InnoDB + SATA SSD:                      │             ║
║  │  → mq-deadline (tốt cho mixed read/write)     │             ║
║  │                                                │             ║
║  │  Kafka + HDD:                                  │             ║
║  │  → deadline (sequential writes dominant)       │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 4.5 Filesystem Internals — Từ `write()` Đến Disk

Filesystem quản lý CÁCH data được tổ chức trên disk. Hiểu internals giải thích tại sao `fsync()` quan trọng cho databases, tại sao journaling cần thiết, và tại sao có thể mất data dù "đã ghi xong".

```
╔═══════════════════════════════════════════════════════════════╗
║   FILESYSTEM INTERNALS                                       ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  WRITE PATH — TỪ write() ĐẾN DISK:                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  App: write(fd, data, len)                     │             ║
║  │       │                                        │             ║
║  │       ▼                                        │             ║
║  │  ┌─────────────┐                               │             ║
║  │  │ Page Cache   │ ← Data nằm ở đây!          │             ║
║  │  │ (kernel RAM) │    write() return NGAY!      │             ║
║  │  └──────┬──────┘                               │             ║
║  │         │ (async)                               │             ║
║  │         ▼                                       │             ║
║  │  ┌─────────────┐                               │             ║
║  │  │ I/O Scheduler│                              │             ║
║  │  └──────┬──────┘                               │             ║
║  │         │                                       │             ║
║  │         ▼                                       │             ║
║  │  ┌─────────────┐                               │             ║
║  │  │ Block Device │                              │             ║
║  │  │ (disk/SSD)   │                              │             ║
║  │  └─────────────┘                               │             ║
║  │                                                │             ║
║  │  ⚠️ write() ≠ data trên disk!                │             ║
║  │  → Data ở page cache (RAM)                    │             ║
║  │  → Mất điện = MẤT DATA!                      │             ║
║  │  → Cần fsync() để ép flush xuống disk!       │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  fsync() VÀ fdatasync():                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  fsync(fd):                                    │             ║
║  │  → Flush data + metadata (inode, timestamps)  │             ║
║  │  → Đảm bảo TẤT CẢ trên disk                │             ║
║  │  → CHẬM (~0.5-5ms mỗi lần)                  │             ║
║  │                                                │             ║
║  │  fdatasync(fd):                                │             ║
║  │  → Flush data + CHỈ metadata cần thiết       │             ║
║  │  → Nhanh hơn fsync một chút                  │             ║
║  │                                                │             ║
║  │  O_DIRECT:                                     │             ║
║  │  → Bypass page cache hoàn toàn!              │             ║
║  │  → App → Block Device trực tiếp              │             ║
║  │  → Databases tự quản lý cache (InnoDB,        │             ║
║  │    RocksDB) → dùng O_DIRECT                   │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  JOURNALING:                                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Vấn đề: Đang ghi file, MẤT ĐIỆN!           │             ║
║  │  → File bị corrupted (half-written)           │             ║
║  │                                                │             ║
║  │  Giải pháp: JOURNAL (write-ahead log!)        │             ║
║  │  ┌──────────────────────────────────┐          │             ║
║  │  │ 1. Ghi vào JOURNAL trước         │          │             ║
║  │  │ 2. Ghi vào vị trí thật          │          │             ║
║  │  │ 3. Xóa journal entry            │          │             ║
║  │  └──────────────────────────────────┘          │             ║
║  │  → Mất điện giữa bước 2?                    │             ║
║  │  → Boot lại: replay journal → FIX!           │             ║
║  │                                                │             ║
║  │  ext4 journal modes:                           │             ║
║  │  • journal: TẤT CẢ qua journal (chậm, safe) │             ║
║  │  • ordered: metadata journal + data trước   │             ║
║  │    metadata (default, cân bằng)               │             ║
║  │  • writeback: chỉ metadata (nhanh, rủi ro)  │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ FILESYSTEM CHOICE CHO DATABASES:                           ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌──────┬──────────────────────────────┐       │             ║
║  │  │ FS   │ Đặc điểm                     │       │             ║
║  │  ├──────┼──────────────────────────────┤       │             ║
║  │  │ext4  │ Stable, journaling, default  │       │             ║
║  │  │      │ PostgreSQL recommendation    │       │             ║
║  │  │XFS   │ Tốt cho large files          │       │             ║
║  │  │      │ MongoDB, Kafka preferred     │       │             ║
║  │  │Btrfs │ CoW, snapshots, checksums    │       │             ║
║  │  │      │ ⚠️ overhead cho random write│       │             ║
║  │  │ZFS   │ Best data integrity          │       │             ║
║  │  │      │ Checksums + ECC + snapshots  │       │             ║
║  │  └──────┴──────────────────────────────┘       │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 4.6 Storage Interfaces — SATA, SAS, NVMe

Interface quyết định **tốc độ tối đa** giữa SSD/HDD và CPU. NVMe nhanh gấp 6x SATA vì kết nối **trực tiếp PCIe** thay vì qua AHCI controller.

```
╔═══════════════════════════════════════════════════════════════╗
║   STORAGE INTERFACES                                         ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  SO SÁNH:                                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌──────┬────────┬────────┬──────┬──────────┐ │             ║
║  │  │      │BW max  │Latency │Queue │Use case  │ │             ║
║  │  │      │(GB/s)  │(μs)    │Depth │          │ │             ║
║  │  ├──────┼────────┼────────┼──────┼──────────┤ │             ║
║  │  │SATA  │ 0.6    │~100    │ 32   │Consumer  │ │             ║
║  │  │      │        │        │      │SSD/HDD   │ │             ║
║  │  │SAS   │ 1.2    │~80     │ 254  │Enterprise│ │             ║
║  │  │      │        │        │      │HDD/SSD   │ │             ║
║  │  │NVMe  │ 3.5-7  │~10-20  │64K   │Fast SSD  │ │             ║
║  │  │(PCIe)│        │        │      │Database  │ │             ║
║  │  │NVMe  │ 12-14  │~5-10   │64K   │Ultra-fast│ │             ║
║  │  │Gen5  │        │        │      │HPC       │ │             ║
║  │  └──────┴────────┴────────┴──────┴──────────┘ │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  TẠI SAO NVMe NHANH HƠN:                                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  SATA SSD:                                     │             ║
║  │  ┌─────┐    ┌──────────┐    ┌─────────┐       │             ║
║  │  │ CPU │────│AHCI Ctrl │────│ SATA SSD│       │             ║
║  │  └─────┘    └──────────┘    └─────────┘       │             ║
║  │  → Qua 1 controller + 1 queue (32 deep)      │             ║
║  │  → Protocol overhead lớn (AHCI từ năm 2004)│             ║
║  │                                                │             ║
║  │  NVMe SSD:                                     │             ║
║  │  ┌─────┐    ┌─────────────────┐                │             ║
║  │  │ CPU │════│ NVMe SSD (PCIe) │                │             ║
║  │  └─────┘    └─────────────────┘                │             ║
║  │  → Trực tiếp qua PCIe bus!                   │             ║
║  │  → 65,535 queues × 65,536 commands mỗi queue│             ║
║  │  → Protocol tối ưu cho flash                  │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ IOPS COMPARISON (4KB random read):                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  HDD (7200 RPM):    ~150 IOPS                  │             ║
║  │  SATA SSD:           ~90,000 IOPS              │             ║
║  │  NVMe SSD:           ~500,000-1,000,000 IOPS   │             ║
║  │                                                │             ║
║  │  PostgreSQL needs: ~10,000 IOPS cho busy DB    │             ║
║  │  → HDD: KHÔNG ĐỦ!                            │             ║
║  │  → SATA SSD: đủ cho phần lớn workloads       │             ║
║  │  → NVMe: cần cho high-concurrency OLTP        │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 4.7 Database I/O Patterns — Tại Sao Storage Architecture Quyết Định Performance

Mỗi database engine chọn I/O pattern khác nhau. Hiểu pattern giúp bạn chọn đúng storage type và tuning parameters.

```
╔═══════════════════════════════════════════════════════════════╗
║   DATABASE I/O PATTERNS                                      ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  B-TREE (PostgreSQL, MySQL/InnoDB):                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  WRITE path:                                   │             ║
║  │  1. Write WAL (sequential append) ← NHANH!   │             ║
║  │  2. Update buffer pool (RAM)                   │             ║
║  │  3. Checkpoint: flush dirty pages (random!)    │             ║
║  │                                                │             ║
║  │  READ path:                                    │             ║
║  │  1. Check buffer pool (RAM) → hit? DONE!      │             ║
║  │  2. Miss → random read from disk              │             ║
║  │  3. B-Tree traversal: O(log n) random reads   │             ║
║  │                                                │             ║
║  │  → RANDOM READ heavy → CẦN SSD!              │             ║
║  │  → WAL sequential → HDD cũng OK              │             ║
║  │  → Tip: Tách WAL disk riêng!                 │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  LSM-TREE (RocksDB, Cassandra, LevelDB):                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  WRITE path:                                   │             ║
║  │  1. Write WAL (sequential)                     │             ║
║  │  2. Insert vào MemTable (RAM, sorted)         │             ║
║  │  3. MemTable đầy → flush thành SSTable       │             ║
║  │     (sequential write!)                        │             ║
║  │  4. Background compaction (sequential R+W)     │             ║
║  │                                                │             ║
║  │  READ path:                                    │             ║
║  │  1. Check MemTable (RAM)                       │             ║
║  │  2. Check bloom filters (RAM)                  │             ║
║  │  3. Check SSTables: newest → oldest           │             ║
║  │  4. Có thể cần đọc nhiều levels             │             ║
║  │                                                │             ║
║  │  → WRITE = SEQUENTIAL → tốt cho HDD/SSD!    │             ║
║  │  → READ = potentially random multi-level      │             ║
║  │  → Read amplification: đọc ~10 files cho     │             ║
║  │    1 key (worse case)                          │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  APPEND-ONLY LOG (Kafka, WAL):                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  WRITE: append cuối file (sequential)         │             ║
║  │  READ:  theo offset (sequential hoặc seek)   │             ║
║  │                                                │             ║
║  │  ┌────────────────────────────────────┐        │             ║
║  │  │ msg0 │ msg1 │ msg2 │ msg3 │ ←WRITE│        │             ║
║  │  └────────────────────────────────────┘        │             ║
║  │    ↑ consumer offset                           │             ║
║  │                                                │             ║
║  │  → 100% sequential = NHANH NHẤT!             │             ║
║  │  → Kafka trên HDD: 600MB/s write possible!   │             ║
║  │  → Kafka dùng sendfile: zero-copy read!       │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ STORAGE SELECTION MATRIX:                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌────────────┬────────┬──────────┬──────────┐ │             ║
║  │  │ Database   │Storage │I/O Type  │Reason    │ │             ║
║  │  ├────────────┼────────┼──────────┼──────────┤ │             ║
║  │  │PostgreSQL  │NVMe SSD│Random R/W│B-Tree    │ │             ║
║  │  │MySQL InnoDB│NVMe SSD│Random R/W│B-Tree    │ │             ║
║  │  │Cassandra   │SATA SSD│Seq write │LSM-Tree  │ │             ║
║  │  │Kafka       │HDD OK! │Seq R/W   │Append log│ │             ║
║  │  │Redis       │Any     │RAM-only  │In-memory │ │             ║
║  │  │MongoDB     │NVMe SSD│Random R/W│WiredTiger│ │             ║
║  │  │ClickHouse  │HDD OK! │Seq scan  │Columnar  │ │             ║
║  │  │Elasticsearch│SSD    │Random R  │Inverted  │ │             ║
║  │  └────────────┴────────┴──────────┴──────────┘ │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 4.8 RAID — Redundant Array of Independent Disks

RAID kết hợp nhiều disk thành 1 logical volume để tăng **performance**, **redundancy**, hoặc cả hai. Chọn sai RAID level cho database = mất data hoặc performance tệ.

```
╔═══════════════════════════════════════════════════════════════╗
║   RAID LEVELS                                                ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  RAID 0 — Striping (KHÔNG redundancy!):                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Data: [A][B][C][D][E][F]                     │             ║
║  │  Disk1: [A][C][E]     Disk2: [B][D][F]        │             ║
║  │                                                │             ║
║  │  + Tốc độ: 2× (parallel R/W)                │             ║
║  │  - 1 disk chết = MẤT TẤT CẢ!               │             ║
║  │  → KHÔNG BAO GIỜ cho production databases!    │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  RAID 1 — Mirroring:                                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Data:  [A][B][C]                              │             ║
║  │  Disk1: [A][B][C]  (copy 1)                    │             ║
║  │  Disk2: [A][B][C]  (copy 2)                    │             ║
║  │                                                │             ║
║  │  + 1 disk chết: KHÔNG mất data!              │             ║
║  │  + Read: 2× (đọc từ cả 2)                   │             ║
║  │  - Capacity: 50% (chỉ dùng được nửa)        │             ║
║  │  → Tốt cho WAL / transaction log disk         │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  RAID 5 — Striping + Distributed Parity:                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Disk1: [A1][B1][ P]                         │             ║
║  │  Disk2: [A2][ P][C1]                         │             ║
║  │  Disk3: [ P][B2][C2]  (P = parity)           │             ║
║  │                                                │             ║
║  │  + Chịu được 1 disk fail                     │             ║
║  │  + Capacity: (n-1)/n (tốt hơn RAID 1)       │             ║
║  │  - Write penalty: mỗi write cần tính parity │             ║
║  │  - Rebuild chậm + nguy hiểm (2nd failure!)   │             ║
║  │                                                │             ║
║  │  RAID 6: 2 parity → chịu 2 disk fail         │             ║
║  │  → Recommended cho large arrays!              │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  RAID 10 — Mirror + Stripe (BEST for DB):                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  ┌─────────┐     ┌─────────┐                  │             ║
║  │  │ Stripe 1│     │ Stripe 2│                  │             ║
║  │  │ D1  D2  │     │ D3  D4  │                  │             ║
║  │  │[A] [A]  │     │[B] [B]  │                  │             ║
║  │  │mirror   │     │mirror   │                  │             ║
║  │  └─────────┘     └─────────┘                  │             ║
║  │                                                │             ║
║  │  + Performance: RAID 0 speed                   │             ║
║  │  + Redundancy: RAID 1 safety                   │             ║
║  │  - Capacity: 50%                               │             ║
║  │  → BEST cho databases (PostgreSQL, MySQL)!     │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ DATABASE RECOMMENDATIONS:                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌───────────────┬──────┬──────────────────┐   │             ║
║  │  │ Component     │RAID  │ Reason            │   │             ║
║  │  ├───────────────┼──────┼──────────────────┤   │             ║
║  │  │ DB data       │ 10   │ Fast + redundant  │   │             ║
║  │  │ WAL/redo log  │ 1    │ Sequential + safe │   │             ║
║  │  │ Backup        │ 5/6  │ Capacity efficient│   │             ║
║  │  │ Temp/scratch  │ 0    │ Speed, no safety  │   │             ║
║  │  └───────────────┴──────┴──────────────────┘   │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 4.9 Go Disk I/O Patterns — Đọc/Ghi File Hiệu Quả

Go `os.File` tưởng đơn giản nhưng có nhiều patterns ảnh hưởng lớn đến performance. Biết khi nào dùng buffered I/O, khi nào `io.Copy`, và cách tránh common pitfalls.

```
╔═══════════════════════════════════════════════════════════════╗
║   GO DISK I/O PATTERNS                                       ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  BUFFERED vs UNBUFFERED I/O:                                 ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // ❌ Unbuffered — mỗi Write = 1 syscall:   │             ║
║  │  f, _ := os.Create("log.txt")                  │             ║
║  │  for _, line := range lines {                  │             ║
║  │      f.WriteString(line + "\n")  // syscall!   │             ║
║  │  }                                             │             ║
║  │  // 1M lines = 1M syscalls → CHẬM!           │             ║
║  │                                                │             ║
║  │  // ✅ Buffered — batched syscalls:            │             ║
║  │  f, _ := os.Create("log.txt")                  │             ║
║  │  w := bufio.NewWriter(f)                       │             ║
║  │  for _, line := range lines {                  │             ║
║  │      w.WriteString(line + "\n")  // buffer!    │             ║
║  │  }                                             │             ║
║  │  w.Flush()  // 1 final syscall (or few)       │             ║
║  │  f.Sync()   // ← QUAN TRỌNG: fsync!          │             ║
║  │                                                │             ║
║  │  → bufio.NewWriterSize(f, 64*1024) cho        │             ║
║  │    performance tốt nhất (64KB buffer)         │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  io.Copy — ZERO-ALLOC FILE COPY:                             ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // ❌ ReadAll + WriteAll:                     │             ║
║  │  data, _ := os.ReadFile("big.dat") // ALL RAM!│             ║
║  │  os.WriteFile("copy.dat", data, 0644)          │             ║
║  │  // 10GB file = 10GB RAM!                      │             ║
║  │                                                │             ║
║  │  // ✅ io.Copy — streaming:                    │             ║
║  │  src, _ := os.Open("big.dat")                  │             ║
║  │  dst, _ := os.Create("copy.dat")               │             ║
║  │  io.Copy(dst, src) // 32KB buffer internally  │             ║
║  │  // 10GB file = 32KB RAM!                      │             ║
║  │                                                │             ║
║  │  // Linux: io.Copy sử dụng splice/sendfile   │             ║
║  │  // → zero-copy khi cả 2 là *os.File!        │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CONCURRENT I/O — PARALLEL READS:                            ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  // Đọc nhiều files song song:                │             ║
║  │  func readFiles(paths []string) [][]byte {     │             ║
║  │      results := make([][]byte, len(paths))     │             ║
║  │      var wg sync.WaitGroup                     │             ║
║  │      // Giới hạn concurrent I/O!              │             ║
║  │      sem := make(chan struct{}, 10)             │             ║
║  │      for i, p := range paths {                 │             ║
║  │          wg.Add(1)                             │             ║
║  │          go func(idx int, path string) {       │             ║
║  │              defer wg.Done()                   │             ║
║  │              sem <- struct{}{}                  │             ║
║  │              defer func(){ <-sem }()           │             ║
║  │              results[idx], _ = os.ReadFile(    │             ║
║  │                  path)                         │             ║
║  │          }(i, p)                               │             ║
║  │      }                                         │             ║
║  │      wg.Wait()                                 │             ║
║  │      return results                            │             ║
║  │  }                                             │             ║
║  │                                                │             ║
║  │  ⚠️ TẠI SAO giới hạn concurrency:            │             ║
║  │  → Quá nhiều concurrent I/O = thrashing!      │             ║
║  │  → HDD: nên 1-2 concurrent                   │             ║
║  │  → SSD: 10-32 concurrent OK                    │             ║
║  │  → NVMe: 64-128 concurrent                    │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 4.10 Storage Monitoring — iostat, fio, và SLOs

Không thể tối ưu những gì không đo được. Đây là toolkit cho backend engineers để monitor và benchmark disk I/O.

```
╔═══════════════════════════════════════════════════════════════╗
║   STORAGE MONITORING & BENCHMARKING                          ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  iostat — REAL-TIME I/O MONITORING:                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  $ iostat -xz 1  (1 giây interval)            │             ║
║  │                                                │             ║
║  │  Device r/s   w/s   rkB/s  wkB/s await  util  │             ║
║  │  sda    150   50    4800   1600  2.5    45%    │             ║
║  │  nvme0  5000  2000  160K   64K   0.1    30%    │             ║
║  │                                                │             ║
║  │  KEY METRICS:                                  │             ║
║  │  • r/s, w/s: IOPS (reads/writes per second)   │             ║
║  │  • await: avg request latency (ms)             │             ║
║  │    → > 10ms trên SSD = VẤN ĐỀ!              │             ║
║  │    → > 20ms trên HDD = BÃO HÒA              │             ║
║  │  • %util: disk utilization                     │             ║
║  │    → > 80% = đang bottleneck!                 │             ║
║  │    → ⚠️ Misleading cho NVMe (multi-queue)    │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  fio — DISK BENCHMARKING:                                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  # Random read (giống DB workload):           │             ║
║  │  $ fio --name=test --ioengine=libaio \         │             ║
║  │    --rw=randread --bs=4k --numjobs=8 \         │             ║
║  │    --iodepth=32 --size=1G --runtime=60         │             ║
║  │                                                │             ║
║  │  # Sequential write (giống Kafka):            │             ║
║  │  $ fio --name=test --ioengine=libaio \         │             ║
║  │    --rw=write --bs=1M --numjobs=1 \            │             ║
║  │    --iodepth=4 --size=10G --runtime=60         │             ║
║  │                                                │             ║
║  │  # Mixed (giống real DB workload):            │             ║
║  │  $ fio --name=test --ioengine=libaio \         │             ║
║  │    --rw=randrw --rwmixread=70 --bs=8k \        │             ║
║  │    --numjobs=16 --iodepth=64 --runtime=60      │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ STORAGE SLOs CHO DATABASES:                                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌───────────┬──────────┬──────────┬────────┐ │             ║
║  │  │ Metric    │ Good     │ Warning  │ Bad    │ │             ║
║  │  ├───────────┼──────────┼──────────┼────────┤ │             ║
║  │  │ p99 read  │ < 1ms    │ 1-5ms    │ > 5ms  │ │             ║
║  │  │ latency   │ (NVMe)   │ (SSD)    │ (HDD)  │ │             ║
║  │  │ p99 write │ < 2ms    │ 2-10ms   │ > 10ms │ │             ║
║  │  │ latency   │          │          │        │ │             ║
║  │  │ IOPS      │ > 50K    │ 10-50K   │ < 10K  │ │             ║
║  │  │ util %    │ < 50%    │ 50-80%   │ > 80%  │ │             ║
║  │  │ await     │ < 0.5ms  │ 0.5-5ms  │ > 5ms  │ │             ║
║  │  └───────────┴──────────┴──────────┴────────┘ │             ║
║  │                                                │             ║
║  │  → Set alerts trên Prometheus/Grafana cho    │             ║
║  │    các thresholds này!                         │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §5. Bus & Data Flow — Đường Cao Tốc Dữ Liệu

### 5.1 Các thành phần nói chuyện thế nào?

```
╔═══════════════════════════════════════════════════════════════╗
║   BUS SYSTEM — HỆ THỐNG ĐƯỜNG TRUYỀN                        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Bus = "đường cao tốc" kết nối các thành phần.              ║
║  Mọi communication đều đi qua bus.                           ║
║                                                               ║
║  ┌────────┐  Memory Bus   ┌────────┐                        ║
║  │  CPU   │◄═════════════►│  RAM   │                        ║
║  │        │  (64-bit wide) │        │                        ║
║  └───┬────┘               └────────┘                        ║
║      │                                                        ║
║      │ PCIe Bus                                               ║
║      │                                                        ║
║  ┌───┴─────────────────────────────────────────┐             ║
║  │              Chipset / IO Hub                │             ║
║  └──┬──────────┬──────────┬──────────┬─────────┘             ║
║     │          │          │          │                        ║
║  ┌──┴───┐  ┌──┴───┐  ┌──┴───┐  ┌──┴───┐                   ║
║  │ SSD  │  │ NIC  │  │ GPU  │  │ USB  │                    ║
║  │      │  │(mạng)│  │      │  │      │                    ║
║  └──────┘  └──────┘  └──────┘  └──────┘                    ║
║                                                               ║
║  3 loại BUS chính:                                            ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  1. Address Bus: CPU gửi ĐỊA CHỈ cần đọc   │             ║
║  │     → "Tôi muốn đọc ô nhớ 0x1234"          │             ║
║  │                                                │             ║
║  │  2. Data Bus: Truyền DỮ LIỆU qua lại        │             ║
║  │     → 64-bit: truyền 8 bytes cùng lúc       │             ║
║  │                                                │             ║
║  │  3. Control Bus: Tín hiệu ĐIỀU KHIỂN         │             ║
║  │     → Read/Write, Interrupt, Clock           │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  BANDWIDTH (Băng thông) — Quan trọng cho System Design:      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Memory Bus: ~50 GB/s (DDR5)               │             ║
║  │  • PCIe 4.0 x16: ~32 GB/s                    │             ║
║  │  • NVMe SSD: ~7 GB/s                         │             ║
║  │  • SATA SSD: ~0.6 GB/s                       │             ║
║  │  • Gigabit Ethernet: ~0.125 GB/s              │             ║
║  │  • 10G Ethernet: ~1.25 GB/s                   │             ║
║  │                                                │             ║
║  │  → Network bandwidth << Memory bandwidth!     │             ║
║  │  → Đây là lý do distributed systems PHỨC TẠP │             ║
║  │  → Data locality matters!                     │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 5.2 I/O — Nút thắt cổ chai #1 của Backend

Trong backend engineering, **I/O là bottleneck phổ biến nhất**. Hiểu rõ I/O giúp bạn thiết kế hệ thống hiệu quả hơn nhiều.

```
╔═══════════════════════════════════════════════════════════════╗
║   I/O — INPUT/OUTPUT                                          ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  I/O = Mọi tương tác với "thế giới bên ngoài" CPU/RAM:     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Disk I/O: đọc/ghi file, database          │             ║
║  │  • Network I/O: HTTP requests, DB queries    │             ║
║  │  • Terminal I/O: stdin/stdout                 │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  TẠI SAO I/O là bottleneck?                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  CPU tính toán:    ~1 ns                      │             ║
║  │  RAM access:       ~100 ns         (100x)     │             ║
║  │  SSD read:         ~100,000 ns     (100,000x) │             ║
║  │  Network (LAN):    ~500,000 ns     (500,000x) │             ║
║  │  Network (cross-DC): ~100,000,000 ns          │             ║
║  │                                                │             ║
║  │  → Khi code đang CHỜ I/O, CPU NGỒI KHÔNG!   │             ║
║  │  → Đây là lý do cần:                         │             ║
║  │    • Async I/O (Go goroutines, Node.js event  │             ║
║  │      loop, epoll/kqueue)                      │             ║
║  │    • Connection pooling                       │             ║
║  │    • Caching (Redis, Memcached)               │             ║
║  │    • Batching (gộp nhiều I/O thành 1)        │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CPU-bound vs I/O-bound:                                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  CPU-bound: Tính toán nặng                    │             ║
║  │  → VD: Encryption, image processing, ML      │             ║
║  │  → Cần nhiều CPU cores (parallelism)         │             ║
║  │                                                │             ║
║  │  I/O-bound: Chờ I/O nhiều (phổ biến hơn!)   │             ║
║  │  → VD: Web server, API, database queries     │             ║
║  │  → Cần concurrency (goroutines, async)        │             ║
║  │  → Thêm CPU cores KHÔNG giúp nhiều!          │             ║
║  │                                                │             ║
║  │  ⚠️ 90% backend services là I/O-bound!       │             ║
║  │  → Đây là lý do Go goroutines hiệu quả:     │             ║
║  │    1000 goroutines chờ I/O ≈ 0% CPU usage!   │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 5.3 PCIe Deep Dive — Xương Sống Của Server Hiện Đại

PCI Express là bus **chính** kết nối CPU với mọi thiết bị ngoại vi (SSD, GPU, NIC). Hiểu PCIe giải thích tại sao NVMe nhanh, tại sao GPU training cần PCIe x16, và tại sao server topology quan trọng.

```
╔═══════════════════════════════════════════════════════════════╗
║   PCIe — PERIPHERAL COMPONENT INTERCONNECT EXPRESS          ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  PCIe GENERATIONS:                                           ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌──────┬──────────┬──────────┬─────────────┐ │             ║
║  │  │ Gen  │ Per Lane │ x1       │ x16         │ │             ║
║  │  │      │ (GT/s)   │ (GB/s)   │ (GB/s)      │ │             ║
║  │  ├──────┼──────────┼──────────┼─────────────┤ │             ║
║  │  │ 3.0  │ 8        │ ~1       │ ~16         │ │             ║
║  │  │ 4.0  │ 16       │ ~2       │ ~32         │ │             ║
║  │  │ 5.0  │ 32       │ ~4       │ ~64         │ │             ║
║  │  │ 6.0  │ 64       │ ~8       │ ~128        │ │             ║
║  │  └──────┴──────────┴──────────┴─────────────┘ │             ║
║  │                                                │             ║
║  │  Lane = 1 đường truyền song song              │             ║
║  │  x1, x4, x8, x16 = số lanes ghép lại         │             ║
║  │  → Bandwidth tỉ lệ tuyến tính với lanes      │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  PCIe TOPOLOGY TRONG SERVER:                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌──────┐         ┌──────┐                    │             ║
║  │  │ CPU0 │═══UPI═══│ CPU1 │  (NUMA link)      │             ║
║  │  └──┬───┘         └──┬───┘                    │             ║
║  │     │                 │                        │             ║
║  │  ┌──┴──┐           ┌──┴──┐                    │             ║
║  │  │PCIe │           │PCIe │  (Root Complex)    │             ║
║  │  │Root │           │Root │                    │             ║
║  │  └──┬──┘           └──┬──┘                    │             ║
║  │     │                 │                        │             ║
║  │  ┌──┴──┬──────┐   ┌──┴──┬──────┐             │             ║
║  │  │NVMe │ NIC  │   │NVMe │ GPU  │             │             ║
║  │  │SSD  │ 25G  │   │SSD  │      │             │             ║
║  │  └─────┴──────┘   └─────┴──────┘             │             ║
║  │                                                │             ║
║  │  ⚠️ NUMA IMPACT:                             │             ║
║  │  → CPU0 truy cập NVMe gắn CPU1              │             ║
║  │    = qua UPI link = thêm ~100ns latency!     │             ║
║  │  → Pin process vào đúng NUMA node!           │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ BACKEND RELEVANCE:                                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌───────────────┬────────┬─────────────────┐ │             ║
║  │  │ Device        │ PCIe   │ Bandwidth       │ │             ║
║  │  ├───────────────┼────────┼─────────────────┤ │             ║
║  │  │ NVMe SSD      │ x4     │ ~8 GB/s (Gen4)  │ │             ║
║  │  │ 25G NIC       │ x4-x8  │ ~3.1 GB/s       │ │             ║
║  │  │ 100G NIC      │ x16    │ ~12.5 GB/s      │ │             ║
║  │  │ GPU (A100)    │ x16    │ ~32 GB/s (Gen4) │ │             ║
║  │  │ FPGA          │ x8-x16 │ ~16-32 GB/s     │ │             ║
║  │  └───────────────┴────────┴─────────────────┘ │             ║
║  │                                                │             ║
║  │  → NIC 100G cần PCIe Gen4 x16 để không bị   │             ║
║  │    bottleneck bởi bus!                         │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 5.4 DMA — Khi CPU Không Cần Động Tay

**Direct Memory Access** cho phép thiết bị (SSD, NIC) đọc/ghi RAM **trực tiếp** mà CPU không cần tham gia từng byte. Không có DMA, mọi byte network data phải đi qua CPU — server sẽ chậm khủng khiếp.

```
╔═══════════════════════════════════════════════════════════════╗
║   DMA — DIRECT MEMORY ACCESS                                ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  KHÔNG CÓ DMA (Programmed I/O):                             ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  NIC nhận 1 packet (1500 bytes):              │             ║
║  │                                                │             ║
║  │  CPU                 NIC                       │             ║
║  │  ┌───┐               ┌───────┐                 │             ║
║  │  │   │◄── read 4B ──│ byte0 │  ×375 lần!     │             ║
║  │  │   │──► write RAM  │ byte4 │                 │             ║
║  │  │   │◄── read 4B ──│ byte8 │                 │             ║
║  │  │   │──► write RAM  │ ...   │                 │             ║
║  │  └───┘               └───────┘                 │             ║
║  │  → CPU BẬN RỘNG suốt quá trình copy!        │             ║
║  │  → 10Gbps network = CPU 100% chỉ copy data! │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CÓ DMA:                                                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  CPU                DMA Engine        NIC      │             ║
║  │  ┌───┐              ┌──────┐         ┌─────┐  │             ║
║  │  │   │── setup ──► │      │         │     │  │             ║
║  │  │   │  (src,dst,  │      │◄═══════│data │  │             ║
║  │  │   │   len)      │      │═══►RAM │     │  │             ║
║  │  │   │             │      │ direct! │     │  │             ║
║  │  │   │◄─ done IRQ─│      │         │     │  │             ║
║  │  └───┘              └──────┘         └─────┘  │             ║
║  │                                                │             ║
║  │  → CPU chỉ setup + nhận interrupt = RẢN!    │             ║
║  │  → DMA engine copy data trực tiếp NIC → RAM │             ║
║  │  → CPU free để làm việc khác!                │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ZERO-COPY I/O (sendfile / splice):                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  TRUYỀN THỐNG (4 copies!):                    │             ║
║  │  Disk → [DMA] → Kernel Buffer                 │             ║
║  │  Kernel Buffer → [CPU] → User Buffer          │             ║
║  │  User Buffer → [CPU] → Socket Buffer          │             ║
║  │  Socket Buffer → [DMA] → NIC                  │             ║
║  │                                                │             ║
║  │  ZERO-COPY (sendfile, 2 copies):              │             ║
║  │  Disk → [DMA] → Kernel Buffer                 │             ║
║  │  Kernel Buffer → [DMA] → NIC  (skip user!)   │             ║
║  │                                                │             ║
║  │  → Kafka dùng sendfile() cho consumer read!   │             ║
║  │  → Nginx dùng sendfile cho static files!      │             ║
║  │  → Go: io.Copy giữa *os.File + net.Conn     │             ║
║  │    tự dùng splice trên Linux!                 │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 5.5 Interrupts — Cách Phần Cứng "Gọi" CPU

Interrupt là cơ chế phần cứng/phần mềm **ngắt** CPU khỏi công việc hiện tại để xử lý sự kiện (packet mạng đến, disk đọc xong, timer hết thời gian). Hiểu interrupts giải thích tại sao context switching tốn kém và tại sao **interrupt coalescing** giúp NIC nhanh hơn.

```
╔═══════════════════════════════════════════════════════════════╗
║   INTERRUPTS                                                 ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  CƠ CHẾ INTERRUPT:                                           ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  CPU đang chạy program:                       │             ║
║  │  ┌─────────────────────────────────────┐       │             ║
║  │  │ instruction 1                        │       │             ║
║  │  │ instruction 2                        │       │             ║
║  │  │ instruction 3 ← IRQ! ═══╗           │       │             ║
║  │  │    ┌─────────────────────╨──────┐    │       │             ║
║  │  │    │ 1. Save CPU state (regs)  │    │       │             ║
║  │  │    │ 2. Jump to ISR handler    │    │       │             ║
║  │  │    │ 3. Execute handler code   │    │       │             ║
║  │  │    │ 4. Restore CPU state      │    │       │             ║
║  │  │    └───────────────────────────┘    │       │             ║
║  │  │ instruction 4 (resume)           │       │             ║
║  │  └─────────────────────────────────────┘       │             ║
║  │                                                │             ║
║  │  ISR = Interrupt Service Routine               │             ║
║  │  → Càng ngắn càng tốt (top half / bottom half)│             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  LOẠI INTERRUPTS:                                             ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  HARDWARE INTERRUPTS (IRQ):                   │             ║
║  │  • NIC: "Có packet mạng đến!"                │             ║
║  │  • Disk: "Đọc xong rồi!"                     │             ║
║  │  • Timer: "1ms đã qua" → scheduler preempt   │             ║
║  │  • Keyboard: "User nhấn phím"                │             ║
║  │                                                │             ║
║  │  SOFTWARE INTERRUPTS (Exceptions/Traps):      │             ║
║  │  • syscall: int 0x80 / syscall instruction    │             ║
║  │  • Page fault: truy cập memory chưa mapped   │             ║
║  │  • Division by zero: lỗi toán học            │             ║
║  │  • Breakpoint: debugger trap                  │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  MSI/MSI-X (Message Signaled Interrupts):                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Legacy: Tất cả devices share IRQ lines      │             ║
║  │  → CPU phải hỏi từng device "có phải bạn?"  │             ║
║  │                                                │             ║
║  │  MSI-X: Device gửi message trực tiếp        │             ║
║  │  → Mỗi queue riêng 1 interrupt vector         │             ║
║  │  → NIC 25G: 64 queues × 64 MSI-X vectors     │             ║
║  │  → Mỗi CPU core handle riêng 1 queue!         │             ║
║  │                                                │             ║
║  │  ⚠️ Interrupt Affinity:                       │             ║
║  │  → Bind NIC interrupt → đúng CPU core        │             ║
║  │  → Tránh interrupt ping-pong giữa cores      │             ║
║  │  → /proc/irq/<N>/smp_affinity                 │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  INTERRUPT COALESCING:                                       ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Mỗi packet = 1 interrupt:                    │             ║
║  │  → 1M packets/s = 1M interrupts/s!           │             ║
║  │  → CPU chỉ xử lý interrupts, không làm gì   │             ║
║  │    khác! ("interrupt livelock")                │             ║
║  │                                                │             ║
║  │  Coalescing: Gộp nhiều packets → 1 interrupt │             ║
║  │  → ethtool -C eth0 rx-usecs 50               │             ║
║  │  → Trade-off: latency ↑ nhưng throughput ↑↑  │             ║
║  │                                                │             ║
║  │  NAPI (Linux): Hybrid interrupt + polling    │             ║
║  │  → Low traffic: interrupt-driven              │             ║
║  │  → High traffic: switch to polling mode       │             ║
║  │  → Tránh livelock ở high packet rate          │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 5.6 MMIO & Port I/O — CPU Nói Chuyện Với Device

Có 2 cách CPU giao tiếp với phần cứng: **Memory-Mapped I/O** (device registers map vào address space) và **Port I/O** (dùng instructions riêng). Hầu hết thiết bị hiện đại dùng MMIO.

```
╔═══════════════════════════════════════════════════════════════╗
║   MMIO & PORT I/O                                            ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  PORT I/O (Legacy):                                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  CPU dùng instructions riêng:                 │             ║
║  │  • IN  AL, 0x60   (đọc từ port 0x60)         │             ║
║  │  • OUT 0x60, AL   (ghi vào port 0x60)         │             ║
║  │                                                │             ║
║  │  → Chỉ 64K ports (0x0000 - 0xFFFF)           │             ║
║  │  → x86 specific, không portable                │             ║
║  │  → Vẫn dùng cho keyboard, speaker cũ         │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  MMIO (Memory-Mapped I/O):                                   ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Device registers = addresses trong RAM map:  │             ║
║  │                                                │             ║
║  │  Virtual Address Space:                        │             ║
║  │  ┌──────────────────────────────┐              │             ║
║  │  │ 0x0000... │ Normal RAM       │              │             ║
║  │  │ ...       │ ...              │              │             ║
║  │  │ 0xFE00... │ NIC registers   │ ← MMIO      │             ║
║  │  │ 0xFF00... │ GPU framebuffer │ ← MMIO      │             ║
║  │  └──────────────────────────────┘              │             ║
║  │                                                │             ║
║  │  CPU ghi vào 0xFE00_0010:                     │             ║
║  │  → Không phải ghi RAM!                        │             ║
║  │  → PCIe route → NIC nhận command!            │             ║
║  │                                                │             ║
║  │  Ưu điểm MMIO:                                │             ║
║  │  • Dùng MOV instruction thường (giống RAM)   │             ║
║  │  • Không giới hạn address space               │             ║
║  │  • Works trên mọi architecture (ARM, RISC-V) │             ║
║  │  • Kernel mmap device registers vào driver    │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ BACKEND RELEVANCE — USERSPACE I/O:                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  DPDK (Data Plane Development Kit):           │             ║
║  │  → Map NIC registers trực tiếp vào userspace │             ║
║  │  → Bypass kernel networking stack hoàn toàn! │             ║
║  │  → 10-100× performance cho packet processing │             ║
║  │                                                │             ║
║  │  SPDK (Storage Performance Dev Kit):          │             ║
║  │  → Map NVMe controller vào userspace          │             ║
║  │  → Bypass kernel block layer                   │             ║
║  │  → Microsecond-level storage latency          │             ║
║  │                                                │             ║
║  │  io_uring (Linux 5.1+):                       │             ║
║  │  → Shared ring buffers (MMIO-style)           │             ║
║  │  → Submit + complete I/O without syscalls!    │             ║
║  │  → PostgreSQL, RocksDB đang adopt!            │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 5.7 Network Data Path — Từ NIC Đến Application

Khi một HTTP request đến server, data đi qua **rất nhiều layers**. Hiểu full path giúp debug "tại sao latency cao?" và tối ưu performance ở đúng layer.

```
╔═══════════════════════════════════════════════════════════════╗
║   NETWORK DATA PATH — PACKET JOURNEY                        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  FULL PATH — PACKET TỪ NIC ĐẾN GO APP:                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. NIC nhận packet từ wire                   │             ║
║  │     │  (electrical/optical signal → bytes)    │             ║
║  │     ▼                                          │             ║
║  │  2. NIC DMA packet → Ring Buffer (RAM)        │             ║
║  │     │  (sk_buff struct, pre-allocated)         │             ║
║  │     ▼                                          │             ║
║  │  3. NIC raises IRQ → CPU                      │             ║
║  │     │  (hoặc NAPI poll ở high traffic)        │             ║
║  │     ▼                                          │             ║
║  │  4. Kernel NIC driver xử lý                   │             ║
║  │     │  → Parse Ethernet header                │             ║
║  │     ▼                                          │             ║
║  │  5. Network stack (IP layer)                   │             ║
║  │     │  → Routing, firewall (iptables/nftables)│             ║
║  │     ▼                                          │             ║
║  │  6. Transport layer (TCP)                      │             ║
║  │     │  → Reassemble, ACK, flow control        │             ║
║  │     ▼                                          │             ║
║  │  7. Socket receive buffer                      │             ║
║  │     │  → Per-socket buffer (tunable size)     │             ║
║  │     ▼                                          │             ║
║  │  8. goroutine: conn.Read(buf)                  │             ║
║  │     │  → syscall: read(fd, buf, len)          │             ║
║  │     │  → copy from kernel → userspace         │             ║
║  │     ▼                                          │             ║
║  │  9. Application processes HTTP request         │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  LATENCY TẠI MỖI LAYER:                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌────────────────────┬────────┬─────────────┐ │             ║
║  │  │ Layer              │Latency │Tuning knob  │ │             ║
║  │  ├────────────────────┼────────┼─────────────┤ │             ║
║  │  │ NIC → Ring Buffer  │ <1μs   │ Ring size   │ │             ║
║  │  │ IRQ processing     │ 1-5μs  │ IRQ affinity│ │             ║
║  │  │ Network stack      │ 5-15μs │ GRO/GSO     │ │             ║
║  │  │ TCP processing     │ 2-10μs │ TCP tuning  │ │             ║
║  │  │ Socket buffer      │ 0-1μs  │ SO_RCVBUF   │ │             ║
║  │  │ Kernel→User copy   │ 1-5μs  │ (overhead)  │ │             ║
║  │  │ App processing     │ varies │ Your code!  │ │             ║
║  │  └────────────────────┴────────┴─────────────┘ │             ║
║  │                                                │             ║
║  │  Total: ~10-40μs kernel overhead per packet   │             ║
║  │  → DPDK bypass: <2μs!                          │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  GO net/http — DATA FLOW:                                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Server.ListenAndServe()                       │             ║
║  │       │                                        │             ║
║  │       ▼                                        │             ║
║  │  net.Listen("tcp", ":8080")                    │             ║
║  │       │  → bind + listen syscall              │             ║
║  │       ▼                                        │             ║
║  │  for { conn := listener.Accept() }             │             ║
║  │       │  → accept syscall                     │             ║
║  │       │  → Go runtime: netpoller (epoll)      │             ║
║  │       ▼                                        │             ║
║  │  go srv.serve(conn)  ← 1 goroutine per conn! │             ║
║  │       │                                        │             ║
║  │       ├─ Read request (conn.Read)              │             ║
║  │       │    → epoll_wait if no data             │             ║
║  │       │    → goroutine parks (not OS thread!)  │             ║
║  │       │                                        │             ║
║  │       ├─ Parse HTTP (bufio.Reader, 4KB buf)   │             ║
║  │       │                                        │             ║
║  │       ├─ Route → Handler                      │             ║
║  │       │                                        │             ║
║  │       ├─ Write response (bufio.Writer, 4KB)   │             ║
║  │       │    → conn.Write → write syscall       │             ║
║  │       │                                        │             ║
║  │       └─ Keep-alive? Loop : Close             │             ║
║  │                                                │             ║
║  │  ⚠️ Goroutine park/unpark = NO OS context sw! │             ║
║  │  → 100K concurrent conns = chỉ vài OS threads│             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 5.8 I/O Models — Blocking, Non-Blocking, Async

Cách application chờ I/O quyết định **throughput** và **scalability**. Đây là kiến thức nền tảng ngay trước khi hiểu tại sao Go goroutines, Node.js event loop, và Nginx architecture khác nhau.

```
╔═══════════════════════════════════════════════════════════════╗
║   I/O MODELS                                                 ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  5 I/O MODELS (Stevens):                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  1. BLOCKING I/O:                              │             ║
║  │  ┌──────┐          ┌──────┐                    │             ║
║  │  │ App  │──read──►│Kernel│                    │             ║
║  │  │BLOCK │  ......  │wait  │  (app ngủ)        │             ║
║  │  │      │◄─data──│done  │                    │             ║
║  │  └──────┘          └──────┘                    │             ║
║  │  → 1 thread/conn = 10K conns = 10K threads!  │             ║
║  │  → Thread per connection model (Apache)       │             ║
║  │                                                │             ║
║  │  2. NON-BLOCKING I/O:                          │             ║
║  │  ┌──────┐          ┌──────┐                    │             ║
║  │  │ App  │──read──►│Kernel│→ EAGAIN!          │             ║
║  │  │      │──read──►│      │→ EAGAIN!          │             ║
║  │  │      │──read──►│      │→ data ready!      │             ║
║  │  └──────┘          └──────┘                    │             ║
║  │  → App phải POLL liên tục = waste CPU!        │             ║
║  │  → Hiếm khi dùng trực tiếp                   │             ║
║  │                                                │             ║
║  │  3. I/O MULTIPLEXING (select/poll/epoll):     │             ║
║  │  ┌──────┐          ┌──────┐                    │             ║
║  │  │ App  │─epoll──►│Kernel│                    │             ║
║  │  │BLOCK │  ......  │watch │  (chờ NHIỀU fds)  │             ║
║  │  │      │◄─ready!─│ fd=5 │  → chỉ 1 thread! │             ║
║  │  │      │──read──►│      │                    │             ║
║  │  └──────┘          └──────┘                    │             ║
║  │  → 1 thread handle 100K connections!          │             ║
║  │  → Nginx, Redis, Node.js model!               │             ║
║  │                                                │             ║
║  │  4. SIGNAL-DRIVEN I/O:                         │             ║
║  │  → Kernel gửi signal khi data ready (ít dùng)│             ║
║  │                                                │             ║
║  │  5. ASYNC I/O (aio/io_uring):                 │             ║
║  │  ┌──────┐          ┌──────┐                    │             ║
║  │  │ App  │──submit──►│Kernel│                  │             ║
║  │  │ chạy │  tiếp    │ đọc  │ (kernel tự lo)   │             ║
║  │  │ code │          │ xong │                    │             ║
║  │  │      │◄─done!──│      │ (data đã ở buf)   │             ║
║  │  └──────┘          └──────┘                    │             ║
║  │  → TRUE async: zero blocking, zero polling!   │             ║
║  │  → io_uring (Linux 5.1+): tương lai!         │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  MULTIPLEXING MECHANISMS:                                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌────────┬──────────┬───────────┬──────────┐ │             ║
║  │  │        │ select   │ epoll     │ kqueue   │ │             ║
║  │  ├────────┼──────────┼───────────┼──────────┤ │             ║
║  │  │ OS     │ All      │ Linux     │ *BSD/Mac │ │             ║
║  │  │ FD max │ 1024     │ No limit  │ No limit │ │             ║
║  │  │ Perf   │ O(n)     │ O(1)      │ O(1)     │ │             ║
║  │  │ How    │ Scan all │ Callback  │ Callback │ │             ║
║  │  │ Scale  │ Bad      │ Excellent │ Excellent│ │             ║
║  │  └────────┴──────────┴───────────┴──────────┘ │             ║
║  │                                                │             ║
║  │  → Go dùng epoll (Linux) / kqueue (Mac)       │             ║
║  │  → Mỗi goroutine "blocking" nhưng thực ra    │             ║
║  │    OS thread KHÔNG block (netpoller!)          │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 5.9 Go Netpoller — Bí Mật Đằng Sau Goroutine I/O

Go biến **blocking I/O syntax** thành **non-blocking execution** bằng netpoller — tích hợp epoll/kqueue vào runtime scheduler. Goroutines "nhìn" blocking nhưng bên dưới là multiplexed I/O.

```
╔═══════════════════════════════════════════════════════════════╗
║   GO NETPOLLER                                               ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  CƠ CHẾ HOẠT ĐỘNG:                                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  goroutine gọi conn.Read():                   │             ║
║  │                                                │             ║
║  │  ┌─────────────────────────────────────────┐   │             ║
║  │  │ 1. syscall read(fd) → EAGAIN (no data) │   │             ║
║  │  │ 2. Register fd với epoll                │   │             ║
║  │  │ 3. PARK goroutine (remove from P queue) │   │             ║
║  │  │ 4. OS thread M: chạy goroutine khác!   │   │             ║
║  │  │    (thread KHÔNG block!)                │   │             ║
║  │  │                                          │   │             ║
║  │  │ ─── time passes, data arrives ───       │   │             ║
║  │  │                                          │   │             ║
║  │  │ 5. Netpoller thread: epoll_wait()        │   │             ║
║  │  │    → fd ready!                           │   │             ║
║  │  │ 6. UNPARK goroutine (add to P queue)    │   │             ║
║  │  │ 7. goroutine resumed: read(fd) → data! │   │             ║
║  │  └─────────────────────────────────────────┘   │             ║
║  │                                                │             ║
║  │  DEVELOPER WRITES:        RUNTIME DOES:       │             ║
║  │  ┌──────────────┐     ┌──────────────────┐     │             ║
║  │  │ data, err :=  │     │ 1. non-blocking  │     │             ║
║  │  │ conn.Read(buf)│ ──► │    read attempt  │     │             ║
║  │  │ // "blocks"   │     │ 2. epoll register│     │             ║
║  │  │               │     │ 3. park goroutine│     │             ║
║  │  │               │     │ 4. schedule other│     │             ║
║  │  │               │     │ 5. epoll ready   │     │             ║
║  │  │               │     │ 6. unpark + read │     │             ║
║  │  └──────────────┘     └──────────────────┘     │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  TẠI SAO DESIGN NÀY THIÊN TÀI:                              ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  vs Thread-per-connection (Java Tomcat):       │             ║
║  │  → 10K connections = 10K threads              │             ║
║  │  → 10K × 1MB stack = 10GB RAM!               │             ║
║  │  → Context switch overhead enormous           │             ║
║  │                                                │             ║
║  │  vs Event loop (Node.js):                      │             ║
║  │  → Single threaded = no parallelism!          │             ║
║  │  → Callback hell / Promise chains             │             ║
║  │  → CPU-bound task blocks EVERYTHING           │             ║
║  │                                                │             ║
║  │  Go: BEST OF BOTH WORLDS!                      │             ║
║  │  → Blocking syntax (dễ đọc, dễ reason)       │             ║
║  │  → Non-blocking execution (scalable)           │             ║
║  │  → Multi-threaded (parallelism khi cần)       │             ║
║  │  → 10K connections = 10K goroutines           │             ║
║  │  → 10K × 2KB stack = 20MB RAM!               │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ CONNECTION POOLING — TẠI SAO CẦN:                         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  Mỗi DB connection = 1 TCP connection:        │             ║
║  │  → 3-way handshake (~1ms LAN, ~100ms WAN)    │             ║
║  │  → TLS handshake (~5-50ms thêm!)             │             ║
║  │  → DB auth + session setup (~1-5ms)           │             ║
║  │  → Total: ~10-150ms cho MỖI connection!      │             ║
║  │                                                │             ║
║  │  Connection Pool (sql.DB trong Go):            │             ║
║  │  → Pre-create N connections                    │             ║
║  │  → Goroutine "mượn" connection từ pool        │             ║
║  │  → Dùng xong "trả" lại                       │             ║
║  │  → Zero handshake overhead!                    │             ║
║  │                                                │             ║
║  │  db.SetMaxOpenConns(25)    // production      │             ║
║  │  db.SetMaxIdleConns(10)    // keep warm        │             ║
║  │  db.SetConnMaxLifetime(5*time.Minute)         │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 5.10 Linux Network Tuning — Server Performance Checklist

Biết **sysctl parameters** nào cần tune cho production server. Nhiều server chạy default Linux settings = bỏ phí 50% performance.

```
╔═══════════════════════════════════════════════════════════════╗
║   LINUX NETWORK TUNING                                       ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  TCP BUFFER TUNING:                                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  # Default quá nhỏ cho high-throughput:       │             ║
║  │  $ sysctl net.core.rmem_max           # recv  │             ║
║  │  $ sysctl net.core.wmem_max           # send  │             ║
║  │                                                │             ║
║  │  # Tune cho production:                       │             ║
║  │  net.core.rmem_max = 16777216        # 16MB   │             ║
║  │  net.core.wmem_max = 16777216        # 16MB   │             ║
║  │  net.ipv4.tcp_rmem = 4096 87380 16777216      │             ║
║  │  net.ipv4.tcp_wmem = 4096 65536 16777216      │             ║
║  │  #          min  default  max                 │             ║
║  │                                                │             ║
║  │  → Quan trọng cho cross-DC replication!       │             ║
║  │  → BDP = Bandwidth × RTT                     │             ║
║  │  → 10Gbps × 10ms RTT = 12.5MB buffer needed! │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  CONNECTION TUNING:                                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  # Backlog (pending connections queue):        │             ║
║  │  net.core.somaxconn = 65535                    │             ║
║  │  net.ipv4.tcp_max_syn_backlog = 65535          │             ║
║  │  → Default 128 = DROP connections ở peak!    │             ║
║  │                                                │             ║
║  │  # TIME_WAIT recycling:                       │             ║
║  │  net.ipv4.tcp_tw_reuse = 1                     │             ║
║  │  → Cho phép reuse TIME_WAIT sockets           │             ║
║  │  → Quan trọng cho services nhiều connections  │             ║
║  │                                                │             ║
║  │  # File descriptors:                          │             ║
║  │  fs.file-max = 1000000                         │             ║
║  │  → Mỗi connection = 1 fd                     │             ║
║  │  → ulimit -n 1000000 (per process)            │             ║
║  │  → Default 1024 = max 1024 connections!       │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  NIC RING BUFFER & RSS:                                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  # Ring buffer (NIC ← DMA → RAM):            │             ║
║  │  $ ethtool -g eth0                             │             ║
║  │  RX: 4096  (tăng nếu drop > 0)              │             ║
║  │  $ ethtool -G eth0 rx 4096                     │             ║
║  │                                                │             ║
║  │  # RSS — Receive Side Scaling:                │             ║
║  │  → NIC hash packet → distribute across       │             ║
║  │    multiple RX queues → multiple CPU cores    │             ║
║  │  → 1 queue per core = parallel processing!    │             ║
║  │  $ ethtool -l eth0    # show channels         │             ║
║  │  $ ethtool -L eth0 combined 16                 │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  ☞ PRODUCTION CHECKLIST:                                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  □ somaxconn ≥ 4096                           │             ║
║  │  □ file-max ≥ 100000                          │             ║
║  │  □ ulimit -n ≥ 65535                          │             ║
║  │  □ tcp_tw_reuse = 1                            │             ║
║  │  □ TCP buffer sizes tuned for BDP             │             ║
║  │  □ NIC ring buffer maximized                   │             ║
║  │  □ RSS enabled (multi-queue NIC)              │             ║
║  │  □ IRQ affinity configured                     │             ║
║  │  □ nf_conntrack_max tuned (if firewall)       │             ║
║  │  □ GOMAXPROCS = num cores (default in Go)     │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §6. Từ Code Đến Thực Thi — Hành Trình Của 1 Dòng Code

### 6.1 Bạn viết code... rồi chuyện gì xảy ra?

Khi bạn gõ `go run main.go`, có một chuỗi biến đổi PHỨC TẠP xảy ra. Hiểu chuỗi này giúp bạn hiểu tại sao có bugs, tại sao có performance issues, và tại sao compiler đôi khi "không nghe lời" bạn.

```go
// File: main.go
package main

func main() {
    x := 42
    y := x + 8
    println(y) // Output: 50
}
```

```
╔═══════════════════════════════════════════════════════════════╗
║   HÀNH TRÌNH CỦA "x := 42"                                  ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  BƯỚC 1: SOURCE CODE → COMPILER                              ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Go Compiler (gc) gồm nhiều giai đoạn:       │             ║
║  │                                                │             ║
║  │  Source Code                                   │             ║
║  │  "x := 42"                                    │             ║
║  │      │                                         │             ║
║  │      ▼                                         │             ║
║  │  [Lexer] → Tokens: IDENT("x"), ASSIGN,       │             ║
║  │            INT(42)                             │             ║
║  │      │                                         │             ║
║  │      ▼                                         │             ║
║  │  [Parser] → AST (Abstract Syntax Tree)        │             ║
║  │            AssignStmt{Name: "x", Value: 42}   │             ║
║  │      │                                         │             ║
║  │      ▼                                         │             ║
║  │  [Type Checker] → Kiểm tra kiểu              │             ║
║  │                   x is int, 42 is int → OK!   │             ║
║  │      │                                         │             ║
║  │      ▼                                         │             ║
║  │  [SSA/Optimizer] → Tối ưu hóa                 │             ║
║  │                    Escape analysis             │             ║
║  │                    Inlining, Dead code elim    │             ║
║  │      │                                         │             ║
║  │      ▼                                         │             ║
║  │  [Code Generator] → Machine Code (binary)     │             ║
║  │                     MOV R1, #42                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  BƯỚC 2: BINARY → OS LOADER                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  OS nhận được file binary (ELF trên Linux)   │             ║
║  │                                                │             ║
║  │  1. Tạo PROCESS mới                           │             ║
║  │     → PID, memory space, file descriptors     │             ║
║  │                                                │             ║
║  │  2. Cấp phát VIRTUAL MEMORY                   │             ║
║  │     → Code segment: chứa instructions        │             ║
║  │     → Data segment: global variables          │             ║
║  │     → Stack: cho goroutine chính              │             ║
║  │     → Heap: dynamic allocation                │             ║
║  │                                                │             ║
║  │  3. Load code vào memory                      │             ║
║  │                                                │             ║
║  │  4. Set Program Counter → điểm bắt đầu      │             ║
║  │     (Go runtime init → main.main)             │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  BƯỚC 3: CPU THỰC THI                                        ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  x := 42 đã biến thành:                      │             ║
║  │                                                │             ║
║  │  MOV R1, #42     ; Load 42 vào register R1   │             ║
║  │  STR R1, [SP+8]  ; Lưu R1 vào stack          │             ║
║  │                                                │             ║
║  │  y := x + 8 biến thành:                       │             ║
║  │  LDR R2, [SP+8]  ; Load x từ stack vào R2    │             ║
║  │  ADD R3, R2, #8  ; R3 = R2 + 8 = 50          │             ║
║  │  STR R3, [SP+16] ; Lưu y vào stack            │             ║
║  │                                                │             ║
║  │  Mỗi instruction:                             │             ║
║  │  1. FETCH: Lấy từ memory (hoặc L1 cache)    │             ║
║  │  2. DECODE: Control Unit giải mã             │             ║
║  │  3. EXECUTE: ALU thực hiện                    │             ║
║  │                                                │             ║
║  │  Tổng thời gian cho 5 instructions:           │             ║
║  │  ~1-5 nanoseconds!                            │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 6.2 Virtual Memory — Ảo giác bộ nhớ vô hạn

```
╔═══════════════════════════════════════════════════════════════╗
║   VIRTUAL MEMORY — TẠI SAO CẦN?                             ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  VẤN ĐỀ: Nhiều chương trình cùng chạy, RAM có hạn!        ║
║                                                               ║
║  GIẢI PHÁP: Mỗi process thấy "RAM riêng"                   ║
║  → Nhưng thực ra là ẢO (virtual)!                           ║
║                                                               ║
║  ┌──────────────────┐     ┌──────────────────┐               ║
║  │ Process A        │     │ Process B        │               ║
║  │ Virtual Memory   │     │ Virtual Memory   │               ║
║  │ ┌──────────────┐ │     │ ┌──────────────┐ │               ║
║  │ │ 0x0000: code │ │     │ │ 0x0000: code │ │               ║
║  │ │ 0x1000: data │ │     │ │ 0x1000: data │ │               ║
║  │ │ 0x2000: heap │ │     │ │ 0x2000: heap │ │               ║
║  │ │ ...          │ │     │ │ ...          │ │               ║
║  │ │ 0xFFFF: stack│ │     │ │ 0xFFFF: stack│ │               ║
║  │ └──────┬───────┘ │     │ └──────┬───────┘ │               ║
║  └────────┼─────────┘     └────────┼─────────┘               ║
║           │ Page Table              │ Page Table               ║
║           ▼                         ▼                         ║
║  ┌────────────────────────────────────────────┐               ║
║  │         Physical RAM (thật)                 │               ║
║  │  ┌─────┬─────┬─────┬─────┬─────┬─────┐   │               ║
║  │  │ P.A │ P.B │ P.A │ P.B │Free │ P.A │   │               ║
║  │  │code │code │heap │data │     │stack│   │               ║
║  │  └─────┴─────┴─────┴─────┴─────┴─────┘   │               ║
║  └────────────────────────────────────────────┘               ║
║                                                               ║
║  PAGE = Đơn vị quản lý memory (thường 4KB):                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Virtual address → Page Table → Physical   │             ║
║  │  • Page Fault: page chưa ở RAM → load từ    │             ║
║  │    disk (SWAP) → CỰC CHẬM!                  │             ║
║  │  • TLB (Translation Lookaside Buffer):        │             ║
║  │    Cache cho Page Table → tránh tra cứu chậm│             ║
║  │                                                │             ║
║  │  ⚠️ Nếu RAM hết → OS dùng SWAP (disk)       │             ║
║  │  → Performance giảm 10,000-100,000x!         │             ║
║  │  → PHẢI monitor memory usage trong production!│             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## §7. Deep Analysis Patterns — 6 Tư Duy Phân Tích

### 7.1 Pattern 1: Đệ quy "Tại sao" (5 Whys)

Áp dụng kỹ thuật Toyota vào câu hỏi: **"Tại sao Redis nhanh hơn PostgreSQL?"**

```
    5 WHYS — REDIS vs POSTGRESQL

    Q1: "Tại sao Redis nhanh hơn PostgreSQL?"
    → A: Vì Redis lưu data trong RAM, PostgreSQL lưu trên disk

    Q2: "Tại sao RAM nhanh hơn disk?"
    → A: Vì RAM là electronic (~100ns),
          disk là mechanical/flash (~100μs-10ms)

    Q3: "Tại sao không lưu HẾT trên RAM?"
    → A: Vì RAM volatile (mất khi tắt điện) VÀ đắt
          ($5/GB RAM vs $0.02/GB HDD)

    Q4: "Vậy Redis mất data khi restart?"
    → A: Có thể! Trừ khi dùng AOF/RDB persistence
          → ghi xuống disk ĐỊNH KỲ
          → Trade-off: performance vs durability

    Q5: "Khi nào PostgreSQL nhanh hơn Redis?"
    → A: Khi cần COMPLEX QUERIES (JOIN, aggregation)
          Redis chỉ có key-value, không có SQL optimizer
          → Trade-off: speed vs query flexibility

    ☞ KẾT LUẬN:
    ┌──────────────────────────────────────────────┐
    │  Không có "database tốt nhất"                 │
    │  Chỉ có database PHÙ HỢP nhất cho use case  │
    │  → Redis: cache, session, real-time data     │
    │  → PostgreSQL: transactional, complex queries │
    │  → Hiểu HARDWARE = hiểu TẠI SAO              │
    └──────────────────────────────────────────────┘

    ═══════════════════════════════════════════════════

    5 WHYS — TẠI SAO SERVICE BỊ GOROUTINE LEAK?

    Q1: "Tại sao memory tăng liên tục?"
    → A: Vì số goroutines tăng mãi không giảm

    Q2: "Tại sao goroutines không kết thúc?"
    → A: Vì goroutine đang blocked trên channel send,
          không ai receive

    Q3: "Tại sao không ai receive?"
    → A: Vì consumer goroutine đã exit do context cancel,
          nhưng producer vẫn gửi vào unbuffered channel

    Q4: "Tại sao producer không biết consumer đã exit?"
    → A: Vì producer không select trên ctx.Done(),
          chỉ send trên channel

    Q5: "Làm sao tránh?"
    → A: LUÔN select ctx.Done() khi send/receive!
          Hoặc dùng buffered channel với timeout

    ☞ FIX:
    ┌──────────────────────────────────────────────┐
    │  // ❌ Leak:                                  │
    │  ch <- data  // blocked forever!              │
    │                                                │
    │  // ✅ Safe:                                   │
    │  select {                                      │
    │  case ch <- data:                              │
    │  case <-ctx.Done():                            │
    │      return // thoát sạch!                    │
    │  }                                             │
    └──────────────────────────────────────────────┘

    ═══════════════════════════════════════════════════

    5 WHYS — TẠI SAO KAFKA CONSUMER LAG TĂNG?

    Q1: "Tại sao consumer lag tăng 500K messages?"
    → A: Vì consumer xử lý chậm hơn producer

    Q2: "Tại sao consumer chậm?"
    → A: Vì mỗi message cần query DB, avg 50ms/msg
          → Max throughput: 20 msg/s/consumer

    Q3: "Tại sao query chậm 50ms?"
    → A: Vì full table scan — thiếu index trên
          column được filter

    Q4: "Tại sao không thêm consumer instances?"
    → A: Có 1 partition = chỉ 1 consumer active!
          Cần tăng partitions TRƯỚC

    Q5: "Giải pháp tối ưu?"
    → A: 1. Thêm index (50ms → 1ms)
          2. Tăng partitions (1 → 8)
          3. Batch DB queries (8 queries → 1 IN query)
          → 20 msg/s → 4000 msg/s!

    ☞ KẾT LUẬN:
    ┌──────────────────────────────────────────────┐
    │  5 Whys giúp tìm ROOT CAUSE, không chữa     │
    │  triệu chứng. "Thêm consumer" là chữa       │
    │  triệu chứng. "Thêm index" mới là gốc rễ!  │
    └──────────────────────────────────────────────┘
```

### 7.2 Pattern 2: First Principles Thinking

Phân rã **"Database"** thành các sự thật cơ bản nhất không thể chối cãi:

```
╔═══════════════════════════════════════════════════════════════╗
║   FIRST PRINCIPLES — DATABASE DECONSTRUCTED                  ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Mọi database, dù PostgreSQL hay MongoDB, đều là:           ║
║                                                               ║
║  1. DATA STRUCTURES:                                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • B-Tree: PostgreSQL indexes                 │             ║
║  │    → O(log n) read, O(log n) write           │             ║
║  │    → Tốt cho READ-heavy workloads            │             ║
║  │                                                │             ║
║  │  • LSM-Tree: RocksDB, Cassandra, LevelDB     │             ║
║  │    → O(1) write (append), O(n) worst read    │             ║
║  │    → Tốt cho WRITE-heavy workloads           │             ║
║  │                                                │             ║
║  │  • Hash Table: Redis, Memcached               │             ║
║  │    → O(1) read/write                          │             ║
║  │    → Nhưng: không range query, memory only   │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  2. ALGORITHMS:                                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Binary Search (B-Tree traversal)           │             ║
║  │  • Merge Sort (LSM compaction)                │             ║
║  │  • Hashing (key→slot mapping)                │             ║
║  │  • Write-Ahead Log (crash recovery)           │             ║
║  │  • Bloom Filter (probabilistic existence)     │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  3. HARDWARE INTERACTION:                                     ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Disk: fsync, page size (4KB), I/O pattern │             ║
║  │  • RAM: buffer pool, shared memory            │             ║
║  │  • CPU: query parsing, hash computation       │             ║
║  │  • Network: client connections, replication   │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  → Khi bạn hiểu 3 yếu tố cơ bản này,                       ║
║    bạn có thể DỰ ĐOÁN behavior của BẤT KỲ database!        ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

**Áp dụng First Principles cho "Tại sao Microservices chậm hơn Monolith?":**

```
╔═══════════════════════════════════════════════════════════════╗
║   FIRST PRINCIPLES — NETWORK CALL DECONSTRUCTED             ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Monolith: function call                                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  result := userService.GetUser(id) // ~1μs   │             ║
║  │  → In-process: stack push + pop               │             ║
║  │  → Data: already in same address space        │             ║
║  │  → Zero serialization                          │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  Microservice: network call                                  ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  1. Serialize request    → JSON/Proto  ~10μs │             ║
║  │  2. Write to TCP buffer  → syscall     ~5μs  │             ║
║  │  3. Network transit      → RTT         ~500μs│             ║
║  │  4. Kernel → userspace   → copy        ~5μs  │             ║
║  │  5. Deserialize request  → parse       ~10μs │             ║
║  │  6. Business logic       → compute     ~50μs │             ║
║  │  7. Serialize response   → JSON/Proto  ~10μs │             ║
║  │  8. Network transit back → RTT         ~500μs│             ║
║  │  9. Deserialize response → parse       ~10μs │             ║
║  │  ──────────────────────────────────────────── │             ║
║  │  Total: ~1,100μs = 1.1ms (vs 1μs!)          │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  → Microservice call chậm hơn 1000× so với function call!   ║
║  → Đây là PHYSICAL LIMIT, không optimize được!              ║
║                                                               ║
║  ☞ IMPLICATIONS:                                              ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  • Fan-out 10 services = 10 × 1ms = 10ms!   │             ║
║  │  • 3 hop chain = 3ms minimum latency!         │             ║
║  │  • → Cần parallel fan-out khi có thể         │             ║
║  │  • → Cần caching ở service boundary           │             ║
║  │  • → Cần gRPC thay JSON (5× serialization)   │             ║
║  │  • → Cần service mesh cho retry/timeout       │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 7.3 Pattern 3: Trade-off Analysis

**Mọi quyết định kỹ thuật đều có trade-off.** Senior engineer PHẢI articulate rõ ràng cả hai mặt.

```
    TRADE-OFF ANALYSIS — MEMORY HIERARCHY

    ┌───────────┬──────────┬──────────┬──────────┐
    │           │ Tốc độ   │ Dung     │ Giá      │
    │           │          │ lượng    │          │
    ├───────────┼──────────┼──────────┼──────────┤
    │ Register  │ ★★★★★    │ ★         │ ★★★★★    │
    │ L1 Cache  │ ★★★★★    │ ★★        │ ★★★★★    │
    │ RAM       │ ★★★      │ ★★★      │ ★★★      │
    │ SSD       │ ★★        │ ★★★★     │ ★★        │
    │ HDD       │ ★         │ ★★★★★    │ ★         │
    └───────────┴──────────┴──────────┴──────────┘

    → NHANH = NHỎ = ĐẮT | CHẬM = LỚN = RẺ
    → Không thể có TẤT CẢ!

    "Kịch bản nào thì mỗi cấp thất bại?"
    ┌──────────────────────────────────────────────┐
    │  • Cache: THẤT BẠI khi working set > cache   │
    │    size → cache thrashing                     │
    │  • RAM: THẤT BẠI khi data > RAM → swap       │
    │    → performance cliff (giảm 1000x!)         │
    │  • SSD: THẤT BẠI khi write amplification     │
    │    quá cao → shorten lifespan                 │
    │  • In-memory DB: THẤT BẠI khi cần            │
    │    durability 100% (power loss = data loss)   │
    └──────────────────────────────────────────────┘
```

**Trade-off trong Backend Architecture:**

```
╔═══════════════════════════════════════════════════════════════╗
║   BACKEND TRADE-OFFS                                         ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  1. CONSISTENCY vs AVAILABILITY (CAP Theorem):               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌──────────────┬─────────────┬─────────────┐ │             ║
║  │  │ System       │ Choose      │ Sacrifice   │ │             ║
║  │  ├──────────────┼─────────────┼─────────────┤ │             ║
║  │  │ PostgreSQL   │ Consistency │ Availability│ │             ║
║  │  │ (single)     │ (ACID)      │ (1 node)    │ │             ║
║  │  │ Cassandra    │ Availability│ Consistency │ │             ║
║  │  │              │ (always up) │ (eventual)  │ │             ║
║  │  │ CockroachDB  │ Consistency │ Latency     │ │             ║
║  │  │              │ (strong)    │ (consensus) │ │             ║
║  │  └──────────────┴─────────────┴─────────────┘ │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  2. LATENCY vs THROUGHPUT:                                   ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  • Batching: throughput ↑↑ nhưng latency ↑   │             ║
║  │    → Kafka: batch 100 msgs → 1 disk write    │             ║
║  │    → DB: batch INSERT 1000 rows cùng lúc     │             ║
║  │                                                │             ║
║  │  • Caching: latency ↓↓ nhưng consistency ↓   │             ║
║  │    → Redis cache: 0.5ms vs 50ms database      │             ║
║  │    → Nhưng stale data tối đa TTL seconds!    │             ║
║  │                                                │             ║
║  │  • Compression: bandwidth ↓ nhưng CPU ↑       │             ║
║  │    → gzip response: 80% smaller, +5ms CPU     │             ║
║  │    → Worth it cho slow network, not fast LAN  │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  3. SIMPLICITY vs PERFORMANCE:                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │                                                │             ║
║  │  ┌──────────────────┬──────────┬─────────────┐│             ║
║  │  │ Pattern          │Simple   │Performance  ││             ║
║  │  ├──────────────────┼──────────┼─────────────┤│             ║
║  │  │ sync.Mutex       │ ★★★★★   │ ★★★         ││             ║
║  │  │ sync.RWMutex     │ ★★★★    │ ★★★★        ││             ║
║  │  │ atomic.Value     │ ★★★     │ ★★★★★       ││             ║
║  │  │ Lock-free queue  │ ★       │ ★★★★★       ││             ║
║  │  │                  │          │             ││             ║
║  │  │ JSON encoding    │ ★★★★★   │ ★★          ││             ║
║  │  │ Protobuf         │ ★★★     │ ★★★★        ││             ║
║  │  │ FlatBuffers      │ ★★      │ ★★★★★       ││             ║
║  │  └──────────────────┴──────────┴─────────────┘│             ║
║  │                                                │             ║
║  │  ☞ "Premature optimization is the root of     │             ║
║  │     all evil" — Knuth                          │             ║
║  │  → Chọn simplicity TRƯỚC, optimize SAU!       │             ║
║  │  → Profile trước khi optimize!                 │             ║
║  │                                                │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 7.4 Pattern 4: Mental Mapping

```
╔═══════════════════════════════════════════════════════════════╗
║   MENTAL MAP — TỪ CODE ĐẾN PHẦN CỨNG                        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Khi bạn viết: db.Query("SELECT * FROM users")              ║
║  Đây là bản đồ TẤT CẢ layers bị ảnh hưởng:                ║
║                                                               ║
║  ┌─────────────────────────────────────────────────┐         ║
║  │  TẦNG ỨNG DỤNG                                  │         ║
║  │  └── Go code: db.Query(...)                     │         ║
║  │      └── Database driver: encode SQL            │         ║
║  ├─────────────────────────────────────────────────┤         ║
║  │  TẦNG TRUNG GIAN                                │         ║
║  │  └── Connection pool: pick connection           │         ║
║  │      └── TCP buffer: send bytes                 │         ║
║  ├─────────────────────────────────────────────────┤         ║
║  │  TẦNG MẠNG                                       │         ║
║  │  └── TCP/IP stack (OS kernel)                    │         ║
║  │      └── NIC (Network Interface Card)           │         ║
║  │          └── Wire/Fiber → Server                │         ║
║  ├─────────────────────────────────────────────────┤         ║
║  │  TẦNG DATABASE SERVER                            │         ║
║  │  └── Query Parser → Query Optimizer             │         ║
║  │      └── Executor: B-Tree traversal             │         ║
║  │          └── Buffer Pool (RAM cache)            │         ║
║  ├─────────────────────────────────────────────────┤         ║
║  │  TẦNG HỆ ĐIỀU HÀNH                              │         ║
║  │  └── File System: XFS/ext4                      │         ║
║  │      └── Block I/O scheduler                    │         ║
║  │          └── Device driver                      │         ║
║  ├─────────────────────────────────────────────────┤         ║
║  │  TẦNG PHẦN CỨNG                                 │         ║
║  │  └── SSD Controller                             │         ║
║  │      └── NAND Flash cells                       │         ║
║  │          └── Electrical signals (0 và 1)        │         ║
║  └─────────────────────────────────────────────────┘         ║
║                                                               ║
║  → Bottleneck có thể ở BẤT KỲ tầng nào!                    ║
║  → Senior Engineer phải biết ĐÂU là bottleneck!            ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

**Mental Map 2: Goroutine Lifecycle — Khi bạn viết `go func()`:**

```
╔═══════════════════════════════════════════════════════════════╗
║   MENTAL MAP — GOROUTINE FULL LIFECYCLE                      ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  go handleRequest(conn)                                       ║
║  │                                                            ║
║  ├─ TẦNG GO RUNTIME                                          ║
║  │  ├─ Allocate 2KB stack (heap, growable)                   ║
║  │  ├─ Create G struct (id, stack, status)                   ║
║  │  ├─ Put G into P's local run queue                        ║
║  │  └─ If all P busy → global queue                        ║
║  │                                                            ║
║  ├─ TẦNG SCHEDULER (GMP)                                     ║
║  │  ├─ M (OS thread) picks G from P's queue                 ║
║  │  ├─ Set G.status = Running                                ║
║  │  ├─ Jump to G's function pointer                          ║
║  │  └─ Context: G runs ON M, managed BY P                   ║
║  │                                                            ║
║  ├─ TẦNG I/O (conn.Read)                                     ║
║  │  ├─ syscall read(fd) → EAGAIN                            ║
║  │  ├─ Netpoller: register fd with epoll                    ║
║  │  ├─ Park G (status → Waiting)                            ║
║  │  ├─ M picks ANOTHER G from queue                         ║
║  │  ├─ ... data arrives → epoll wakes fd                   ║
║  │  └─ Unpark G (status → Runnable → Running)              ║
║  │                                                            ║
║  ├─ TẦNG OS                                                   ║
║  │  ├─ M = pthread = kernel thread                           ║
║  │  ├─ syscalls: futex, epoll_wait, read, write             ║
║  │  └─ OS scheduler: timeslice M across CPU cores           ║
║  │                                                            ║
║  └─ TẦNG HARDWARE                                             ║
║     ├─ CPU core executes M's instructions                    ║
║     ├─ L1/L2 cache: G's stack data                           ║
║     └─ Context switch M = flush pipeline + TLB!             ║
║                                                               ║
║  ☞ Khi goroutine "chờ I/O":                                  ║
║  → G parked (0 CPU), M free → chạy G khác                 ║
║  → 100K goroutines waiting = near 0 CPU usage!               ║
║  → NHƯNG: 100K goroutines COMPUTING = need 100K cores!      ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 7.5 Pattern 5: Reverse Engineering & Implementation

```
    REVERSE ENGINEERING — TỰ TAY XÂY ĐỂ HIỂU

    "What I cannot create, I do not understand" — Feynman

    BÀI TẬP: Tự build Key-Value Store đơn giản bằng Go

    Bước 1 — In-memory (Hash Table):
    ┌──────────────────────────────────────────────┐
    │  type KVStore struct {                        │
    │      mu   sync.RWMutex                        │
    │      data map[string][]byte                   │
    │  }                                             │
    │  → Nhanh! Nhưng mất data khi restart         │
    └──────────────────────────────────────────────┘

    Bước 2 — Thêm persistence (Write-Ahead Log):
    ┌──────────────────────────────────────────────┐
    │  Mỗi write → append vào WAL file trước!     │
    │  Khi restart → replay WAL để khôi phục state│
    │  → Bây giờ bạn HIỂU tại sao DB cần WAL!    │
    └──────────────────────────────────────────────┘

    Bước 3 — Tại sao cần index?
    ┌──────────────────────────────────────────────┐
    │  WAL file lớn → full scan CHẬM!             │
    │  → Cần index (B-Tree hoặc Hash index)       │
    │  → Bây giờ bạn HIỂU tại sao DB có index!   │
    └──────────────────────────────────────────────┘

    ☞ Khi tự build, bạn đối mặt CHÍNH XÁC các vấn đề
      mà PostgreSQL, Redis, etcd đã giải quyết.
    ☞ Tài nguyên: CodeCrafters — Build your own Redis
```

**Go Code — Concurrent KV Store với WAL:**

```
╔═══════════════════════════════════════════════════════════════╗
║   BUILD YOUR OWN — KV STORE WITH WAL                        ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  // WAL entry format: [op][keylen][key][vallen][val]         ║
║  const (                                                      ║
║      OpSet    byte = 1                                        ║
║      OpDelete byte = 2                                        ║
║  )                                                            ║
║                                                               ║
║  type KVStore struct {                                        ║
║      mu   sync.RWMutex                                        ║
║      data map[string][]byte                                   ║
║      wal  *os.File                                            ║
║      buf  *bufio.Writer                                       ║
║  }                                                            ║
║                                                               ║
║  func (s *KVStore) Set(key string, val []byte) error {       ║
║      s.mu.Lock()                                              ║
║      defer s.mu.Unlock()                                      ║
║                                                               ║
║      // 1. Write WAL FIRST (crash safety!)                   ║
║      s.buf.WriteByte(OpSet)                                   ║
║      binary.Write(s.buf, binary.LittleEndian,                ║
║                   uint32(len(key)))                            ║
║      s.buf.WriteString(key)                                   ║
║      binary.Write(s.buf, binary.LittleEndian,                ║
║                   uint32(len(val)))                            ║
║      s.buf.Write(val)                                         ║
║      s.buf.Flush()                                            ║
║      s.wal.Sync() // ← fsync = durability!                  ║
║                                                               ║
║      // 2. Update in-memory AFTER WAL                        ║
║      s.data[key] = val                                        ║
║      return nil                                               ║
║  }                                                            ║
║                                                               ║
║  func (s *KVStore) Get(key string) ([]byte, bool) {          ║
║      s.mu.RLock()         // RLock cho reads!                ║
║      defer s.mu.RUnlock()                                     ║
║      val, ok := s.data[key]                                   ║
║      return val, ok       // O(1) from memory                ║
║  }                                                            ║
║                                                               ║
║  // Recovery: replay WAL on startup                          ║
║  func (s *KVStore) Recover() error {                         ║
║      // Read WAL file, replay each entry                     ║
║      // → Rebuild in-memory map from disk!                   ║
║      // → Đây chính xác là cách Redis AOF works!            ║
║  }                                                            ║
║                                                               ║
║  ☞ BÀI HỌC TỪ IMPLEMENTATION:                               ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  1. WAL trước, memory sau → crash safety     │             ║
║  │  2. fsync() = đảm bảo data trên disk        │             ║
║  │     → Nhưng CHẬM! (~1ms per fsync)           │             ║
║  │     → Trade-off: batch fsync (Redis) hoặc   │             ║
║  │       group commit (PostgreSQL)               │             ║
║  │  3. RLock cho read, Lock cho write            │             ║
║  │     → N readers concurrent, 1 writer only     │             ║
║  │  4. In-memory map = index!                    │             ║
║  │     → Khi data > RAM? → cần on-disk index   │             ║
║  │     → B-Tree hoặc LSM-Tree                   │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 7.6 Pattern 6: Lịch sử và Sự tiến hóa

```
╔═══════════════════════════════════════════════════════════════╗
║   CONTEXTUAL HISTORY — TẠI SAO NÓ TỒN TẠI?                 ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Sự tiến hóa của CPU:                                         ║
║                                                               ║
║  1940s: Vacuum Tubes (đèn chân không)                        ║
║  ├── ENIAC (1945): 18,000 đèn, 30 tấn!                     ║
║  ├── Vấn đề: hỏng liên tục, tốn điện khủng khiếp          ║
║  │                                                            ║
║  1950s: Transistor (bán dẫn)                                  ║
║  ├── Nhỏ hơn, bền hơn, ít điện hơn                         ║
║  ├── Nhưng: phải hàn TỪNG transistor                         ║
║  │                                                            ║
║  1960s: Integrated Circuit (IC)                               ║
║  ├── Nhiều transistors trên 1 chip                           ║
║  ├── → Moore's Law bắt đầu (Gordon Moore, 1965)            ║
║  │                                                            ║
║  1970s: Microprocessor (CPU trên 1 chip)                     ║
║  ├── Intel 4004 (1971): 2,300 transistors                    ║
║  ├── → Personal Computer revolution!                         ║
║  │                                                            ║
║  2000s: Multi-core CPU                                        ║
║  ├── Single-core không thể nhanh hơn (heat wall)            ║
║  ├── → Thêm NHIỀU cores thay vì 1 core nhanh hơn          ║
║  ├── → Concurrency trở thành MUST-KNOW!                     ║
║  ├── → Đây là lý do Go có GOROUTINES!                       ║
║  │                                                            ║
║  2020s: Heterogeneous Computing                               ║
║  ├── CPU + GPU + Neural Engine + Security chip               ║
║  └── Apple M-series: SoC (System on Chip)                    ║
║                                                               ║
║  ☞ Mỗi bước tiến = giải quyết GIỚI HẠN VẬT LÝ            ║
║    của thế hệ trước!                                         ║
║  ☞ Multi-core → Concurrency → Go goroutines                ║
║    Đây KHÔNG phải coincidence!                               ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

**Sự tiến hóa của Storage:**

```
╔═══════════════════════════════════════════════════════════════╗
║   STORAGE EVOLUTION                                          ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  1950s: Punch Cards + Magnetic Tape                          ║
║  ├── Sequential access ONLY                                  ║
║  ├── → Batch processing (đọc từ đầu đến cuối)             ║
║  │                                                            ║
║  1956: Hard Disk Drive (IBM 350)                              ║
║  ├── RANDOM ACCESS lần đầu tiên!                            ║
║  ├── 5MB, size = 2 tủ lạnh, $50,000/năm thuê              ║
║  ├── → Databases ra đời (random access → B-Tree!)          ║
║  │                                                            ║
║  1970s-2000s: HDD improvements                               ║
║  ├── 5MB → 1TB, nhưng seek time vẫn ~10ms                 ║
║  ├── → Vấn đề: random I/O chậm kinh khủng                 ║
║  ├── → Databases phải optimize cho sequential I/O           ║
║  ├── → WAL, B-Tree fanout, large pages                      ║
║  │                                                            ║
║  2007: SSD (Solid State Drive)                                ║
║  ├── Random read: 10ms → 0.1ms (100× nhanh hơn!)          ║
║  ├── → Nhiều DB assumptions cần xem lại                    ║
║  ├── → B-Tree vs LSM-Tree debate thay đổi hoàn toàn       ║
║  │                                                            ║
║  2013: NVMe (Non-Volatile Memory Express)                    ║
║  ├── Bypass AHCI/SATA bottleneck                             ║
║  ├── Direct PCIe = 7GB/s, ~10μs latency                    ║
║  ├── → Kernel overhead > device latency!                    ║
║  ├── → io_uring, SPDK ra đời để bypass kernel             ║
║  │                                                            ║
║  2020s: CXL Memory / Persistent Memory                       ║
║  ├── Byte-addressable persistent storage                     ║
║  └── → Ranh giới RAM-Disk đang biến mất!                  ║
║                                                               ║
║  ☞ Mỗi thế hệ storage → thay đổi DB design patterns!     ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

**Sự tiến hóa của Concurrency Models:**

```
╔═══════════════════════════════════════════════════════════════╗
║   CONCURRENCY MODEL EVOLUTION                                ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  1960s: No OS / Batch Processing                              ║
║  ├── 1 program at a time, run to completion                  ║
║  │                                                            ║
║  1970s: Processes (Unix)                                      ║
║  ├── fork() = copy entire process (heavy!)                   ║
║  ├── IPC: pipes, shared memory, signals                      ║
║  ├── → Apache prefork: 1 process per request                ║
║  │                                                            ║
║  1990s: Threads (pthreads, Java)                              ║
║  ├── Shared memory = lighter than process                    ║
║  ├── NHƯNG: race conditions, deadlocks, 1MB stack           ║
║  ├── → Java Tomcat: 1 thread per request                    ║
║  ├── → C10K Problem (1999): 10K conns = 10K threads!       ║
║  │                                                            ║
║  2000s: Event Loop (Node.js, Nginx, Redis)                   ║
║  ├── Single thread + non-blocking I/O                        ║
║  ├── Giải C10K! Nhưng: callback hell, no parallelism       ║
║  ├── → Redis: single thread + epoll = 100K ops/s!          ║
║  │                                                            ║
║  2004: Erlang/OTP (BEAM VM)                                   ║
║  ├── Lightweight processes + message passing                 ║
║  ├── "Let it crash" philosophy                                ║
║  ├── → WhatsApp: 2 triệu conns per server!                ║
║  │                                                            ║
║  2009: Go (Goroutines + Channels)                             ║
║  ├── Best of all worlds:                                      ║
║  │   • Lightweight (2KB vs 1MB)                              ║
║  │   • Blocking syntax (dễ đọc)                             ║
║  │   • Non-blocking runtime (scalable)                       ║
║  │   • Multi-threaded (parallel khi cần)                    ║
║  ├── → Docker, Kubernetes, etcd viết bằng Go!              ║
║  │                                                            ║
║  2020s: io_uring + Virtual Threads (Java 21)                 ║
║  ├── Java copy Go model: lightweight virtual threads        ║
║  ├── io_uring: kernel async I/O cho mọi ngôn ngữ          ║
║  └── → Concurrency convergence: mọi ngôn ngữ đi          ║
║        tới cùng 1 model (M:N scheduling)!                   ║
║                                                               ║
║  ☞ LESSON: Go KHÔNG phát minh goroutines.                    ║
║    Go TỔNG HỢP bài học từ 50 năm lịch sử!                 ║
║    Hiểu lịch sử = hiểu TẠI SAO Go design như vậy.          ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

**Tổng hợp: Mỗi Vấn Đề Lịch Sử → Giải Pháp Trong Go:**

```
    ┌──────────────────────┬──────────────────────────┐
    │ HW/OS Problem        │ Go's Answer              │
    ├──────────────────────┼──────────────────────────┤
    │ Multi-core CPUs      │ GOMAXPROCS, goroutines   │
    │ Thread 1MB stack     │ Goroutine 2KB stack      │
    │ Thread context switch│ Goroutine park/unpark    │
    │ Callback hell        │ Blocking syntax          │
    │ C10K connections     │ Netpoller (epoll)        │
    │ Shared memory races  │ Channels + CSP model     │
    │ Memory leaks (C/C++) │ GC (garbage collector)   │
    │ Slow disk I/O        │ io.Copy zero-copy splice │
    │ Network serialization│ encoding/gob, protobuf   │
    │ Complex build systems│ go build (zero deps!)    │
    └──────────────────────┴──────────────────────────┘
```

---

## §8. Tổng Kết & Câu Hỏi Phỏng Vấn Senior

### 8.1 Câu hỏi phỏng vấn

```
╔═══════════════════════════════════════════════════════════════╗
║   CÂU HỎI PHỎNG VẤN SENIOR — COMPUTER ARCHITECTURE          ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║  Q1: "Một dòng code đi qua những giai đoạn nào              ║
║       trước khi CPU thực thi?"                                ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Source → Lexer → Parser → Type Check →     │             ║
║  │  SSA/Optimize → Code Gen → Binary →          │             ║
║  │  OS Load → Memory Mapping → Fetch/Decode/    │             ║
║  │  Execute trên CPU                             │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  Q2: "Tại sao array traversal nhanh hơn linked list?"        ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  → Spatial locality + cache line efficiency  │             ║
║  │  → Array: data liên tiếp → 1 cache miss     │             ║
║  │    load 64 bytes = nhiều elements             │             ║
║  │  → Linked list: nodes rải rác → mỗi node    │             ║
║  │    có thể gây cache miss                      │             ║
║  │  → Chênh lệch: có thể tới 10-100x!          │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  Q3: "Stack vs Heap khác nhau thế nào?"                      ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  Stack: LIFO, tự động, cực nhanh (move SP)  │             ║
║  │  → Local vars, function params               │             ║
║  │  → Mỗi goroutine 1 stack riêng (2KB→)      │             ║
║  │                                                │             ║
║  │  Heap: Dynamic, cần GC, chậm hơn (malloc)   │             ║
║  │  → Shared data, escape analysis              │             ║
║  │  → Go compiler quyết định qua escape analysis│             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  Q4: "CPU-bound vs I/O-bound? Giải pháp khác nhau?"         ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  CPU-bound: Tính toán nặng → Parallelism    │             ║
║  │  → Thêm CPU cores, GOMAXPROCS                │             ║
║  │                                                │             ║
║  │  I/O-bound: Chờ I/O → Concurrency           │             ║
║  │  → Goroutines, async I/O, connection pooling │             ║
║  │  → 90% backend services là I/O-bound!        │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  Q5: "Memory alignment ảnh hưởng performance               ║
║       thế nào? Cho ví dụ trong Go."                          ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  → CPU đọc memory theo khối 4/8 bytes        │             ║
║  │  → Misaligned data = 2 lần đọc thay vì 1   │             ║
║  │  → Struct field ordering: lớn → nhỏ          │             ║
║  │  → VD: struct{bool, int64, bool} = 24 bytes │             ║
║  │         struct{int64, bool, bool} = 16 bytes │             ║
║  │  → Ảnh hưởng cache utilization              │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
║  Q6: "Tại sao Virtual Memory quan trọng?"                    ║
║  ┌──────────────────────────────────────────────┐             ║
║  │  → Process isolation: mỗi process có         │             ║
║  │    address space riêng, không thể truy cập   │             ║
║  │    memory của process khác                    │             ║
║  │  → Memory overcommit: tổng virtual memory    │             ║
║  │    > physical RAM (dùng swap)                 │             ║
║  │  → Memory-mapped files, shared libraries     │             ║
║  │  → ⚠️ Swap = performance cliff!             │             ║
║  └──────────────────────────────────────────────┘             ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

### 8.2 Tổng kết

```
    ┌──────────────────────────────────────────────────────────┐
    │  TỔNG KẾT: CÁCH MÁY TÍNH HOẠT ĐỘNG                     │
    ├──────────────────────────────────────────────────────────┤
    │                                                          │
    │  ┌──────────────────────────────────────────┐            │
    │  │ 1. CPU = Bộ não, chỉ hiểu 0 và 1       │            │
    │  │    → Fetch-Decode-Execute mỗi giây      │            │
    │  │      hàng TỶ lần                        │            │
    │  │                                          │            │
    │  │ 2. Memory Hierarchy = Tháp tốc độ       │            │
    │  │    → Register → L1 → L2 → L3 → RAM     │            │
    │  │    → Cache locality = KEY to performance │            │
    │  │                                          │            │
    │  │ 3. RAM = Stack (nhanh) + Heap (linh hoạt)│           │
    │  │    → Go escape analysis quyết định       │            │
    │  │    → Alignment matters!                   │            │
    │  │                                          │            │
    │  │ 4. Disk = HDD (cơ học) vs SSD (điện tử) │            │
    │  │    → Sequential >> Random (đặc biệt HDD)│            │
    │  │    → Ảnh hưởng database design!          │            │
    │  │                                          │            │
    │  │ 5. Bus & I/O = Đường cao tốc dữ liệu   │            │
    │  │    → I/O-bound vs CPU-bound              │            │
    │  │    → 90% backend = I/O-bound!            │            │
    │  │                                          │            │
    │  │ 6. Code → Binary → OS → CPU             │            │
    │  │    → Compiler pipeline + Virtual Memory  │            │
    │  │    → Hiểu full stack = debug nhanh hơn   │            │
    │  └──────────────────────────────────────────┘            │
    │                                                          │
    │  Châm ngôn:                                              │
    │  "Hiểu máy tính từ transistor đến code =                │
    │   hiểu TẠI SAO mọi thứ hoạt động,                      │
    │   không chỉ biết CÁCH dùng."                            │
    │                                                          │
    └──────────────────────────────────────────────────────────┘
```
